<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2018-06-16 sab 16:26 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Riassunto Probabilit√† e Statistica per l'Informatica</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Gabriele Calissi" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="https://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://www.pirilampo.org/styles/readtheorg/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://www.pirilampo.org/styles/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://www.pirilampo.org/styles/readtheorg/js/readtheorg.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Riassunto Probabilit√† e Statistica per l'Informatica</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org906f5de">1. GitHub</a></li>
<li><a href="#org08a3b25">2. Lezioni</a>
<ul>
<li><a href="#orga0f2c5b">2.1. Statistica Descrittiva</a></li>
<li><a href="#org6c16eba">2.2. Calcolo delle probabilit√†</a></li>
<li><a href="#org7ddc341">2.3. Distribuzioni Notevoli</a>
<ul>
<li><a href="#orgedc442b">2.3.1. Distribuzione Bernoulliana</a></li>
<li><a href="#orgd9934e9">2.3.2. Distribuzione Binomiale</a></li>
<li><a href="#org2ee4694">2.3.3. Distribuzione di Poisson</a></li>
<li><a href="#org07e3d22">2.3.4. Distribuzione Geometrica</a></li>
<li><a href="#org6c47d94">2.3.5. Distribuzione Uniforme</a></li>
<li><a href="#org993ceb7">2.3.6. Distribuzione triangolare</a></li>
<li><a href="#org33f6b9a">2.3.7. Distribuzione esponenziale</a></li>
<li><a href="#orgb6ebf6a">2.3.8. Distribuzione normale</a></li>
<li><a href="#org9a9a2bf">2.3.9. Distribuzione Chi-Quadro</a></li>
<li><a href="#orgef7ce9a">2.3.10. Distribuzione t di STUDENT</a></li>
<li><a href="#orgc20ac14">2.3.11. Distribuzione F di FISHER</a></li>
</ul>
</li>
<li><a href="#org1e1407d">2.4. Teoremi di Convergenza</a>
<ul>
<li><a href="#org5e3266b">2.4.1. Legge dei grandi numeri</a></li>
<li><a href="#orged4c3a6">2.4.2. Teorema Limite Centrale</a></li>
</ul>
</li>
<li><a href="#org597d91d">2.5. Stime di parametri</a>
<ul>
<li><a href="#orga0e362a">2.5.1. Campionamento e campioni</a></li>
<li><a href="#orgfe4fbf9">2.5.2. Principali distribuzioni campionarie</a></li>
<li><a href="#org169fb56">2.5.3. Stimatori e stime puntuali</a></li>
<li><a href="#org59e7d29">2.5.4. Stime intervallari</a></li>
<li><a href="#orgb047b2e">2.5.5. Intervalli di Confidenza per la Varianza</a></li>
<li><a href="#orgd7b1626">2.5.6. Considerazioni sulla Numerosit√† del Campione</a></li>
<li><a href="#orgba8f11c">2.5.7. Stime di parametri</a></li>
</ul>
</li>
<li><a href="#org5222ead">2.6. Verifica di ipotesi: test parametrici</a>
<ul>
<li><a href="#org4540d26">2.6.1. Caratteristiche generali di un test di ipotesi</a></li>
<li><a href="#orgd1ba168">2.6.2. Considerazioni sugli errori di I e II specie</a></li>
<li><a href="#orgf6f53e7">2.6.3. Test sulla media di una popolazione</a></li>
<li><a href="#orgfe377a0">2.6.4. Test sulla varianza di una popolazione</a></li>
<li><a href="#org78eeb3e">2.6.5. Test sulla differenza delle medie di due popolazioni</a></li>
<li><a href="#org7b2b17f">2.6.6. Test sull'uguaglianza delle varianze di due popolazioni</a></li>
<li><a href="#orgd043965">2.6.7. Test di incorrelazione</a></li>
</ul>
</li>
<li><a href="#org9acb7a0">2.7. Verifica di Ipotesi: Test non parametrici</a>
<ul>
<li><a href="#org0222d5d">2.7.1. Test per la bont√† dell'adattamento</a></li>
<li><a href="#orgc4dcbcc">2.7.2. Test del Chi-Quadro</a></li>
<li><a href="#orgd0ddb61">2.7.3. Test per il confronto delle distribuzioni di due popolazioni</a></li>
<li><a href="#org19d8445">2.7.4. Test di indipendenza</a></li>
<li><a href="#org8acd98f">2.7.5. Test di incorrelazione</a></li>
</ul>
</li>
<li><a href="#orge58cbc3">2.8. Regressione Lineare</a>
<ul>
<li><a href="#org569a306">2.8.1. Stima delle costanti del modello</a></li>
<li><a href="#orge5c4ebd">2.8.2. Attendibilit√† del modello lineare</a></li>
<li><a href="#orgb99c715">2.8.3. Analisi dei residui</a></li>
<li><a href="#org7c4e26a">2.8.4. Regressione lineare multipla</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgd9ee9de">3. Laboratorio</a>
<ul>
<li><a href="#org6ab4fce">3.1. Libri</a></li>
<li><a href="#orgeb7324d">3.2. Slides</a>
<ul>
<li><a href="#org5e1ec72">3.2.1. Statistica Descrittiva</a></li>
<li><a href="#org629deed">3.2.2. Calcolo delle Probabilit√†</a></li>
<li><a href="#org8ab59fb">3.2.3. Distribuzioni Notevoli</a></li>
<li><a href="#org5f5f532">3.2.4. Stime di Parametri</a></li>
<li><a href="#orgcf3bbd5">3.2.5. Verifica di ipotesi: Test Parametrici</a></li>
<li><a href="#org5bee095">3.2.6. Verifica di ipotesi: Test non Parametrici</a></li>
<li><a href="#org8063237">3.2.7. Regressione Lineare</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org906f5de" class="outline-2">
<h2 id="org906f5de"><span class="section-number-2">1</span> GitHub</h2>
<div class="outline-text-2" id="text-1">
<ul class="org-ul">
<li><a href="https://github.com/gabrielecalissi/psi">Guardalo in GitHub</a>;</li>
<li><a href="https://github.com/gabrielecalissi/psi/archive/master.zip">Scarica .zip</a>;</li>
<li><a href="https://github.com/gabrielecalissi/psi/archive/master.tar.gz">Scarica .tar.gz</a>.</li>
</ul>
</div>
</div>
<div id="outline-container-org08a3b25" class="outline-2">
<h2 id="org08a3b25"><span class="section-number-2">2</span> Lezioni</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-orga0f2c5b" class="outline-3">
<h3 id="orga0f2c5b"><span class="section-number-3">2.1</span> Statistica Descrittiva</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Raccolta di metodi e strumenti matematici atti ad organizzare una o pi√π serie di dati in modo tale
da evidenziare in forma sintetica eventuali:
</p>
<ul class="org-ul">
<li>Simmetrie;</li>
<li>Periodicit√†;</li>
<li>Leggi di altro genere.</li>
</ul>
<p>
Ovvero in grado di descriverne in maniera immediatamente comprensibile le informazioni implicitamente
contenute nei dati stessi.
</p>

<p>
Solitamente la serie di dati di cui si dispone √® costituita da un numero limitato di <i>osservazioni</i> che devono
essere rappresentative di un'ampia <i>popolazione</i>.
</p>

<p>
Con il termine <i>popolazione</i> si intende l'insieme degli elementi cui si riferisce l'<i>indagine statistica</i>.
</p>

<p>
Affrontare uno studio di statistica descrittiva richiede di tener presente che le tecniche di organizzazione
dei dati varino in funzione dei modi di presentarsi delle <i>caratteristiche (caratteri)</i> degli elementi
su cui √® svolta l'indagine.
</p>

<p>
<i>Caratteri qualitativi</i>: quando le caratteristiche sono qualit√† o dati non numerici. Per es.: GUSTO =
{dolce, amaro} e COLORE = {rosso, verde, giallo, &#x2026;}.
</p>

<p>
<i>Caratteri quantitativi</i>: quando le caratteristiche sono grandezze misurabili.
</p>
<ul class="org-ul">
<li><i>Quantitativi discreti</i>: possono assumere un numero limitato di valori, per es. DADO = {1, 2, &#x2026;, 6}.</li>
<li><i>Quantitativi continui</i>: assumono valori reali come la TEMPERATURA.</li>
</ul>

<p>
Supponiamo di considerare \(n\) elementi della popolazione e di rilevare, per ognuno di essi, il dato
relativo al carattere quantitativo da esaminare.
</p>

<p>
<i>Insieme dei dati</i>: \(E = \{x_1, \dots, x_n\}\).
</p>

<p>
<i>Numerosit√†</i>: numero di elementi considerati \(n\).
</p>

<p>
Quando il <i>carattere √® discreto</i> √® comodo raggruppare i dati considerando l'insieme di tutti i valori assumibili
(modalit√† del carattere) ed associare ad ognuno di tali valori il numero di volte che esso compare in \(E\).
</p>

<p>
\(N\) = numero totale di modalit√†.
</p>

<p>
\(S = \{s_1, \dots, s_N\}\) = insieme delle modalit√†.
</p>

<p>
<i>Frequenza assoluta</i> della modalit√† \(s_j, j = 1, \dots, N\): \(f_j, j = 1, \dots, N\). Data dal numero di elementi di
\(E = \{x_1, \dots, x_n\}\) che hanno valore \(s_j\).
</p>

<p>
<i>Distribuzione di frequenza assoluta dei dati osservati</i>: funzione che associa ad ogni modalit√† la corrispondente
frequenza assoluta. \(f: S \to \mathbb{N}\), \(S = \{s_1, \dots s_N\}\).
</p>

<p>
La <i>frequenza cumulata assoluta</i> per la modalit√† \(s_j\) √® la somma delle frequenze assolute di tutte le modalit√†
\(s_k \in S \mid s_k \leq s_j\). \(F_j = \sum_{s_k \leq s_j} f_k\).
</p>

<p>
<i>Frequenza relativa</i>: \(p_j = \frac{f_j}{n}\).
</p>

<p>
<i>Frequenza cumulata relativa</i>: \(P_j = \sum_{k:s_k \leq s_j} p_k\).
</p>

<p>
Si dicono distribuzione di frequenza cumulata assoluta, relativa e cumulata relativa dei dati osservali, le
funzioni \(F, p\) e \(P\) che associano ad ogni modalit√† \(s_j\) le relative frequenze \(F_j, p_j, P_j\). Con \(n\) numero
delle osservazioni.
</p>

<p>
Esempio:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-01_12-15-55.png" alt="screenshot_2018-03-01_12-15-55.png" />
</p>
</div>



<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-01_12-16-09.png" alt="screenshot_2018-03-01_12-16-09.png" />
</p>
</div>

<p>
La forma tabellare consente di fare facilmente alcune semplici osservazioni:
</p>
<ul class="org-ul">
<li>Il numero di stanze che si presenta con maggior frequenza √® 4 (24).</li>
<li>3 appartamenti su 10 hanno 4 stanze.</li>
<li>9 appartamenti su 10 hanno meno di 7 stanze.</li>
</ul>

<p>
Quando il <i>carattere</i> da studiare √® <i>continuo</i> (o discreto con un numero elevato di modalit√†) √®
conveniente <i>ricondursi a raggruppamenti</i> come quelli appena trattati.
Si suddivide l'insieme \(S\) delle modalit√† in <i>classi</i>.
</p>

<p>
<i>Classe</i>: un qualsiasi sottoinsieme di \(S\).
</p>

<p>
<i>Partizione</i>: ogni famiglia di classi tra loro disgiunte la cui unione √® tutto \(S\).
</p>

<p>
La scelta delle classi con cui si suddivide l'insieme \(S\) √® del tutto <i>arbitraria</i> anche se
√® <i>necessario</i> che esse formino una <i>partizione</i> di \(S\).
</p>

<p>
Le partizioni devono essere:
</p>
<ul class="org-ul">
<li>Significative per il caso in esame.</li>
<li>Sufficientemente numerose.</li>
</ul>

<p>
Ad ogni classe sono associate diverse grandezze che la caratterizzano come:
</p>
<ul class="org-ul">
<li><i>Confine inferiore/superiore</i>: valori estremi delle classe.</li>
<li><i>Ampiezza</i>: differenza tra confine superiore ed inferiore.</li>
<li><i>Valore centrale</i>: semi-somma tra i due confini.</li>
</ul>

<p>
Nel caso in cui il carattere esaminato sia continuo occorre specificare quando le classi sono
chiuse, a destra o a sinistra, ovvero specificare se gli elementi dell'indagine il cui dato coincide
con il confine della classe sono da raggruppare all'interno della classe stessa oppure no.
</p>

<p>
Per esempio:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-01_12-21-02.png" alt="screenshot_2018-03-01_12-21-02.png" />
</p>
</div>

<p>
\(S = [0.44, 5.42] \subset R\)
</p>

<p>
Volendo suddividere \(S\) in 5 classi potremmo scegliere:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-01_12-21-51.png" alt="screenshot_2018-03-01_12-21-51.png" />
</p>
</div>

<p>
I valori centrali delle classi sono \(\bar{x_k}\).
</p>

<p>
Le classi scelte non hanno tutte la stessa ampiezza, utile se si desidera che ogni classe sia abbastanza
consistente. Gli appartamenti con valore maggiore di 4 migliaia di euro sono pochi, si √® ritenuto
opportuno adottare un intervallo di ampiezza maggiore dei restanti quattro intervalli.
</p>

<p>
Per esempio:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-01_12-23-23.png" alt="screenshot_2018-03-01_12-23-23.png" />
</p>
</div>

<p>
<i>Indici di tendenza centrale</i>
</p>

<p>
In generale un ricercatore che disponga di una serie di osservazioni statistiche e si proponga di
descriverne le propriet√†, fissa la propria attenzione sulla determinazione di <i>un solo valore</i> che
rappresenti in qualche modo l'intera serie.
</p>

<p>
Per tale ragione sono stati introdotti gli <i>indici di tendenza centrale</i> o <i>indici di posizione</i> che
sono quantit√† in grado di sintetizzare con un solo valore numerico i valori assunti dai dati.
</p>

<p>
Il valore che √® da solo certamente pi√π utile di ogni altro nello studio di una serie di dati √® la
<i>media</i> definita come media aritmetica tra tutti i valori dei dati osservati.
</p>

<p>
Supponiamo di indicare con \(x_1, \dots, x_n\) l'insieme delle osservazioni disponibili (valori) allora
definiremo la <i>media</i> come \(\bar{x} = \frac{1}{n} \sum_{i = 1}^{n} x_i = \frac{x_1 + \dots + x_n}{n}\)
</p>

<p>
Nel caso in cui i <i>dati siano di tipo quantitativo discreto</i> allora avremo
\(\bar{x} = \frac{1}{n} \sum_{i = 1}^{n} s_j f_j = \frac{s_1 f_1+ \dots + s_N f_N}{n}\)
</p>

<p>
\(\bar{x} = \sum_{j=1}^n s_j p_j = s_1 p_1 + \dots + s_n p_N\).
</p>

<p>
<i>Momento \(k\)-esimo</i> rispetto ad \(y\):
\(M_{k, y} = \frac{1}{n} \sum_{i=1}^n (x_i - y)^k\).
</p>

<p>
Allora la media √® anche il momento primo rispetto all'origine:
\(x = \frac{1}{n} \sum_{i=1}^n x_i\).
</p>

<p>
\(x = \frac{1}{n} \sum_{i=1}^n (x_i - 0)^1\).
</p>

<p>
Un secondo indice di tendenza √® rappresentata dalla <i>mediana</i> definita come quel numero reale che precede tanti
elementi delle serie di dati quanti ne segue.
</p>

<p>
Se ordiniamo la serie di dati \(x_1, \dots, x_n\) in modo crescente ottenendo la serie x(1), &#x2026;, x(n),
la mediana \(\hat{x}\) √® data:
</p>
<ul class="org-ul">
<li>Dall'elemento di posto \(\frac{(n+1)}{2}\) se \(n\) √® dispari.</li>
<li>Dalla media aritmetica tra l'elemento di posto \(\frac{n}{2}\) e quello di posto \(\frac{n}{2} + 1\) se \(n\)
√® pari.</li>
</ul>

<p>
Un ultimo indice di tendenza √® rappresentato dalla <i>moda</i> \(\tilde{x}\) definita come quel valore o classe cui
corrisponde la massima frequenza assoluta.
</p>

<p>
La moda viene spesso utilizzata nel caso di dati qualitativi ovvero quando risulti impossibile definire
media e mediana.
</p>

<p>
Si osservi che non √® garantita l'unicit√† della moda. Infatti parleremo di:
</p>
<ul class="org-ul">
<li>Distribuzione <i>uni-modale</i> nel caso in cui vi sia un'unica moda.</li>
<li>Distribuzione <i>multi-modale</i> nel caso in cui vi siano pi√π mode.</li>
</ul>

<p>
Per esempio:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-01_12-39-12.png" alt="screenshot_2018-03-01_12-39-12.png" />
</p>
</div>



<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-01_12-39-23.png" alt="screenshot_2018-03-01_12-39-23.png" />
</p>
</div>

<p>
Il calcolo della mediana richiede di ordinare la serie di dati.
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-01_12-39-45.png" alt="screenshot_2018-03-01_12-39-45.png" />
</p>
</div>

<p>
Per quanto riguarda il calcolo della moda √® banale ricavarla dalla tabella delle frequenze.
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-01_12-40-09.png" alt="screenshot_2018-03-01_12-40-09.png" />
</p>
</div>

<p>
Si ricerca il valore con massima frequenza assoluta ottenendo che la moda √® \(\tilde{x} = 4\).
</p>

<p>
<i>Indice di variabilit√†</i>
</p>

<p>
Siano date le seguenti serie di dati: \(E_1 = \{0.5, 0.8, 2.0, 2.7, 4.0\}\) ed \(E_2 = \{1.4, 1.7, 2.0, 2.1, 2.8\}\)
che rappresentano il reddito mensile (migliaia di euro) di due gruppi distinti di individui (appartenenti a
due diverse regioni). Le due serie di dati appaiono molto diverse tra loro. Gli elementi di \(E_1\) sono molto
disomogenei tra loro mentre non lo sono quelli di \(E_2\). Entrambi i casi hanno per√≤ ugual <i>media</i> e <i>mediana</i>.
</p>

<p>
Gli indici di tendenza centrale, quindi, non sono utili per fornire informazioni circa l'omogeneit√† o
disomogeneit√† dei dati.
</p>

<p>
Per ovviare a tale limite vengono introdotti gli indici che misurano il grado di <i>omogeneit√†</i> o <i>dispersione</i>
dei dai.
</p>

<p>
Il pi√π importante tra questi √® senz'altro la <i>varianza</i> definita come: \(x^2 = \frac{1}{n} (x_i - \bar{x})^2\).
Viene definita confrontando ogni singola osservazione \(x_i\) con la media \(\bar{x}\) e sommando i quadrati
delle differenze cos√¨ ottenute.
</p>

<p>
Ricordando la definizione \(M_{k, y} = \frac{1}{n} \sum_{i=1}^n (x_i - y)^k\) la <i>varianza</i> √® allora il <i>momento secondo
rispetto alla media</i>: \(x^2 = \frac{1}{n} (x_i - \bar{x})^2\).
</p>

<p>
Viene introdotto il quadrato perch√© in caso contrario \(\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x}) = 0\). La
varianza √® tanto pi√π grande quanto pi√π i singoli dati si scostano dalla media, vale a dire tanto pi√π
i dati risultano disomogenei. Nel caso in esame avremo: \(s_{E_1}^2 = 1.69\) e \(s_{E_2}^2 = 0.22\). E pertanto
la misura varianza consente di rappresentare il <i>grado di disomogeneit√†</i> della serie di dati.
</p>

<p>
Nel caso di <i>caratteri quantitativi discreti</i>, di cui sia nota la distribuzione di frequenza, la <i>varianza</i>
pu√≤ essere calcolata tramite le seguenti formule:
</p>

<p>
\(s^2 = \frac{1}{n} \sum_{j=1}^N (s_j - \bar{x})^2 f_j = \sum_{j=1}^N (s_j - \bar{x})^2 p_j\). Alternativamente la <i>varianza</i> pu√≤ essere
calcolata tramite la seguente formula: \(s^2 = \frac{1}{n} \sum_{i=1}^n x_i^2 - \bar{x}^{2}\).
</p>

<p>
Analogamente √® possibile mostrare che per <i>caratteri quantitativi discreti</i> vale la seguente relazione:
\(s^2 = \sum_{j=1}^{N} s_j^2 p_j - \bar{x}^2\).
</p>

<p>
Poich√© la dimensione della varianza √® il quadrato di quella dei dati,
in molti casi si preferisce una diversa misura detta <i>scarto quadratico medio</i>:
</p>

<p>
\(s = \sqrt{s^2} = \sqrt{\frac{1}{n} \sum_{i=1}^n x_i^2 - \bar{x}^2} = \sqrt{\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2}\).
</p>

<p>
Il molti casi si √® interessati a studiare fenomeni che coinvolgono due o pi√π caratteri della popolazione
tali da non potersi considerare separatamente. Si pensi ad esempio al caso in cui vengano considerati
separatamente. 
</p>

<p>
Si pensi ad esempio al caso in cui vengano considerati i seguenti caratteri:
</p>
<ul class="org-ul">
<li>Valore al metro quadro.</li>
<li>Superficie.</li>
</ul>
<p>
per un insieme di appartamenti di una data zona di una citt√†.
</p>

<p>
In quel caso √® necessario considerare congiuntamente le due caratteristiche, vale a dire procedere in modo
differente a quanto fatto fin qui. Limitiamoci a considerare il caso di due caratteri contemporanei.
</p>

<p>
In questo caso l'insieme dei dati statistici \(E\) sar√† costituito da coppie di valori \(E = \{(x_1, y_1), \dots, (x_n, y_n)\}\).
</p>

<p>
Ipotizziamo inoltre che entrambi i caratteri siano di tipo quantitativo e discreto.
</p>

<p>
I caratteri quantitativi continui vengono trattati in modo analogo previo una procedura di raggruppamento in classi.
</p>

<p>
Sia \(S = \{(s_j, u_k), j = 1, \dots, N; k = 1, \dots, M\}\) l'insieme delle coppie di valori assumibili dalla coppia di caratteri
analizzati. Viene detta <i>frequenza assoluta</i> di \((s_j, u_k)\) la quantit√† \(f_{jk}\) definita come \(f_{jk}\) = numero di elementi
\(E\) aventi valore \((s_j, u_k)\).
</p>

<p>
Definiremo <i>distribuzione di frequenza assoluta doppia</i> la funzione \(f\) che associa ad ogni coppia di valori \((s_j, u_k)\)
la corrispondente frequenza \(f_{jk}\).
</p>

<p>
Analogamente al caso unidimensionale vengono solitamente definiti ed utilizzati altri tipi di frequenze:
</p>
<ul class="org-ul">
<li>Frequenza cumulata assoluta: \(F_{jk} = \sum_{r:s_r \leq s_j; l:u_l \leq u_k} f_{rl}\).</li>
<li>Frequenza relativa: \(p_{jk} = \frac{f_{jk}}{n}\).</li>
<li>Frequenza cumulata relativa: \(P_{jk} = \sum_{r:s_r \leq s_j; l:u_l \leq u_k} p_{rl}\).</li>
</ul>

<p>
Con <i>distribuzione di frequenza doppia</i> si intende infine una qualsiasi delle funzioni \(f, F, p, P\) che
associ ad ogni coppia (s<sub>j</sub>, u<sub>k</sub>) la corrispondente frequenza. In aggiunta alla distribuzioni appena citate,
analoghe a quelle del caso unidimensionale, esistono altre distribuzioni di frequenza spesso prese in
considerazione.
</p>

<p>
<i>Distribuzioni marginali</i>: distribuzioni dei singoli caratteri presi indipendentemente dagli altri.
</p>

<p>
Nel caso ci si riferisca al primo carattere, per ogni valore assumibile ad esso, sia \(s_j\), √® detta
<i>frequenza assoluta marginale</i> la quantit√† \(f_{xj}\) data dal numero di elementi \(E\) il cui primo carattere
ha valore \(s_j\), vale a dire \(f_{xj}\) = numero di elementi \(E\) aventi valore \((s_{j}, *)\).
</p>

<p>
Analogamente avremo:
</p>
<ul class="org-ul">
<li>Frequenza assoluta marginale: \(F_{xj}\) = somma delle frequenze assolute marginali di tutti i valori \(s_k\) tali che
\(s_k \leq s_j\).</li>
<li>Frequenza relativa marginale: \(p_{xj}\) = rapporto tra frequenza assoluta marginale \(f_{xj}\) e numerosit√† \(n\) delle
osservazioni.</li>
<li>Frequenza cumulata relativa marginale: \(P_{xj}\) = somma delle frequenze relative marginali di tutti i valori \(s_k\)
tali che \(s_k \leq s_j\).</li>
</ul>

<p>
Per esempio:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-01_13-14-48.png" alt="screenshot_2018-03-01_13-14-48.png" />
</p>
</div>



<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-01_13-15-01.png" alt="screenshot_2018-03-01_13-15-01.png" />
</p>
</div>

<p>
Es.
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-01_13-15-19.png" alt="screenshot_2018-03-01_13-15-19.png" />
</p>
</div>

<p>
Consideriamo due serie \(\{x_i\}\ \{y_i\},\ i = 1, \dots, n\) e poniamo a confronto le variazioni delle coppie di dati rispetto ai
corrispondenti valori medi considerando le <i>coppie di scarti</i> \(x_i - \bar{x}\) e \(y_i - \bar{y}\). Risulta abbastanza
naturale pensare che esista una relazione di dipendenza tra i due caratteri se a valori positivi (negativi) dello scarto
\(x_i - \bar{x}\) corrispondono sistematicamente o quasi sempre valori positivi o negativi dello scarto \(y_i - \bar{y}\).
</p>

<p>
<i>Covarianza</i>: si definisce covarianza \(c_{xy}\) (dei dati o campionaria) delle due serie di dati \(\{x_i\}\ \{y_i\}\):
\(c_{xy} = \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})\), \(s^2 = \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2\).
</p>

<p>
La covarianza assume un valore positivo (negativo) che diviene grande in valore assoluto nel caso in cui i termini prodotto
\((x_i - \bar{x}) (y_i - \bar{y})\) abbiano segni concordi (positivi o negativi che siano). In questo caso si parla di
serie statistiche fortemente correlate o per meglio dire di dati delle serie fortemente correlati.
</p>

<p>
Nel caso opposto vale a dire nel caso in cui i dati delle serie siano incorrelati (non vi √® dipendenza degli uni
dagli altri) avremo che i prodotti \((x_i - \bar{x})(y_i - \bar{y})\) avranno segni diversi (discordi in segno) e la
covarianza, per come definita, risulter√† piccola in valore assoluto (prossima al valore 0). La covarianza pu√≤
essere calcolata anche tramite la seguente formula:
</p>

<p>
\(c_{xy} = \frac{1}{n} \sum_{i=1}^n x_i y_i - \bar{x} \bar{y}\), \(s^2 = \frac{1}{n} \sum_{i=1}^n x_i^2 - \bar{x}^2\).
</p>

<p>
Nel caso in cui i dati si riferiscano a caratteri quantitativi discreti, di cui √® nota la distribuzione di
frequenza doppia, √® possibile utilizzare le seguenti formule per il calcolo della covarianza.
</p>

<p>
\(c_{xy} = \sum_{j=1}^N \sum_{k=1}^M (s_j - \bar{x})(u_k - \bar{y}) p_{jk} = \sum_{j=1}^N \sum_{k=1}^M s_j u_k p_{jk} - \bar{x} \bar{y}\).
</p>

<p>
Due serie di dati \(\{x_i\}\ \{y_i\}\) si dicono:
</p>
<ul class="org-ul">
<li>Statisticamente incorrelate se \(\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y}) = 0\) e quindi \(c_{xy} = \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y}) = 0\);</li>
<li>Statisticamente indipendenti se vale la seguente condizione:
\(\forall j = 1, \dots, N\) e \(k = 1, \dots, M \quad p_{jk} = p_j p_k\), con \(p_{jk} = \frac{f_{jk}}{n}\), \(p_j = \frac{f_j}{n}\), \(p_k = \frac{f_k}{n}\).</li>
</ul>

<p>
Due serie di dati statisticamente indipendenti sono incorrelate mentre non √® necessariamente vero il contrario.
</p>

<p>
Statisticamente indipendenti \(\implies\) statisticamente incorrelate.
</p>

<p>
Statisticamente incorrelate \(\not\implies\) statisticamente indipendenti.
</p>

<p>
Infatti: \(\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y}) = \sum_{i=1}^n (x_i - \bar{x}) \sum_{i=1}^n (y_i - \bar{y}) = 0\).
</p>

<p>
Nel caso bidimensionale (variabili \(x\) e \(y\)) la covarianza si pu√≤ rappresentare attraverso una matrice
\(2 \times 2\):
</p>
\begin{equation*}
c = 
\begin{bmatrix}
c_{xx} &c_{xy}\\
c_{xy} &c_{yy}
\end{bmatrix}
=
\begin{bmatrix}
var(x) &cov(x, y)\\
cov(x, y) & var(y)
\end{bmatrix}
\end{equation*}
<p>
√à indipendente dalla grandezza delle varianze.
</p>

<p>
Per una misura indipendente dalla variabilit√† delle grandezze si usa la matrice di correlazione:
</p>
\begin{equation*}
\text{Corr} =
\begin{bmatrix}
\frac{c_{xx}}{\sigma_x^2} &\frac{c_{xy}}{\sigma_x \sigma_y}\\
\frac{c_{xy}}{\sigma_x \sigma_y} &\frac{c_{yy}}{\sigma_y^2}
\end{bmatrix}
=
\begin{bmatrix}
1 &corr(x, y)\\
corr(x, y) &1
\end{bmatrix}
\end{equation*}
<p>
Nel caso di \(m\) variabili,
</p>
\begin{equation*}
\text{Corr} =
\begin{bmatrix}
1 &\frac{c_{x_1 x_2}}{\sigma_{x_1} \sigma_{x_2}} &\dots &\frac{c_{x_1 x_m}}{\sigma_{x_1} \sigma_{x_m}}\\
\frac{c_{x_1 x_2}}{\sigma_{x_1} \sigma_{x_2}} &1 &\dots &\vdots\\
\vdots &\ddots &\ddots &\vdots\\
\frac{c_{x_1 x_m}}{\sigma_{x_1} \sigma_{x_m}} &\dots &\dots &1
\end{bmatrix}
\end{equation*}

<p>
<i>Regressione lineare per serie di dati</i>
</p>

<p>
Consideriamo un campione costituito da un insieme \(E\) di coppie di dati, relativi a due caratteri \(x\) ed \(y\):
\(E = \{L(x_1, y_1), \dots, (x_n, y_n)\}\). In molti casi ci si pone la questione se tra tali caratteri \(x\) ed \(y\) esista
un legame di tipo funzionale o una relazione di tipo funzionale che ne descriva in modo soddisfacentemente
corretto il legame realmente esistente. Un'analisi tesa a rispondere a una tale questione viene detta <i>analisi
di regressione</i>.
</p>

<p>
Un tale studio viene affrontato pensando ad uno dei due caratteri come ad una <i>variabile indipendente</i>, sia
per esempio il carattere \(x\), e cercando di stabilire quale funzione \(f\), all'interno di una ben determinata
classe, consenta di scrivere la seguente relazione \(y = f(x)\) in modo che essa descriva al meglio il legame
tra la variabile indipendente \(x\) e il carattere \(y\) che a questo punto viene interpretato coma <i>variabile
dipendente</i>. Occorre specificare cosa si intende per funzione che meglio descrive il legame tra i due caratteri.
Solitamente si determina la funzione \(f\) che minimizza le distanze tra i valori osservati del carattere \(y\) e quelli
che si otterrebbero per il carattere \(y\) se la relazione che lega il carattere \(y\) ad \(x\) fosse proprio quella descritta
da \(f\).
</p>

<p>
In altri termini quello che si cerca √® la funzione \(f\) che minimizza la seguente quantit√† \(g(f) = \sum_{i=1}^n [f(x_i) - y_i]^2\) dove
il quadrato si utilizza affinch√© le distanze vengano tutte considerate con segno positivo. Nel caso particolare in cui \(f\)
sia vincolata ad essere una funzione lineare (retta) allora parleremo di <i>regressione lineare</i>.
</p>

<p>
Nel caso della <i>regressione lineare</i> il problema si riduce alla determinazione dei coefficienti \(m\) e \(q\) della retta
\(y = mx + q\) per cui risulti minima la quantit√† \(g(m, q) = \sum_{i=1}^n [mx_i + q - y_i]^2\).
</p>

<p>
I valori \(mx_i + q\) sono proprio i valori \(f(x_i)\) che rappresentano l'approssimazione alle \(y_i\) tramite
la funzione \(f\).
</p>

<p>
Risolvendo il sistema algebrico ottenuto e ricordando le definizioni di varianza e covarianza si ottiene in
definitiva \(m = \frac{c_{xy}}{s_x^2}\) e \(q = \bar{y} - \frac{c_{xy}}{s_x^2} \bar{x}\).
</p>

<p>
Questo metodo consente di determinare la retta che meglio descrive la relazione tra i due caratteri senza
peraltro fornire alcuna indicazione circa il grado di approssimazione che √® in grado di offrire. Per tale
motivo √® stata introdotta una nuova grandezza detta <i>coefficiente di correlazione lineare</i>: \(r_{xy} = \frac{c_{xy}}{s_x s_y}\).
</p>

<p>
L'importanza di tale coefficiente deriva dal fatto che esso assume valori sempre appartenenti all'intervallo
\([-1, 1]\). Inoltre:
</p>
<ul class="org-ul">
<li>√à nullo nel caso in cui le serie di dati sono <i>statisticamente incorrelate</i>.</li>
<li>√à pari ad 1 (in valore assoluto) quando le <i>coppie di dati</i> si trovano <i>esattamente sulla retta</i>
\(y = mx + q\).</li>
</ul>
<p>
Pertanto esso rappresenta <i>il grado di allineamento delle coppie di dati</i>.
</p>

<p>
Per esempio, supponiamo di voler controllare la resistenza di un campione di 15 travi di cemento, tutte
ottenute dalla stessa gettata, misurando sia i carichi di prima lesione che quelli di rottura finale e
supponiamo che i dati disponibili siano i seguenti:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-01_14-22-07.png" alt="screenshot_2018-03-01_14-22-07.png" />
</p>
</div>

<p>
√à possibile computare il coefficiente di correlazione che sar√† pari a \(r_{xy} = 0.0195\).
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-01_14-22-49.png" alt="screenshot_2018-03-01_14-22-49.png" />
</p>
</div>

<p>
<i>Regressione (modello lineare) per serie di dati</i>
</p>

<p>
Abbiamo accennato in precedenza al fatto che non si √® sempre vincolati alla scelta di una retta tra le
funzioni che possono descrivere la relazione tra le due serie di dati.
</p>

<p>
Quanto esposto in precedenza pu√≤ essere applicato anche nel caso in cui si considerino relazioni funzionali
di diversa natura, la cui scelta pu√≤ essere suggerita da una qualche impressione derivante da ispezioni
visive dei dati o da altre forme di conoscenza circa il fenomeno analizzato.
</p>

<p>
Per esempio, si faccia ancora riferimento ai dati dell'esempio precedente e si valuti l'opportunit√† di
sfruttare il seguente modello:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-01_14-25-32.png" alt="screenshot_2018-03-01_14-25-32.png" />
</p>
</div>

<p>
Si noti inoltre che molte relazioni funzionali non lineari possono essere ricondotte a tali (lineari)
con opportune trasformazioni delle variabili. Per esempio, una relazione del tipo \(y = a \cdot e^{bx}\) pu√≤
essere riscritta come \(\tilde{y} = \beta \cdot \tilde{x} + \alpha\), dove \(\tilde{y} = \log{(y)}\), \(\tilde{x} = x\) e
\(\alpha = \log{(a)}\), \(\beta = b\).
</p>

<p>
La determinazione dei coefficienti \(a\) e \(b\) che meglio permettono di approssimare una serie di punti
\(\{x_i, y_i\}\) pu√≤ essere effettuata riconducendosi ad una regressione lineare ovvero determinando i
coefficienti \(\alpha\) e \(\beta\) che meglio approssimano, linearmente, la serie dei punti \(\{\tilde{x_i} \tilde{y_i}\}\), dove
\(\tilde{y_i} = \log{(y_i)}\) e \(\tilde{x_i} = x_i\). Una volta determinati tali coefficienti, il calcolo di \(a\) e \(b\)
risulta immediato.
</p>

<p>
Alcune funzioni riconducibili a lineari:
</p>
<ul class="org-ul">
<li>\(y = a \log{(x)} + b\);</li>
<li>\(y = a x^b\);</li>
<li>\(y = \frac{1}{a + b \cdot e^{-x}}\), \(\beta = b\).</li>
</ul>
</div>
</div>

<div id="outline-container-org6c16eba" class="outline-3">
<h3 id="org6c16eba"><span class="section-number-3">2.2</span> Calcolo delle probabilit√†</h3>
<div class="outline-text-3" id="text-2-2">
<p>
Teoria (assiomatica o frequentista o soggettiva) che riguarda il calcolo della probabilit√† del verificarsi di certi
eventi composti di eventi elementari. √à lo strumento base per la <i>statistica</i>, che trae conclusioni su una popolazione,
utilizzando i dati osservati su una collezione di individui (campione) appartenenti alla popolazione (inferenza su
popolazione).
</p>

<p>
Al fine di presentare l'<i>impostazione assiomatica</i> supponiamo di voler studiare una situazione (esperimento) avente un 
insieme \(\Omega\) di diversi possibili esiti, ben distinti tra loro. Ogni sottoinsieme \(A\) di \(\Omega\) viene detto <i>evento</i>.
Ad ogni evento \(A\) √® associabile una quantit√† numerica detta <i>probabilit√†</i> e denotata tramite \(P(A)\) il cui significato
varia a seconda dell'impostazione.
</p>

<p>
<i>Impostazione assiomatica</i>
</p>

<p>
L'insieme \(\Omega\) che pu√≤ contenere un numero finito o infinito di elementi viene detto <i>spazio campione</i>.
</p>

<p>
Ogni evento pu√≤ essere <i>elementare</i> se √® costituito da un elemento singolo di \(\Omega\), oppure <i>composto</i> in caso
contrario.
</p>

<p>
Due eventi \(A\) e \(B\) vengono detti <i>incompatibili</i> se sono <i>sottoinsiemi disgiunti</i>.
</p>

<p>
Si definisce <i>insieme delle parti</i> di \(\Omega\) l'insieme di tutti i suoi sottoinsiemi e lo si denota tramite \(\mathcal{P}(\Omega)\)
</p>

<p>
La probabilit√† deve essere definita per tutti gli elementi di \(\mathcal{P}(\Omega)\) con particolari propriet√† (algebra di Boole
o \(\sigma\)-algebre).
</p>

<p>
Per esempio:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-06_11-50-52.png" alt="screenshot_2018-03-06_11-50-52.png" />
</p>
</div>

<p>
Possibili eventi sono i suoi sottoinsiemi, \(\{R\}\) e \(\{B, G\}\)
</p>

<p>
Un altro esempio:
</p>

<p>
Consideriamo un esperimento che pu√≤ fornire come risultato un qualsiasi valore reale in un intervallo
\([a, b] \subseteq \mathbb{R}\).
</p>

<p>
In questo caso avremo:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-06_11-54-12.png" alt="screenshot_2018-03-06_11-54-12.png" />
</p>
</div>

<p>
<i>Definizione di probabilit√† secondo Kolmogorov</i>
</p>

<p>
Viene detta <i>misura di probabilit√†</i> ogni applicazione \(P : \mathcal{P}(\Omega) \to \mathbb{R}_0^+\) che associa
un valore reale ad ogni sottoinsieme di \(\Omega\) e per cui valgono le seguenti propriet√†:
</p>
<ul class="org-ul">
<li><p>
Per ogni \(A \subseteq \Omega\) esiste ed √® unico un numero \(P(A) \geq 0\).
</p>

<p>
Interpretando \(P(A)\) come <i>frequenza relativa</i> dell'evento \(A\), essa √® compresa tra 0 e 1.
</p></li>

<li>\(P(\Omega) = 1\);</li>
<li>Data la famiglia \(\{A_i, i \in I \subseteq \mathbb{N}\}\) di eventi incompatibili vale
\(P\left(\bigcup_{i \in I} A_i \right) = \sum_{i \in I} P(A_i)\);</li>
</ul>

<p>
Ogni <i>misura di probabilit√†</i> √® una funzione che assegna valori numerici a sottoinsiemi di \(\Omega\) e non ai suoi
elementi (eventi elementari), come contrariamente si √® portati a pensare.
</p>

<p>
Per esempio consideriamo lo spazio campione: \(\Omega = [a, b] \subseteq \mathbb{R}\). Una misura di probabilit√†
da assegnare a \(\mathcal{P}(\Omega) \to \mathbb{R}_0^+\) definita ponendo \(P((c, d)) = \frac{d-c}{b-a}\) quando
l'evento che consideriamo √® un intervallo \((c, d) \subseteq [a, b] \quad a \leq c < d \leq b\). Possiamo, per
esempio, porre \(P(\{s\}) = 0\) per ogni \(s \in [a, b]\), in modo da poter calcolare anche la probabilit√†
di eventi con estremi inclusi.
</p>

<p>
Dalle 3 propriet√† che definiscono le misure di probabilit√†, discendono in modo immediato alcune <i>propriet√†
aggiuntive</i>. Sia \(P\) una misura di probabilit√† definita sull'insieme delle parti \(\mathcal{P}(\Omega)\) di uno
spazio campione \(\Omega\).
Allora:
</p>
<ul class="org-ul">
<li>Per ogni \(A \subseteq \Omega\) vale \(P(\bar{A}) = 1 - P(A)\);</li>
<li>Per ogni \(A \subseteq \Omega\) vale \(P(A) \leq 1\);</li>
<li>Per ogni \(A, B \subseteq \Omega\) se \(A \subseteq B\) allora \(P(A) \leq P(B)\);</li>
<li>Per ogni \(A, B \subseteq \Omega\) anche non incompatibili, vale \(P(A \cup B) = P(A) + P(B) - P(A \cap B)\);</li>
<li>Per ogni \(A \subseteq \Omega\) vale \(P(\bar{A}) = 1 - P(A)\), infatti \(1 = P(A \cup \bar{A}) = P(A) + P(\bar{A}) - P(A \cap \bar{A}) =
  P(A) + P(\bar{A}) - 0\);</li>
<li>Per ogni \(A, B \subseteq \Omega\) anche non incompatibili, vale \(P(A \cup B) = P(A) + P(B) - P(A \cap B)\);</li>
<li>Per ogni \(A, B \subseteq \Omega\) anche non incompatibili, vale \(P(A \cup B) = P(A \cap \bar{B}) + P(A \cap B) + P(\bar{A} \cap B)\);</li>
<li>Per ogni \(A, B \subseteq \Omega\) anche non incompatibili, vale \(P(A) = P(A \cap \bar{B}) + P(A \cap B)\) e \(P(B) = P(A \cap B) + P(\bar{A} \cap B)\).</li>
</ul>

<p>
In base alle precedenti propriet√† √® possibile osservare che la propriet√†:
</p>
<ul class="org-ul">
<li>Data la famiglia \(\{A_i, i \in I \subseteq N\}\) di eventi incompatibili vale \(P\left(\bigcup_{i \in I} A_i \right) = \sum_{i \in I} P(A_i)\)</li>
</ul>
<p>
√à un caso particolare della propriet√†:
</p>
<ul class="org-ul">
<li>Per ogni \(A, B \subseteq \Omega\) anche non incompatibili, vale \(P(A \cup B) = P(A) + P(B) - P(A \cap B)\) nel caso in cui gli
eventi \(A\) e \(B\) siano incompatibili (\(A \cap B = \emptyset\)).</li>
</ul>

<p>
Per esempio, supponiamo di avere effettuato un investimento immobiliare e di avere a disposizione 3 appartamenti di
diverso valore da vendere. Supponiamo di essere interessati a fare delle stime sui ricavi del nostro investimento
tenendo conto di quanti di tali appartamenti saranno stati venduti entro la fine dell'anno. Un modo per descrivere
tutte le possibili situazioni relative alle vendite alla fine dell'anno consiste nell'associare a ciascuna di esse
una terna \((\alpha_1, \alpha_2, \alpha_3)\), dove \(\alpha_i = 1\) se l'appartamento \(i\)-mo sar√† stato venduto alla fine dell'anno e
\(\alpha_i = 0\) in caso contrario.
</p>

<p>
In questo modo l'insieme delle possibili situazioni alla fine dell'anno pu√≤ essere descritta come
\(\Omega = \{(0, 0, 0), (1, 0, 0), (0, 1, 0), (0, 0, 1), (1, 1, 0), (1, 0, 1), (0, 1, 1), (1, 1, 1)\}\).
</p>

<p>
Supponiamo ora che gli 8 casi realizzabili (eventi elementari) siano egualmente possibili ovvero che la
misura di probabilit√† adatta a descrivere il fenomeno sia la \(P\) definita come segue:
\(P(A) = \frac{\text{numero di elementi di } A}{\text{numero di elementi di } \Omega}\) per ogni elemento \(A\) di \(\Omega\).
</p>

<p>
Consideriamo ora l'evento \(A\): "almeno un appartamento viene venduto".
</p>

<p>
Siamo pertanto interessati al seguente evento: \(A = \{(1, 0, 0), (0, 1, 0), (0, 0, 1), (1, 1, 0), (1, 0, 1), (0, 1, 1), (1, 1, 1)\}\).
Poich√© esso contiene 7 elementi su un totale di 8 casi possibili, allora: \(P(A) = \frac{\text{numero di elementi di } A}{\text{numero di elementi di } \Omega}
= \frac{7}{8}\).
</p>

<p>
Consideriamo ora l'evento \(B\): "almeno due appartamenti vengono venduti". √à abbastanza chiaro che ogni situazione di vendita contenuta
in \(B\) lo √® a maggior ragione in \(A\) (almeno 1 venduto contiene almeno 2 venduti) per cui \(B \subseteq A\). In effetti avremo
\(B = \{(1, 1, 0), (1, 0, 1), (0, 1, 1), (1, 1, 1)\}\) da cui si ricava \(P(B) = \frac{4}{8} = \frac{1}{2}\), \(P(A) = \frac{7}{8}\).
Pertanto vale quanto asserito in precedenza, ovvero che \(B \subseteq A \implies P(B) \leq P(A)\). Infine, consideriamo l'evento
\(C\) "il terzo appartamento viene venduto", ovvero \(C = \{(0, 0, 1), (1, 0, 1), (0, 1, 1), (1, 1, 1)\}\). Supponiamo
di essere interessati a determinare la probabilit√† di \(B \cup C\): \(P(B \cup C) = P(B) + P(C) - P(B \cap C) = \frac{1}{2} + \frac{1}{2}
= \frac{5}{8}\) essendo \(B \cap C = \{(1, 0, 1), (0, 1, 1), (1, 1, 1)\}\). In effetti \(P(B \cup C)\) avrebbe potuto essere determinata direttamente
osservando che \(B \cup C = \{(0, 0, 1), (1, 1, 0), (1, 0, 1), (0, 1, 1), (1, 1, 1)\}\).
</p>

<p>
Esempio: da un'urna con 6 palline bianche e 5 palline nere se ne estraggono 2. Qual √® la probabilit√† che una delle palline
estratte sia bianca e l'altra nera?.
</p>

<p>
Lo spazio campione ha \(11 \cdot 10 = 110 \text{elementi}\). Ci sono \(6 \cdot 5 = 30\) modi in cui la prima estratta √® bianca e la seconda √® nera,
e \(5 \cdot 6 = 30\) modi in cui la prima estratta √® nera e la seconda √® bianca. Quindi, pensando che tutti i punti dello spazio
campione siano egualmente probabili, la probabilit√† cercata √®: \(\frac{30 + 30}{110} = \frac{6}{11}\).
</p>

<p>
Secondo esempio: in quanti modi si possono ordinare le lettere \(a, b, c\) (senza ripetizione)?
</p>

<p>
Ce ne sono 6 (\(3 \cdot 2\)): abc, acb, bac, bca, cab, cba. Ciascuno di questi ordinamenti √® una <i>permutazione</i>.
</p>

<p>
In generale \(n \cdot (n-1) \cdot \cdots \cdot 2 \cdot 1 = n!\)
</p>

<p>
Terzo esempio: qual √® la probabilit√† che tra \(n\) persone ce ne siano almeno 2 che compiono gli anni lo stesso
giorno dell'anno? ‚Üí \(356 \cdot \dots 365 = 365^n\) possibilit√†.
</p>

<p>
Ragioniamo sull'evento negato, calcoliamo la probabilit√† che le \(n\) persone abbiano tutte compleanni in giorni
diversi:
</p>
<ul class="org-ul">
<li>La prima persona ha 365 possibili giorni per il proprio compleanno;</li>
<li>La seconda pu√≤ averlo solo nei rimanenti 364;</li>
<li>La terza solo nei rimanenti 363.</li>
<li>Ecc.</li>
</ul>

<p>
La probabilit√† che i compleanni non coincidano in nessun caso (per nessuna delle \(n\) persone) √®:
\(\frac{365 \cdot 364 \cdot \cdots \cdot (365 - n+1)}{365^n}\). Pertanto, la probabilit√† che almeno 2 persone su \(n\) compiano
gli anni gli anni lo stesso giorno √® \(1 - \frac{365 \cdot 364 \cdot \dots \cdot (365 - n+1)}{365^n}\)
</p>

<p>
Nel caso di n = 23:
</p>

<p>
La probabilit√† che i compleanni non coincidano in nessuno caso (per nessuna delle \(n\) persone) √®:
\(\frac{365 \cdot 364 \cdot \cdots \cdot (365 - 23 + 1)}{365^n} = 0.4927\).
</p>

<p>
Pertanto, la probabilit√† che almeno 2 persone su \(n\) compiano gli anni lo stesso giorno √®:
\(1 - \frac{365 \cdot 364 \cdot \cdots \cdot (365 - 23 + 1)}{365^n} = 0.5073\).
</p>

<p>
Si voglia determinare il numero di differenti gruppi di \(r\) oggetti che √® possibile costruire (formare)
usando \(n\) oggetti diversi (non importa l'ordine degli oggetti).
</p>

<p>
Per esempio: quanti gruppi diversi di 3 oggetti √® possibile costruire dai 5 oggetti \(A, B, C, D, E\)?
</p>

<ul class="org-ul">
<li>Il primo pu√≤ esser scelto in 5 modi diversi;</li>
<li>Il secondo in 4;</li>
<li>Il terzo in 3.</li>
</ul>

<p>
Per√≤, lo stesso gruppo di 3, per esempio \(ABC\), pu√≤ presentarsi come \(ABC, ACB, BAC, BCA, CAB, CBA\), ma il gruppo √®
sempre lo stesso. Perci√≤ il numero di gruppi diversi √®: \(\frac{5 \cdot 4 \cdot 3}{3 \cdot 2 \cdot 1} = 10\).
</p>

<p>
In generale: \(\frac{n (n-1) \cdots (n - r +1)}{r!} = \frac{n!}{(n-r)! r!} = \binom{n}{r}\)
detto <i>coefficiente binomiale</i>, numero delle <i>combinazioni</i> di \(n\) oggetti presi a gruppi di \(r\).
</p>

<p>
Esempio: si selezioni a caso un gruppo di 5 persone da un insieme di 6 uomini e 9 donne. Qual √® la probabilit√† che nel gruppo
selezionato ci siano esattamente 3 uomini e 2 donne?
</p>

<p>
Ognuna delle \(\left(\begin{smallmatrix}15\\5\end{smallmatrix}\right)\) combinazioni √® ugualmente probabile. Ci sono
\(\left(\begin{smallmatrix}6\\3\end{smallmatrix}\right)\) scelte possibili per la scelta dei 3 uomini e
\(\left(\begin{smallmatrix}9\\2\end{smallmatrix}\right)\) per la scelta delle 2 donne.
</p>

<p>
Perci√≤ la probabilit√† \(\frac{\left(\begin{smallmatrix}6\\3\end{smallmatrix}\right) \cdot \left(\begin{smallmatrix}9\\2\end{smallmatrix}\right)}{\left(\begin{smallmatrix}15\\5\end{smallmatrix}\right)}
= \frac{240}{1001}\)
</p>

<p>
Siano dati uno spazio campione \(\Omega\) ed una misura di probabilit√† \(P\) definita sul suo insieme delle parti \(\mathcal{P}(\Omega)\)
</p>

<p>
Secondo l'impostazione assiomatica di probabilit√†, considerati due eventi, \(A\) e \(B\), con \(P(B) > 0\), √® detta <i>probabilit√†
dell'evento</i> \(A\) condizionata dall'evento \(B\) la quantit√† \(P(A|B) = \frac{P(A \cap B)}{P(B)}\).
</p>

<p>
Per esempio: si consideri un lotto di produzione di transistor. 5 di questi sono difettosi immediatamente, 10 parzialmente
difettosi (non funzionano dopo un uso di 2 ore), e 25 sono accettabili. Si scelga a caso un transistor. Se non risulta
immediatamente difettoso, qual √® la probabilit√† che sia accettabile (cio√® funzioni dopo un uso di 2 ore)?
</p>

<p>
Poich√© non risulta immediatamente difettoso, non √® uno dei 5: quindi
\[ P(\text{accett.}|\text{non  immed. difet.}) = \frac{P(\text{accett.} \cap \text{non immed. difet.})}{P(\text{non immed. difet.})}
= \frac{P(\text{accett.})}{P(\text{non immed. difet.})} = \frac{\frac{25}{40}}{\frac{35}{40}} = \frac{5}{7}\]
</p>

<p>
Si riprenda in esame l'esempio degli appartamenti. Si supponga di essere interessati a determinare la probabilit√† dell'evento \(B\)
"almeno 2 appartamenti verranno venduti" sapendo con certezza che si √® verificato l'evento \(C\) "il terzo appartamento viene venduto".
</p>

<p>
In questo caso ci troviamo di fronte ad un condizionamento, infatti il verificarsi certo dell'evento \(C\) influisce sulla
possibilit√† che si verifichi anche \(B\). La nuova probabilit√† da associare a \(B\) diventa allora: \(P(B \cap C) = \frac{3}{8}\).
</p>

<p>
\[P(B|C) = \frac{P(B \cap C)}{P(C)} = \frac{P(B \cap C)}{P(C)} = \frac{\frac{3}{8}}{\frac{4}{8}} = \frac{3}{4}\]
con \(P(B) = \frac{1}{2}\) e \(P(C) = \frac{4}{8}\)
</p>

<p>
Due eventi \(A, B \in \mathcal{P}(\Omega)\) sono detti <i>stocasticamente indipendenti</i> se vale la seguente condizione: \(P(A) = P(A|B)\)
ovvero se vale \(P(B) = P(B|A)\), o ancora se \(P(A \cap B) = P(A)P(B)\).
</p>

<p>
Si continui con l'ultimo esempio: si consideri l'evento \(C\) "il terzo appartamento viene venduto" e l'evento \(D\)
"il secondo appartamento viene venduto". In base alla definizione condizionata risulta
\[ P(C|D) = \frac{P(C \cap D)}{P(D)} = \frac{\frac{2}{8}}{\frac{4}{8}} = \frac{1}{2} = P(C)\]
con \(P(C \cap D) = \frac{2}{8}\) e \(P(D) = \frac{4}{8}\), essendo \(D = \{(0, 1, 0), (1, 1, 0), (0, 1, 1), (1, 1, 1)\}\),
\(C \cap D = \{(0, 1, 1), (1, 1, 1)\}\).
</p>

<p>
Pertanto √® possibile concludere come gli eventi \(C\) e \(D\) risultino <i>stocasticamente indipendenti</i>. Infatti
varranno anche le altre relazioni collegate.
</p>

<p>
Osserviamo che l'indipendenza √® influenzata non solo dagli eventi considerati ma anche dalla particolare misura di
probabilit√† \(P\) adottata. Infatti, scelte differenti per \(P\), legate a considerazioni non matematiche, avrebbero
potuto portare ad esempio ad avere gli eventi \(C\) e \(D\) non stocasticamente indipendenti.
</p>

<p>
Si riprenda in esame l'urna con 4 palline fisicamente identiche ma di diverso colore, una rossa, due blu e una verde,
(pertanto faremo riferimento alla probabilit√† \(P'\) e non a \(P\)).
</p>

<p>
Supponiamo di estrarre in maniera casuale una pallina, e di fare poi una seconda estrazione tenendo fuori dall'urna
la pallina appena estratta (senza reimmissione). Si voglia calcolare la probabilit√† che le 2 palline estratte in questo
modo siano quelle blu.
</p>

<p>
Consideriamo gli eventi \(A_1\): "la pallina √® blu" e \(A_2\): "la seconda pallina √® blu" e calcoliamo la probabilit√† di
\(A_1 \cap A_2\) facendo uso della seguente formula: \(P'(A_1 \cap A_2) = P'(A_2|A_1) P'(A_1)\). A tal scopo si osservi che
\(P'(A_1) = \frac{1}{2}\) e \(P'(A_2|A_1) = \frac{1}{3}\). In definitiva avremo \(P'(A_1 \cap A_2) = P'(A_2|A_1) P'(A_1) = \frac{1}{2}
\frac{1}{3} = \frac{1}{6}\).
</p>

<p>
Nello stesso caso, ma <i>con reimmissione</i> della pallina pescata: \(P'(A_1 \cap A_2) = P'(A_1) P'(A_1) = \frac{1}{2}
\frac{1}{2} = \frac{1}{4}\).
</p>

<p>
La formula \(P (A \cap B) = P(A|B) P(B)\) pu√≤ essere generalizzata al caso dell'intersezione di pi√π eventi, in tal caso
prende il nome di "formula del prodotto" e diviene \(P(A_1 \cap \dots \cap A_n) = P(A_1) P(A_2|A_1) \dots P(A_n|A_1 \cap \dots \cap A_{n-1})\) ed √®
valida comunque sia scelto \(n \in \mathbb{N}_+\) e la famiglia \(\{A_i, i = 1, \dots, n\}\) di sottoinsiemi di \(\Omega\).
</p>

<p>
Torniamo all'urna e supponiamo di effettuare 3 estrazioni, senza reimmissione. Si vuole calcolare la probabilit√† che
la prima volta venga estratta una pallina blu, la seconda una rossa e la terza una verde e denotiamo questi eventi
rispettivamente con \(A_1, A_2\) e \(A_3\): \(P(A_1 \cap A_2 \cap A_3) = P(A_1) P(A_2|A_1)P(A_3|A_1 \cap A_2)\). \(P(A_1) = \frac{1}{2}\),
\(P(A_2|A_1) = \frac{1}{3}\) e \(P(A_3|A_1 \cap A_2) = \frac{1}{2}\). Quindi \(P(A_1 \cap A_2 \cap A_3) = \frac{1}{2} \frac{1}{3}
\frac{1}{2} = \frac{1}{12}\).
</p>

<p>
√à utile ricordare altre formule particolarmente importanti nel calcolo delle probabilit√†. Consideriamo una partizione
\(\{A_i, i = 1, \dots, n; A_i \subseteq \Omega\}\) dello spazio campione \(\Omega\) ovvero una famiglia di eventi <i>mutualmente incompatibili</i>
e tali che la loro unione sia \(\Omega\) stesso. La prima formula √® nota come "formula delle probabilit√† totali":
\[P(B) = \sum_{i=1}^n P(B|A_i) P(A_i)\]
</p>

<p>
Caso particolare: \(A\) e \(B\) siano eventi. \(A = (A \cap B) \cup (A \cap \bar{B})\). \((A \cap B)\) e \((A \cap \bar{B})\) sono esclusivi,
quindi:
\[ P(A) = P(A \cap B) + P(A \cap \bar{B}) = P(A|B) P(B) + P(A|\bar{B}) P(\bar{B}) = P(A|B) P(B) + P(A|\bar{B})[1 - P(B)]\]
Permette di calcolare la probabilit√† di un evento condizionando al fatto che un secondo evento si sia o meno verificato.
</p>

<p>
Per esempio, un'assicurazione decide di dividere i guidatori in 2 categorie: facili agli incidenti (\(A\)) e non facili
(\(\bar{A}\)). Le statistiche dicono che un guidatore facile agli incidenti ha probabilit√† 0.4 di fare un incidente
nell'anno mentre uno non facile agli incidenti ha probabilit√† 0.2 di fare un incidente nell'anno.
</p>

<p>
Supponiamo che il 30% dei guidatori sia facile agli incidenti, qual √® la probabilit√† che un guidatore abbia un incidente
nell'anno?
</p>

<p>
Sia \(A_1\) l'evento "il guidatore ha un incidente": \(P(A_1) = P(A_1|A) P(A) + P(A_1|\bar{A}) P(\bar{A}) = 0.4 \cdot 0.3 + 0.2 \cdot 0.7
= .26\)
</p>

<p>
Se un cliente ha effettivamente un incidente nell'anno, qual √® la probabilit√† che sia facile agli incidenti?
</p>

<p>
Si sa che inizialmente la stima della probabilit√† che fosse facile agli incidenti era 0.3. Sapendo che ha avuto un incidente,
rivalutiamo questa probabilit√† con la nuova informazione:
</p>

<p>
Dalle formule viste:
\[P(A|A_1) = \frac{P(A, A_1)}{P(A_1)} = \frac{P(A) P(A_1|A)}{P(A_1)} = \frac{(.3)(.4)}{(.26)} = .4615\]
</p>

<p>
Esempio: un laboratorio di analisi del sangue √® in grado di scoprire con probabilit√† 0.99 se una certa malattia √® presente.
C'√® per√≤ una probabilit√† di 0.01 di falso positivo (cio√® anche se la persona √® sana il test la valuta come malata).
</p>

<p>
Se la percentuale di popolazione malata √® 0.5% qual √® la probabilit√† che una persona sia effettivamente malata se viene
valutata come malata dal test?
</p>

<p>
Sia \(D\) l'evento: una persona √® malata; \(E\) l'evento: il test √® positivo (persona valutata come malata). Si deve
calcolare:
\[P(D|E) = \frac{P(D, E)}{P(E)} = \frac{P(E|D) P(D)}{P(E|\bar{D}) P(\bar{D}) + P(E|D) P(D)} =
\frac{(.99)(.005)}{(.01)(.995) + (.99)(.005)} = .3322\]
</p>

<p>
√à un caso particolare della seconda formula molto importante: la <i>formula di Bayes</i>.
</p>

<p>
La "formula di Bayes" nella forma generale per eventi \(B\) tali che \(P(B) > 0\) √® data da
\[ P(A_i|B) = \frac{P(B|A_i) P(A_i)}{\sum_{j=1}^n P(B|A_j) P(A_j)}\]
ed √® valida per ogni \(i = 1, \dots, n\).
</p>

<p>
Si osservi che anche in questo caso √® necessario richiedere che la famiglia \(\{A_i, i = 1, \dots, n; A_i \subseteq \Omega\}\)
sia una partizione dello spazio campione \(\Omega\).
</p>

<p>
Esempio: supponiamo di aver effettuato un'indagine sugli individui in et√† lavorativa abitanti in un quartiere di una
data citt√† italiana, e di aver riscontrato che il 40% di tal individui ha la licenza elementare o media, il 50% ha
un titolo di scuola superiore mentre il restante 10% √® laureato.
</p>

<p>
Una seconda indagine ha permesso di rilevare i tassi di disoccupazione tra i tre gruppi di individui che risultano
essere rispettivamente 15%, 5% e 10%.
</p>

<p>
Supponiamo ora di assegnare un numero ad onguno di tali individui e di estrarre uno dei numeri cos√¨ assegnati,
selezionando quindi in modo del tutto casuale un singolo individuo tra tutti. Si vuole determinare la
probabilit√† dell'evento \(B\) "l'individuo che verr√† estratto √® disoccupato".
</p>

<p>
Il metodo migliore per calcolare tale probabilit√† consiste nel far ricorso alla formula delle probabilit√† totali,
denotando: \(A_1\) "l'indiviudo ha la licenza elementare o media", \(A_2\) "l'individuo ha un titolo di scuola superiore",
\(A_3\) "l'individuo ha la laurea". Sfruttando l'informazione disponibile assegneremo le seguenti probabilit√†:
\(P(A_1) = 0.4, P(A_2) = 0.5, P(A_3) = 0.1\).
</p>

<p>
Inoltre, sempre in base ai risultati delle indagini avremo \(P(B|A_1) = 0.15, P(B|A_2) = 0.05, P(B|A_3) = 0.1\).
Osservando che la terna \(A_1, A_2\) ed \(A_3\) costituisce una partizione dello spazio campione si pu√≤ applicare la
formula delle probabilit√† totali ottenendo: \(P(B) = \sum_{i=1}^3 P(B|A_i) P(A_i) = 0.4 \cdot 0.15 + 0.5 \cdot 0.05 + 0.1 \cdot 0.1 = 0.095\).
</p>

<p>
Supponiamo ora di essere certi che l'individuo estratto sia un disoccupato, e di essere interessati a determinare
la probabilit√†, condizionata a tale informazione, che esso sia laureato.
</p>

<p>
Allora √® possibile far uso della Formula di Bayes, in base alla quale si ricava:
\[ P(A_3|B) = \frac{P(B|A_3) P(A_3)}{\sum_{j=1}^3 P(B|A_j) P(A_j)} = \frac{0.1 \cdot 0.1}{0.095} = 0.105\]
</p>

<p>
Delle opportune trasformazioni, chiamate "variabili aleatorie", consentono di ricondursi sempre ad \(\mathbb{R}\) come spazio
campione e di considerare quali suoi sottoinsiemi tutti gli intervalli del tipo (a, b) o [a, b] con \(-\infty \leq a < b \leq +\infty\),
tutte le possibili unioni ed intersezioni (finite o infinite), e tutti i loro complementi. Formalmente:
dato  uno spazio campione \(\Omega\), √® detta "variabile aleatoria" (o casuale) un'applicazione \(X: \Omega \to \mathbb{R}\) che associa un
numero reale ad ogni elemento di \(\Omega\).
</p>

<p>
In base a questa definizione √® possibile assegnare delle probabilit√† ad eventi del tipo \(X \in B \subseteq \mathbb{R}\) essendo
\(P(\{X \in B\}) = P(\{\omega \in \Omega | X(\omega) \in B\})\) dove \(P\) rappresenta una misura di probabilit√† definita su \(\mathcal(P)(\Omega)\).
Per comodit√† denoteremo da qui in avanti con \(P(X \in B)\) tali probabilit√†, ma ci si ricordi sempre che \(X \in B\) va pensato
come evento di \(\Omega\).
</p>

<p>
Facciamo riferimento all'esempio degli appartamenti e consideriamo lo spazio \(\Omega\) e la probabilit√† \(P\) in esso definiti.
Una variabile aleatoria che ha senso considerare in questo caso potrebbe essere la \(X :=\) "numero di appartamenti venduti
a fine anno". Formalmente essa andrebbe definita come funziona da \(\Omega\) in \(\mathbb{R}\) che assegna:
</p>
<ul class="org-ul">
<li>\(X((0, 0, 0)) = 0\)</li>
<li>\(X((0, 0, 1)) = X((0, 1, 0)) = X((1, 0, 0)) = 1\)</li>
<li>\(X((0, 1, 1)) = X((1, 1, 0)) = X((1, 0, 1)) = 2\)</li>
<li>\(X((1, 1, 1)) = 3\)</li>
</ul>

<p>
In base alla definizione della variabile casuale \(X\) che abbiamo fornito, ha senso definire la probabilit√† che
esattamente un appartamento venga venduto \(X\) = 1. Infatti, vale quanto segue:
\[ P(X=1) = P(\omega \in \Omega : X(\omega) = 1) = P(\{(0, 0, 1), (0, 1, 0), (1, 0, 0)\}) = \frac{3}{8}\]
</p>

<p>
La definizione di variabile aleatoria pu√≤ risultare poco chiara dal punto di vista intuitivo anche se per gli scopi
del corso sar√† necessario pensare alle variabili aleatorie come ad esiti esprimibili numericamente di esperimenti
ancora da effettuare, dove per esperimento intenderemo un qualsiasi fenomeno o situazione con sviluppi imprevedibili
a priori.
</p>

<p>
Come notazione adotteremo quella solitamente utilizzata in campo statistico, indicando con lettere maiuscole le
variabili aleatorie e con lettere minuscole le rispettive possibili realizzazioni.
</p>

<p>
Essendo imprevedibile a priori il valore assunto da una variabile aleatoria, tutto ci√≤ che si pu√≤ fare relativamente ad
essa √® esprimere delle valutazioni di tipo probabilistico sui valori che essa assumer√†. Per tale ragione ad ogni variabile
aleatoria \(X\) √® associata una funzione che esprime in modo chiaro tali valutazioni. Essa √® la <i>funzione di ripartizione</i>:
\[F_X : \mathbb{R} \to [0, 1] \subseteq \mathbb{R}\]
definita come \(F_X(t) = P(X \leq t)\) per ogni valore di \(t \in \mathbb{R}\).
Riconsideriamo la variabile aleatoria definita nell'esempio precedente, e determiniamone la corrispondente funzione di
ripartizione. Per questo osserviamo prima di tutto che la \(X\) pu√≤ assumere solo i valori 0, 1, 2 e 3.
Quindi sicuramente sar√† \(F_X(t) = P(X \leq t) = 0\) per \(t < 0\). Avremo poi
</p>
\begin{align*}
&F_X(t) = P(X = 0) = P(\{0, 0, 0\}) = \frac{1}{8} \text{ per } t <0\\
&F_X(t) = P(X = 0 \text{ oppure } 1) = P(\{(0, 0, 0), (1, 0, 0), (0, 1, 0), (0, 0, 1)\}) = \frac{1}{2} \text{ per } 1 \leq t \leq 2\\
&F_X(t) = P(X = 0 \text{ oppure } 1 \text{ oppure } 2) = 1 - P(X = 3) = 1 - P(\{(1, 1, 1)\}) = 1 - \frac{1}{8} = \frac{7}{8} \text{ per } 2 \leq t < 3\\
&F_X(t) = P(X = 0 \text{  oppure  } 1 \text{ oppure } 2 \text{ oppure } 3) = P(\Omega) = 1 \text{ per } t \geq 3
\end{align*}

<p>
La funzione di ripartizione risulta essere descritta dal grafico nella figura sottostante:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-14_10-05-12.png" alt="screenshot_2018-03-14_10-05-12.png" />
</p>
</div>

<p>
Una volta nota la funzione di ripartizione di una variabile aleatoria, √® possibile determinare la probabilit√† che
essa assuma valori in intervalli dell'asse reale di nostro interesse osservando che vale:
\[ P(X \in (a, b]) = F_X (b) - F_X (a) \text{ per ogni $a, b, \in \mathbb{R}$ con } a < b\]
</p>

<p>
La dimostrazione di questa uguaglianza segue dal fatto che, per ogni \(a < b\), gli eventi \(X \in (-\infty, a]\) ed \(X \in (a, b]\)
sono incompatibili e che dalla seguente propriet√†:
</p>
<ul class="org-ul">
<li>Data la famiglia \(\{A_i, i \in I \subseteq N\}\) di eventi incompatibili vale \(P\left(\bigcup_{i \in I} A_i \right) = \sum_{i \in I} P(A_i)\)
risulta \(P(\{X \in (-\infty, a]\} \cup \{X \in (a, b]\}) = P(X \in (-\infty, a]) + P(X \in (a, b])\).</li>
</ul>
<p>
Vale allora anche la seguente relazione:
\[F_X (b) = P(X \leq b) = P(\{X \in (-\infty, a]\} \cup \{X \in (a, b]\}) = P(X \in (-\infty, a]) + P(X \in (a, b]) = F_X (a) + P(X \in (a, b])\]
da cui si ricava appunto la seguente: \(P(X \in (a, b]) = F_X(b) - F_X(a)\) per ogni \(a, b \in \mathbb{R}\) con \(a < b\).
</p>

<p>
Per esempio, si voglia determinare la probabilit√† che la variabile aleatoria introdotta negli esempi precedenti assuma
valori in [1, 2]. Si osservi innanzitutto che in base alla seguente relazione:
</p>
<ul class="org-ul">
<li>Per ogni \(A, B \subseteq \Omega\) anche non incompatibili, vale \(P(A \cup B) = P(A) + P(B) - P(A \cap B)\) vale nel caso specifico
la seguente relazione \(P(X \in [1, 2]) = P(X = 1) + P(X \in (1, 2])\) essendo \(X=1\) ed \(X \in (1, 2]\) eventi incompatibili.</li>
</ul>

<p>
Da cui segue che \(P(X \in [1, 2]) = P(X = 1) + P(X \in (1, 2]) = \frac{3}{8} + [F_X(2) - F_X(1)] = \frac{3}{8} + \left[
\frac{7}{8} - \frac{1}{2} \right] = \frac{3}{4}\):
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-14_11-40-34.png" alt="screenshot_2018-03-14_11-40-34.png" />
</p>
</div>

<p>
Notiamo per√≤ che in genere la funzione di ripartizione di una variabile aleatoria non √® nota; obiettivo della
statistica √® quello di determinarla o di determinare grandezze ad essa associate, mentre nella probabilit√† e
nelle sue applicazioni si assume che essa sia nota.
</p>

<p>
√à possibile dimostrare che sono delle funzioni di ripartizione tutte e sole le funzioni \(F: \mathbb{R} \to [0, 1]\) che
godono simultaneamente delle seguenti propriet√†:
</p>
<ul class="org-ul">
<li>\(F\) √® monotona non decrescente;</li>
<li>\(\lim_{t \to +\infty} F(t) = 1\);</li>
<li>\(\lim_{t \to -\infty} F(t) = 0\);</li>
<li>\(\lim_{t \to t_0^+} F(t) = F(t_0)\) per ogni \(t_0 \in \mathbb{R}\).</li>
</ul>

<p>
Per esempio, immaginiamo di essere interessati ad effettuare delle valutazioni sul tasso di inflazione \(X\) che vi sar√†
alla fine dell'anno. Poich√© al momento attuale non √® noto il valore che assumer√† \(X\), possiamo pensare ad esso come
ad una variabile aleatoria. Un economista contattato, in proposito afferma, in base alle sue considerazioni, che
\(X\) √® una variabile avente <i>funzione di ripartizione</i> definita come segue:
</p>
\begin{equation*}
F_X (t) =
\begin{cases}
0 \quad &\text{per $t < 0$}\\
1-e^{-t} \quad &\text{per $t \geq 0$}
\end{cases}
\end{equation*}
<p>
Il grafico dell'andamento di tale funzione √® riportato nella figura sottostante:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-14_12-08-28.png" alt="screenshot_2018-03-14_12-08-28.png" />
</p>
</div>

<p>
√à facile verificare che la funzione \(F_X(t)\) cos√¨ soddisfa le condizioni richieste, e pertanto risulta effettivamente una
funzione di ripartizione.
</p>

<p>
Supponiamo di essere ora interessati a determinare la probabilit√† che tale tasso sia compreso nell'intervallo \((1, 2]\), a
tal scopo sar√† sufficiente applicare la seguente formula: \(P(X \in (a, b]) = F_X(b) - F_X(a)\) per ogni \(a, b \in \mathbb{R}\) con \(a < b\),
che nel caso in questione diviene \(P(X \in (1, 2])\) = F<sub>X</sub>(2) - F<sub>X</sub>(1) e dalla cui applicazione si ricava
\[P(X \in (1, 2]) = F_X(2) - F_X(1) = (1 - e^{-2}) - (1-e^{-1}) = 0.865 - 0.632 = 0.233\]
</p>

<p>
Si osservi che la relazione \(P(X \in (a, b]) = F_X(b) - F_X(a)\) per ogni \(a, b \in \mathbb{R}\) con \(a < b\) pu√≤ essere utilizzata
anche se desideriamo calcolare la probabilit√† che il tasso sia strettamente maggiore di 2, infatti averemo quanto segue:
\[P(X \in (2, +\infty]) = \lim_{t \to +\infty} F_X(t) - F_X(2) = 1 - (1 - e^{-2}) = 0.135\]
Si pu√≤ inoltre osservare che le funzioni di ripartizione considerate negli ultimi 2 esempi, sebbene entrambe soddisfino
tutte le propriet√†, presentano una significativa differenza:
</p>
<ul class="org-ul">
<li>La prima non √® una funzione continua su \(\mathbb{R}\);</li>
<li>La seconda √® una funzione continua su \(\mathbb{R}\).</li>
</ul>

<p>
In effetti le variabili aleatorie si distinguono in due categorie in base alla propriet√† di continuit√† delle corrispondenti
funzioni di ripartizione:
</p>
<ul class="org-ul">
<li><p>
Variabile aleatoria <i>discreta</i>: l'insieme dei valori \(S\) che essa pu√≤ assumere (supporto) √® finito o costituito da
un'infinit√† di valori discreti. Ad ogni variabile aleatoria discreta √® associabile, oltre alla funzione di ripartizione,
una seconda funzione che fornisce delle valutazioni sulle probabilit√† che essa assuma specifici valori.
</p>

<p>
Sia \(S\) il supporto della variabile aleatoria discreta \(X\). Viene detta <i>distribuzione discreta di probabilit√†</i> la funzione
\(p_x : \mathbb{R} \to [0, 1]\) definita come segue:
</p>
\begin{equation*}
p_x(t) =
\begin{cases}
P(X=t) \quad &\text{per ogni $t \in S$}\\
0 \quad &\text{altrimenti}
\end{cases}
\end{equation*}
<p>
Come per le funzioni di ripartizione, esistono alcune propriet√† che identificano le distribuzioni discrete di probabilit√†.
Infatti, una funzione \(p_x\) definita su un insieme finito \(S\) √® una distribuzione di probabilit√† se e solo se sono
soddisfatte simultaneamente le seguenti propriet√†:
</p>
<ul class="org-ul">
<li>\(p_x (t) \geq 0, t \in \mathbb{R}\);</li>
<li>\(\sum_{s \in S} p_x(s) = 1\).</li>
</ul>
<p>
Si osservi che la seconda delle due propriet√† √® conseguenza diretta delle due seguenti propriet√† precedentemente introdotte:
</p>
<ul class="org-ul">
<li>\(P(\Omega) = 1\);</li>
<li>Data la famiglia \(\{A_i, i \in I \subseteq N\}\) di eventi incompatibili vale \(P\left(\bigcup_{i \in I} A_i \right) = \sum_{p \in I} P(A_i)\).</li>
</ul>
<p>
Tra le funzioni di ripartizione delle variabili discrete e le distribuzioni discrete di probabilit√† esiste una corrispondeza
biunivoca. Infatti, valgono le seguenti relazioni:
</p>
<ul class="org-ul">
<li>\(F_X(t) = \sum_{s \in S : s \leq t} p_x(s)\) per ogni \(t \in \mathbb{R}\);</li>
<li>\(p_X(s) = F_X(s) - \lim_{t \to s^-} F_X(t)\) per ogni \(s \in S\).</li>
</ul>
<p>
Dalla prima di tali relazioni se ne deduce che le funzioni di ripartizione delle variabili aleatorie discrete presentano dei
"salti" in corrispondenza dei valori \(s\), mentre sono costanti per gli altri valori: per tale ragione vengono dette
<i>funzioni a gradino</i>.
</p>

<p>
Per esempio si consideri la variabile aleatoria definita negli esempi relativi agli appartamenti. Essa √® discreta in
quanto pu√≤ assumere i seguenti valori \(S = \{0, 1, 2, 3\}\). La sua distribuzione discreta di probabilit√† pu√≤ essere
definita facendo uso o della seguente relazione:
\[ p_X(s) = F_X(s) - \lim_{t \to s^-} F_X(t) \quad \text{per ogni } s \in S\]
considerando la funzione di ripartizione calcolata precedentemente, oppure direttamente andando a calcolare la
probabilit√† che \(X\) assuma i singoli valori in \(S\) facendo uso della seguente relazione:
</p>
\begin{equation*}
p_x(t) =
\begin{cases}
P(X=t) \quad &\text{per ogni $t \in S$}\\
0 \quad &\text{altrimenti}
\end{cases}
\end{equation*}</li>
</ul>

<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-14_12-41-38.png" alt="screenshot_2018-03-14_12-41-38.png" />
</p>
</div>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-14_12-43-10.png" alt="screenshot_2018-03-14_12-43-10.png" />
</p>
</div>
<ul class="org-ul">
<li><p>
Variabile aleatoria <i>continua</i>: la corrispondente funzione \(F_X\) √® continua. In particolare, √® detta
<i>assolutamente continua</i> se esiste una funzione \(f_X : \mathbb{R} \to \mathbb{R}_+\) tale che
\(F_X(t) = \int_{-\infty}^t f_X(u)du\) per ogni \(t \in \mathbb{R}\). Una tale funzione, quando esiste, viene detta <i>densit√† di
probabilit√†</i> di \(X\). √à detto poi <i>supporto</i> della variabile \(X\) l'insieme \(S = \{t \in \mathbb{R} : f_X(t) \neq 0\}\).
Si osservi che se la densit√† di probabilit√† di una variabile casuale esiste allora la funzione di ripartizione
√® una sua primitiva.
</p>

<p>
Per semplicit√† supporremo nel seguito che le variabili aleatorie assolutamente continue abbiano funzione di
ripartizione derivabile e che la funzione di densit√† di probabilit√† sia la derivata della funzione di ripartizione.
</p>

<p>
Come per le distribuzioni discrete di probabilit√† anche le funzioni di densit√† di probabilit√† per essere tali
devono soddisfare le seguenti due propriet√†:
</p>
<ul class="org-ul">
<li>\(f_X(t) \geq 0\) per ogni \(t \in \mathbb{R}\);</li>
<li>\(\int_{-\infty}^{+\infty} f_X(t)dt = 1\)</li>
</ul>

<p>
La probabilit√† che una variabile aleatoria continua (o assolutamente continua) assuma un ben determinato valore √®
sempre nulla. Infatti, se \(X\) √® una variabile aleatoria continua allora per ogni \(t_0 \in \mathbb{R}\) vale:
\[P(X = t_0) = P(X \leq t_0) - \lim_{t \to t_0^-} P(X \leq t) = F_X(t_0) - \lim_{t \to t_0^-} F_X(t) = F_X(t_0) - F_X(t_0) = 0\]
Pertanto quando si pensa a variabili aleatorie continue, non ha mai senso domandarsi, quale sia la probabilit√†
che assumano valori esatti. Al contrario ha senso domandarsi quale sia la probabilit√† che tali variabili
assumano valori in specifici intervalli dell'asse reale.
</p>

<p>
Per calcolare la probabilit√† che una variabile casuale continua \(X\) assuma un valore in un intervallo \((a, b] \subseteq \mathbb{R}\)
√® possibile far ricorso alla seguente formula: \(P(X \in (a, b]) = F_X(b) - F_X(a)\) per ogni \(a, b \in \mathbb{R}\) con \(a < b\), oppure
alla seguente formula: \(P(X \in (a, b]) = \int_a^b f_X(u)du\) per ogni \(a, b \in \mathbb{R}\) con \(a < b\). La quale √® ricavabile dalla
precedente combinata con la seguente \(F_X(t) = \int_{-\infty}^t f_X(u)du\) per ogni \(t \in \mathbb{R}\).
</p>

<p>
√à utile segnalare che \(P(X \in (a, b]) = F_X(b) - F_X(a) = \int_{-\infty}^b f_x(u)du - \int_{-\infty}^a f_x(u)du = \int_a^b f_x(u)du\).
</p>

<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-14_14-40-36.png" alt="screenshot_2018-03-14_14-40-36.png" />
</p>
</div>

<p>
Essendo \(P(X=a) = 0\) risulta sempre \(P(X \in [a, b]) = P(X \in (a, b])\) per ogni \(a, b \in \mathbb{R}\) con \(a < b\).
</p></li>
</ul>

<p>
Si consideri la variabile aleatoria \(X\) introdotta nell'esempio precedente. Essa √® continua in quanto la sua funzione
di densit√† di probabilit√†, ottenuta derivando la ripartizione, √® data da:
</p>
\begin{equation*}
f_X(t) =
\begin{cases}
0 \quad &\text{per $t < 0$}\\
e^{-t} \quad &\text{per $t \geq 0$}
\end{cases}
\end{equation*}
<p>
In realt√† √® possibile osservare che la funzione di ripartizione non √® derivabile in 0 e pertanto la scelta di porre la sua
derivata pari a \(f_X(0) = e^{-0} = 1\) in quel punto √® arbitraria, anche se non influenza in alcun modo le valutazioni sulla
variabile considerata \(X\).
</p>

<p>
Calcoliamo la probabilit√† che \(X\) assuma valori in \([1, 2]\) facendo ricorso ala formula
\(P(X \in (a, b]) = \int_a^b f_X(u)du\) per ogni \(a, b\), con \(a < b\), ottenendo
\[P(X \in [1, 2]) = P(X = 1) + \int_1^2 f_X(u)du = 0 + \int_1^2 e^{-u} du = 0 - e^{-2} + e^{-1} = 0.233\]
</p>

<p>
La funzione di ripartizione √® la funzione integrale della funzione di densit√† di probabilit√†. Quindi, data la funzione
di partizione, si ottiene la funzione di densit√† di probabilit√† tramite derivazione \(\frac{d}{dt} F_X(t) = f_X(t)\).
</p>

<p>
In molti casi √® lecito considerare situazioni (esperimenti) il cui esito √® rappresentato, anzich√© da un valore numerico,
da una coppia o da una \(n\)-pla di valori; si pensi ad esempio alla coppia costi-ricavi in un investimento immobiliare.
Si parla allora di <i>variabili aleatorie multidimensionali</i>.
</p>

<p>
In modo analogo a quanto visto per le variabili unidimensionali, le variabili di tal tipo sono definite come applicazioni
da uno spazio campione \(\Omega\) allo spazio \(\mathbb{R}^n\) dove \(n\) √® la dimensione della variabile. Come per le variabili aleatorie
unidimensionali, conviene pensare a queste variabili aleatorie come a risultati di esperimenti esprimibili tramite
\(n\)-ple di valori numerici. Anche in questo caso √® consuetudine considerare funzioni che esprimano le valutazioni
probabilistiche sui valori assumibili delle variabili.
</p>

<p>
Per il momento definiremo tali funzioni limitandoci a considerare <i>variabili aleatorie bidimensionali assolutamente
continue</i> anche se quanto descritto in seguito pu√≤ essere facilmente esteso al caso di pi√π dimensioni e non
necessariamente continuo.
</p>

<p>
Sia quindi \((X;Y): \Omega \to \mathbb{R}^2\) una variabile aleatoria bidimensionale dove \(\Omega\) √® uno spazio campione al quale √® associata
una probabilit√† \(P\) definita sui sottoinsiemi di \(\Omega\).
</p>

<p>
√à detta <i>funzione di ripartizione congiunta</i> la funzione bidimensionale \(F_{X, Y} (t, s) : \mathbb{R}^2 \to [0, 1] \subseteq \mathbb{R}\)
definita come \(F_{X, Y}(t, s) = P(\{X \leq t\} \cap \{Y \leq s\})\) per ogni \((t, s) \in \mathbb{R}^2\).
</p>

<p>
Se, come qui assunto, la variabile \((X;Y)\) √® assolutamente continua, allora esiste la <i>funzione di densit√† congiunta</i>
\(F_{X, Y} : \mathbb{R}^2 \to \mathbb{R}_+\) tale che
\(F_{X, Y}(t, s) = \int_{-\infty}^t \int_{-\infty}^s f_{X, Y} (u, v)du dv\) per ogni \((t, s) \in \mathbb{R}^2\).
</p>

<p>
Conoscendo la funzione di ripartizione congiunta o quella di densit√† congiunta √® possibile determinare la probabilit√†
che la coppia \((X;Y)\) assuma valori in un qualsiasi sottoinsieme rettangolare \((a_1, b_1] \times (a_2, b_2] \in \mathbb{R}^2\).
</p>

<p>
Infatti, valgono le seguenti formule:
</p>
<ul class="org-ul">
<li>\(P((X, Y) \in (a_1, b_1] \times (a_2, b_2]) = F_{X, Y}(b_1, b_2) - F_{X, Y}(a_1, b_2) - F_{X, Y}(b_1, a_2) + F_{X, Y}(a_1, a_2)\)</li>
<li>\(P((X, Y) \in (a_1, b_1] \times (a_2, b_2]) = \int_{a_1}^{b_1} \int_{a_2}^{b_2} f_{X, Y} (u, v) du dv\)</li>
</ul>
<p>
per ogni \((a_1, b_1] \times (a_2, b_2] \in \mathbb{R}^2\).
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-14_15-11-47.png" alt="screenshot_2018-03-14_15-11-47.png" />
</p>
</div>

<p>
In molti casi, bench√© ci si trovi di fronte a situazioni i cui esiti sono di tipo multidimensionali, capita di essere
interessati ai valori che possono essere assunti solamente da una delle variabili (si √® interessati a valutare probabilit√†
associate a solo uno dei valori numerici che descrivono l'esito dell'esperimento). Per questo motivo sono state introdotto
le <i>funzioni marginali</i>. Anche per la loro descrizione ci limitiamo al caso bidimensionale. Data una variabile aleatoria
bidimensionale \((X;Y)\) assolutamente continua, avente funzione di ripartizione congiunta \(F_{X, Y}\) e funzione di densit√†
congiunta \(f_{X, Y}\) sono dette <i>funzione di ripartizione marginale di \(X\)</i> e <i>funzione di densit√† marginale di \(X\)</i>:
\[F_X(t) = P(X \leq t) = P(\{X \leq t\} \cap \{Y \leq +\infty\}) = F_{X, Y}(t, +\infty)\]
\[f_X(t) = \int_{-\infty}^{+\infty} f_{X, Y}(t, s)ds\]
</p>

<p>
Concludiamo questa parte introducendo la nozione di indipendenza tra variabili aleatorie. Data una variabile aleatoria
bidimensionale (\(X;Y\)) diciamo che due variabili \(X\) ed \(Y\) considerate singolarmente sono <i>stocasticamente
indipendenti</i> se e solo se per ogni \((t, s) \in \mathbb{R}^2\) vale \(F_{X, Y}(t, s) = F_X(t) \cdot F_Y(s)\). √à possibile verificare
che tale condizione √® equivalente alla seguente: \(P(\{X \in A\} \cap \{Y \in B\}) = P(X \in A) \cdot P(Y \in B)\) per ogni \(A, B \subseteq \mathbb{R}\)
e che questa √® a sua volta equivalente alla seguente \(f_{X, Y}(t, s) = f_X(t) \cdot f_Y(s)\) per ogni coppia \((t, s) \in \mathbb{R}^2\)
quando la coppia di variabili \((X, Y)\) sia assolutamente continua.
</p>

<p>
Nell'esempio che segue esaminiamo una variabile aleatoria bidimensionale discreta.
</p>

<p>
Supponiamo di dover lanciare un dato equilibrato e di essere interessati agli eventi \(A\) "esce un numero pari" e \(B\)
"esce un numero minore o uguale a 4". Al fine di esplicitare il fatto che questi eventi si verifichino lanciando il dado,
consideriamo la coppia di variabili \((X, Y)\) dove:
</p>
\begin{equation*}
X :=
\begin{cases}
1 \quad &\text{se l'evento $A$ si verifica}\\
0 \quad &\text{se l'evento $A$ non si verifica}
\end{cases}
\end{equation*}
\begin{equation*}
Y :=
\begin{cases}
1 \quad &\text{se l'evento $B$ si verifica}\\
0 \quad &\text{se l'evento $B$ non si verifica}
\end{cases}
\end{equation*}
<p>
Poich√© le due variabili dipendono dallo stesso esperimento √® logico studiarle congiuntamente. Come prima cosa potremmo
determinarne la funzione di ripartizione congiunta.
</p>

<p>
In realt√† per√≤ quando si abbia a che fare con variabili multidimensionali discrete si preferesce considerare la
distribuzione di probabilit√† congiunta definita come \(P_{X, Y}(t, s) = P(\{X = t\} \cap \{Y = s\})\) dove \((t, s)\) √® una
coppia di valori assumibili da \((X, Y)\).
Osserviamo ora che al variare del risultato del lancio del dado la coppia \((X, Y)\) assume i seguenti valori
</p>
\begin{equation*}
(X, Y) =
\begin{cases}
(0, 0) \quad &\text{se esito 5}\\
(0, 1) \quad &\text{se esito 1 oppure 3}\\
(1, 0) \quad &\text{se esito 6}\\
(1, 1) \quad &\text{se esito 2 oppure 4}
\end{cases}
\end{equation*}
<p>
Supponendo che il dado sia equilibrato sar√† lecito attribuire le seguenti probabilit√†:
</p>
<ul class="org-ul">
<li>\(p_{X, Y}(0, 0) = P(\text{"esito 5"}) = \frac{1}{6}\)</li>
<li>\(p_{X, Y}(0, 1) = P(\text{"esito 1 o 3"}) = \frac{2}{6}\)</li>
<li>\(p_{X, Y}(1, 0) = P(\text{"esito 6"}) = \frac{1}{6}\)</li>
<li>\(p_{X, Y}(1, 1) = P(\text{"esito 2 o 4"}) = \frac{2}{6}\)</li>
</ul>
<p>
Calcoliamo ora le probabilit√† marginali della coppia \((X, Y)\) ottenendo
</p>
<ul class="org-ul">
<li>\(p_X(0) = P(\{X = 0\} \cap \{Y \text{ qualsiasi}\}) = p_{X, Y}(0, 0) + p_{X, Y}(0, 1) = \frac{1}{2}\)</li>
<li>\(p_X(1) = P(\{X = 1\} \cap \{Y \text{ qualsiasi}\}) = p_{X, Y}(1, 0) + P_{X, Y}(1, 1) = \frac{1}{2}\)</li>
<li>\(p_Y(0) = P(\{X \text{ qualsiasi}\} \cap \{Y = 0\}) = p_{X, Y}(0, 0) + p_{X, Y}(1, 0) = \frac{1}{3}\)</li>
<li>\(p_Y(0) = P(\{X \text{ qualsiasi}\} \cap \{Y = 1\}) = p_{X, Y}(0, 1) + p_{X, Y}(1, 1) = \frac{2}{3}\)</li>
</ul>
<p>
Le due variabili aleatorie \(X\) ed \(Y\) risultano essere stocasticamente indipendenti, infatti risulta:
</p>
<ul class="org-ul">
<li>\(p_{X, Y} (0, 0) = \frac{1}{6} = \frac{1}{2} \cdot \frac{1}{3} = p_X(0) \cdot p_Y(0)\)</li>
<li>\(p_{X, Y}(0, 1) = \frac{2}{6} = \frac{1}{2} \cdot \frac{2}{3} = p_X(0) \cdot p_Y(1)\)</li>
<li>\(p_{X, Y} (1, 0) = \frac{1}{6} = \frac{1}{2} \cdot \frac{1}{3} = p_X(1) \cdot p_Y(0)\)</li>
<li>\(p_{X, Y}(1, 1) = \frac{2}{6} = \frac{1}{2} \cdot \frac{2}{3} = p_X(1) \cdot p_Y(1)\)</li>
</ul>

<p>
Gli indici di tendenza centrare e la variabilit√† sono grandezze numeriche associate alle variabili aleatorie
in grado di sintetizzare, con un solo valore, le principali caratteristiche delle loro distribuzioni.
Risultano strettamente legati agli indici introdotti nella prima parte in relazione alla statistica descrittiva.
</p>

<p>
Il pi√π importante degli <i>indici di tendenza centrale</i> √® il <i>valore atteso</i>, corrispondente alla media matematica
dei dati statistici. Data una variabile aleatoria unidimensionale \(X\) con supporto \(S \subseteq \mathbb{R}\) √® detto
<i>valore atteso</i> di \(X\) la quantit√†
</p>
\begin{equation*}
E[X] =
\begin{cases}
\sum_{s \in S} s \cdot p_X(s) \quad &\text{se $X$ √® discreta}\\
\int_{-\infty}^{+\infty} u \cdot f_X(u)du \quad &\text{se $X$ √® assolutamente continua}
\end{cases}
\end{equation*}
<p>
Si osservi l'analogia di questa formula con quella della media pesata di una serie di dati statistici.
In effetti il valore atteso, cos√¨ come la media di una serie di dati, va pensato come una "media pesata" dei
valori assumibili dalla variabile, e fornisce un'indicazione di massima del posizionamento delle variabili
lungo l'asse dei numeri reali.
</p>

<p>
Il valore atteso gode delle seguenti tre propriet√†:
</p>
<ol class="org-ol">
<li>Per ogni \(a \in \mathbb{R}\), se \(X=a\) con probabilit√† uguale ad 1 allora \(E[x] = a\);</li>
<li>\(E[a \cdot X + b] = a \cdot E[x] + b\) per ogni variabile \(X\) e per ogni \(a, b, \in \mathbb{R}\);</li>
<li>Data una funzione \(y = g(X)\) della variabile aleatoria \(X\), il suo valore atteso √® \(E[g(X)] = \int_{-\infty}^{+\infty} g(u) f_X(u) du\)</li>
</ol>
<p>
Occorre osservare che il valore atteso di una variabile potrebbe anche non esistere, poich√© esso √® definito come
integrale improprio.
Questa situazione pu√≤ verificarsi nel caso in cui l'integrale o la sommatoria non convergano.
</p>

<p>
Il valore atteso √® in realt√† un caso particolare di momento centrale, per ogni \(r = 1, 2, \dots\) √® detto <i>momento centrale
di \(X\) di ordine \(r\)</i> la quantit√†
</p>
\begin{equation*}
E[X^r] =
\begin{cases}
\sum_{s \in S} s^r \cdot p_X(s) \quad &\text{se $X$ √® discreta}\\
\int_{-\infty}^{+\infty} u^r \cdot f_X(u)du \quad &\text{se $X$ √® assolutamente continua}
\end{cases}
\end{equation*}
<p>
Un secondo indice di tendenza centrale che occorre descrivere √® la moda.
</p>

<p>
Data una variabile aleatoria \(X\) √® detta <i>moda</i> una quantit√≤ \(\tilde{X} \in \mathbb{R}\) corrispondente al valore per
cui √® massima la distribuzione discreta di probabilit√† (se \(X\) √® discreta) oppure la funzione di densit√† (se \(X\)
√® assolutamente continua).
</p>

<p>
Non √® detto che un tale valore sia unico, se lo √® diremo che la distribuzione di \(X\) √® <i>unimodale</i>, in caso contrario
si parler√† di distribuzione <i>multimodale</i>. Pu√≤ capitare in alcuni casi che la distribuzione discreta di probabilit√† o la
funzione di densit√† presentino diversi punti di massimo locale. Sebbene ci√≤ non sarebbe formalmente corretto, tutti
questi punti di massimo locale vengono solitamente considerati come punti modali e pertanto anche in questo caso si
parla di distribuzione multimodale.
</p>

<p>
Un terzo indice di tendenza centrale √® la <i>mediana</i>. Data una variabile aleatoria \(X\) diciamo mediana una quantit√†
\(\hat{X} \in \mathbb{R}\) che soddisfa la diseguaglianza \(\lim_{t \to \hat{X}^-} F_X(t) \leq \frac{1}{2} \leq F_X (\hat{X})\).
</p>

<p>
Nel caso in cui la funzione di ripartizione della variabile sia continua ed invertibile allora \(\hat{X} = F_X^{-1}(0.5)\).
</p>

<p>
Nel caso di variabili discrete invece la mediana √® il valore dell'ascissa in cui la funzione di ripartizione passa
da un valore minore di 0.5 ad uno superiore.
</p>

<p>
Pi√π semplicemente √® possibile pensare alla mediana come a quel valore
per cui sia la probabilit√† che \(X\) assuma valori pi√π piccoli che la probabilit√† che \(X\) assuma valori pi√π grandi
sono pari a 0.5.
</p>

<p>
La mediana pu√≤ non essere unica e ci√≤ si verifica quando esistano pi√π valori \(t\) per i quali risulti \(F_X(t) = \frac{1}{2}\).
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-14_16-28-48.png" alt="screenshot_2018-03-14_16-28-48.png" />
</p>
</div>

<p>
Unitamente alla mediana √® possibile considerare altri indici definiti in maniera simile e che dividono la retta
dei reali in due intervalli di probabilit√† assegnata e che sono detti "quantili". Dato un valore
\(p \in [0, 1] \subseteq \mathbb{R}\) √® detto <i>quantile \(p\)-esimo della variabile aleatoria \(X\)</i> il valore
\(x_p \in \mathbb{R} : \lim_{t \to x_p^-}F_X(t) \leq p \leq F_X(x_p)\). Nel caso in cui la funzione di ripartizione sia continua ed
invertibile allora \(x_p = F_X^{-1}(p)\).
</p>

<p>
Pertanto √® possibile pensare ad \(x_p\) come a quel valore per cui risulta \(P(X \leq x_p) = p\) e \(P(X > x_p) = 1 - p\).
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-14_17-22-18.png" alt="screenshot_2018-03-14_17-22-18.png" />
</p>
</div>

<p>
Supponiamo di avere a disposizione 2 appartamenti da vendere entro la fine dell'anno e supponiamo che la
vendita di ciascuno di essi sia indipendente dalla vendit√† dell'altro. Supponiamo inoltre di sapere, in base alla nostra
esperienza, che le probabilit√† di vendere i due appartementi nel tempo prefissato siano 3/4 e 2/3.
</p>

<p>
Consideriamo la variabile aleatoria \(X\) "numero di appartamenti venduti a fine anno". Essa √® una variabile discreta per
il cui computo della distribuzione di probabilit√† conviene considerare i seguenti eventi: \(A\) "il primo alloggio viene
venduto" e \(B\) "il secondo alloggio viene venduto".
</p>

<p>
Osservando che in base a quanto affermato in precedenza avremo \(P(A) = \frac{3}{4}\), \(P(\bar{A}) = \frac{1}{4}\),
\(P(B) = \frac{2}{3}\) e \(P(\bar{B}) = \frac{1}{3}\) si ricava immediatamente:
</p>
<ul class="org-ul">
<li>\(p_X(0) = P(\bar{A} \cap \bar{B}) = P(\bar{a}) \cdot P(\bar{B}) = \frac{1}{12}\);</li>
<li>\(p_X(1) = P(\{\bar{A} \cap B\} \cup \{A \cap \bar{B}\}) = P(\{\bar{A} \cap B\}) + P(\{A \cap \bar{B}\}) = P(\bar{A}) \cdot P(B) + P(A) \cdot P(\bar{B})
  = \frac{5}{12}\);</li>
<li>\(p_X(2) = P(A \cap B) = P(A) \cdot P(B) = \frac{6}{12}\).</li>
</ul>
<p>
Possiamo determinare facilmente sia il valore atteso \(E[X] = \sum_{s \in S} s \cdot p_X(s) = 0 \cdot p_X(0) + 1 \cdot p_X(1) + 2 \cdot p_X(2) =
0 \cdot \frac{1}{12} + 1 \cdot \frac{5}{12} + 2 \cdot \frac{6}{12} = 1.416\)
che la moda per la variabile \(X\): \(\tilde{X} = 2\). Il calcolo della mediana richiede la determinazione preventiva della
funzione di ripartizione.
</p>

<p>
Tale funzione pu√≤ essere calcolata per mezzo della distribuzione di probabilit√† e sar√†:
</p>
\begin{equation*}
F_X(t) =
\begin{cases}
0 \quad &\text{per $t < 0$}\\
\frac{1}{12} \quad &\text{per $0 \leq t < 1$}\\
\frac{1}{2} \quad &\text{per $1 \leq t < 2$}\\
1 \quad &\text{per $t \geq 2$}
\end{cases}
\end{equation*}
<p>
Il grafico della funzione di ripartizione √® riportato in seguito:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-14_17-38-00.png" alt="screenshot_2018-03-14_17-38-00.png" />
</p>
</div>

<p>
Dal grafico √® possibile osservare che tutti i valori \(t \in [1, 2)\) sono mediane, infatti per ognuno di tali valori si ha che
\(P(X \leq t) = \frac{1}{2}\) e \(P(X \geq t) = \frac{1}{2}\).
</p>

<p>
Consideriamo la variabile assolutamente continua \(X\) gi√† vista avente funzione di densit√† di probabilit√† data da
</p>
\begin{equation*}
f_X (t) =
\begin{cases}
0 \quad &\text{per $t < 0$}\\
e^{-t} \quad &\text{per $t \geq 0$}
\end{cases}
\end{equation*}
<p>
e funzione di ripartizione data da
</p>
\begin{equation*}
F_X (t) =
\begin{cases}
0 \quad &\text{per $t < 0$}\\
1-e^{-t} \quad &\text{per $t \geq 0$}
\end{cases}
\end{equation*}
<p>
Per questa variabile si ricavano immediatamente il valore atteso \(E[X] = \int_{-\infty}^{+\infty} t \cdot f_X(t)dt = \int_0^{+\infty} t \cdot e^{-t}dt = \lim_{b \to +\infty}|-e^{-t}(t+1)|_0^b = 1\),
la mediana \(\bar{X} = F_X^{-1}(0.5) = - \log 0.5 = 0.693\) ed infine la moda \(\tilde{X} = 0\) essendo questo
il punto di massimo della funzione di densit√† di probabilit√†.
</p>

<p>
Per misurare il grado di dispersione dei valori assumibili da una variabile aleatoria vengono usati gli <i>indici di
variabilit√†</i>. Tra questi quello che risulta in assoluto il pi√π importante √® senza dubbio la <i>varianza</i>. Formalmente,
data una variabile aleatoria \(X\) √® detta <i>varianza</i> di \(X\) la quantit√†
</p>
\begin{equation*}
V[X] =
\begin{cases}
\sum_{s \in S}(s - E[X])^2 p_X(s) \quad &\text{se $X$ √® discreta}\\
\int_{-\infty}^{+\infty}(u - E[X])^2 f_X(u)du \quad &\text{se $X$ √® assolutamente continua}
\end{cases}
\end{equation*}
<p>
Cos√¨ come il valore atteso anche la varianza talvolta pu√≤ non esistere, quando la sommatoria o l'integrale divergono.
</p>

<p>
Cos√¨ come il valore atteso di una variabile aleatoria \(X\) viene spesso indicato con \(\mu_x\) la <i>varianza</i> viene sovente indicata
\(\sigma_X^2\). Essa viene indicata con il quadrato in quanto la sua radice √® un altro indice molto importante chiamato
<i>deviazione standard</i> \(\sigma_X = \sqrt{\sigma_X^2}\). La deviazione standard ha il vantaggio rispetto alla varianza di avere la stessa
unit√† di misura del valore atteso.
</p>

<p>
Anche la varianza gode di alcune propriet√† che √® meglio ricordare:
</p>
<ul class="org-ul">
<li>Per ogni \(a \in \mathbb{R}\), se \(X = a\) con probabilit√† uguale ad 1 allora \(V[X] = 0\);</li>
<li>\(V[a \cdot X + b] = a^2 \cdot V[X]\) per ogni variabile \(X\) e per ogni \(a, b \in \mathbb{R}\);</li>
<li>\(V[X] = E[X^2] - (E[X])^2\) per ogni variabile aleatoria \(X\).</li>
</ul>

<p>
Consideriamo la variabile aleatoria descritta nell'esempio dei 2 appartamenti. Possiamo determinare la varianza o tramite la
definizione stessa o tramite la seguente propriet√†: \(V[X] = E[X^2] - (E[X])^2\) per ogni variabile aleatoria \(X\).
</p>

<p>
In generale risulta pi√π comodo utilizzare la propriet√† sopra riportate cos√¨ come faremo di seguito pertanto determiniamo
il momento centrale di ordine 2 della variabile \(X\).
\[E[X^2] = 0^2 \cdot p_X (0) + 1^2 \cdot p_X (1) + 2^2 \cdot p_X (2) = 0^2 \cdot \frac{1}{12} + 1^2 \cdot \frac{5}{12} + 2^2 \cdot \frac{6}{12} = \frac{29}{12}\]
La varianza risulta quindi essere \(V[X] = E[X^2] - (E[X])^2 = \frac{29}{12} - (1.416)^2 = 0.42\) mentre la deviazione standard
√® \(\sigma_X = \sqrt{0.42} = 0.65\).
</p>

<p>
Consideriamo la variabile aleatoria \(X\) descritta precedentemente. Calcoliamone la varianza:
\[V[X] = E[X^2] - (E[X])^2 = \int_0^{+\infty} t^2 \cdot e^{-t} dt - 1^2 = \lim_{b \to +\infty}|-e^{-t}(t^2 + 2t + 2)|_0^b - 1= 2 - 1 = 1\]
inoltre la deviazione standard √® \(\sigma_X = \sqrt{1} = 1\) ed √® pertanto maggiore di quella dell'esempio precedente.
</p>

<p>
Gli indici visti fino ad ora sono relativi a variabili unidimensionali. Anche per le variabili multidimensionali ed in
particolare per quelle bidimensionali esistono indici di tendenza centrale e variabilit√†.
</p>

<p>
Sia \((X, Y)\) una variabile aleatoria bidimensionale discreta o continua. Sono detti <i>valori attesi marginali</i> e
<i>varianze marginali</i> le quantit√† \(E[X], E[Y], V[X], V[Y]\) ottenute considerando le distribuzioni marginali di \(X\) ed \(Y\)
ed integrando (o sommando) in accordo alle seguenti
</p>
\begin{equation*}
E[X] =
\begin{cases}
\sum_{s \in S} s \cdot p_X(s) \quad &\text{se $X$ √® discreta}\\
\int_{-\infty}^{+\infty} u \cdot f_X(u)du \quad &\text{se $X$ √® assolutamente continua}
\end{cases}
\end{equation*}
\begin{equation*}
V[X] =
\begin{cases}
\sum_{s \in S}(s - E[X])^2 p_X(s) \quad &\text{se $X$ √® discreta}\\
\int_{-\infty}^{+\infty}(u - E[X])^2 f_X(u)du \quad &\text{se $X$ √® assolutamente continua}
\end{cases}
\end{equation*}
<p>
Si noti che la varianza √® il valore atteso di \(g(X) = (X - E[X])^2\).
</p>

<p>
√à utile ricordare che valgono le seguenti relazioni:
</p>
<ul class="org-ul">
<li>\(E[a \cdot X + b \cdot Y] = a \cdot E[X] + b \cdot E[Y]\) per ogni coppia \(X, Y\) e per ogni \(a, b \in \mathbb{R}\);</li>
<li>\(E[X \cdot Y] = E[X] \cdot E[Y]\) per ogni coppia \(X, Y\) stocasticamente indipendenti;</li>
<li>\(V[X + Y] = V[X] + V[Y]\) per ogni coppia \(X, Y\) stocasticamente indipendenti.</li>
</ul>
<p>
Oltre ai valori attesi ed alle varianze marginali, un altro indice √® estremamente importante, si tratta della
<i>covarianza</i> definita come
\[\text{Cov}[X, Y] = E[(X - E[X]) \cdot (Y - E[Y])] = \iint_{\mathbb{R}^2} (t - E[X]) \cdot (s - E[Y]) \cdot f_{X, Y} (t, s) dt ds\]
o equivalentemente come
\[\text{Cov}[X, Y] = E[X \cdot Y] - E[X] \cdot E[Y] = \iint_{\mathbb{R}^2} t \cdot s \cdot f_{X, Y}(t, s)dt ds - \int_{\mathbb{R}} t \cdot f_X (t) dt \cdot \int_{\mathbb{R}} s \cdot f_Y(s)ds\]
La covarianza √® un indice della correlazione che sussiste tra due variabili ovvero del loro grado di dipendenza reciproca.
Tanto pi√π essa √® grande tanto pi√π forte √® il legame di dipendenza tra le variabili. Si noti ad esempio che se le variabili
\(X\) ed \(Y\) sono stocasticamente indipendenti, allora in base alla seguente propriet√†:
</p>

<p>
\(E[X \cdot Y] = E[X] \cdot E[Y]\). Per ogni coppia \(X, Y\) stocasticamente indipendente
si ottiene che \(\text{Cov}[X, Y] = E[X \cdot Y] - E[X] \cdot E[Y] = E[X] \cdot E[Y] - E[X] - E[Y] = 0\).
Due variabili aleatorie aventi covarianza nulla vengono dette <i>incorrelate</i>.
</p>

<p>
Occorre per√≤ sottolineare che la nozione di incorrelazione √® pi√π debole di quella di indipendenza. Infatti, √® possibile
mostrare che seppur esistono coppie di variabili incorrelate esse non sono indipendenti.
</p>

<p>
Un ultimo indice da ricordare, strettamente legato alla covarianza ed utilizzato per esprimere pi√π chiaramente il grado
di dipendenza tra due variabili, √® il <i>coefficiente di correlazione lineare di Pearson</i>:
\[ \rho_{XY} = \frac{\text{Cov}[X, Y]}{\sqrt{V[X]\cdot V[Y]}} = \frac{\text{Cov}[X, Y]}{\sigma_X \cdot \sigma_Y}\]
Tale indice rispetto alla covarianza ha il vantaggio di godere delle seguenti propriet√†:
</p>
<ul class="org-ul">
<li>\(\rho_{XY} = 0\) se \(X\) ed \(Y\) sono incorrelate;</li>
<li>\(|\rho_{XY}| = 1\) se vale la relazione \(Y = a \cdot X + b\) per ogni \(a, b \in \mathbb{R}\). Pi√π precisamente, se \(\rho_{XY}\) vale +1 allora \(a > 0\),
e se vale -1 allora \(a < 0\).</li>
</ul>
</div>
</div>

<div id="outline-container-org7ddc341" class="outline-3">
<h3 id="org7ddc341"><span class="section-number-3">2.3</span> Distribuzioni Notevoli</h3>
<div class="outline-text-3" id="text-2-3">
<p>
Abbiamo visto che esiste una corrispondenza biunivoca tra la <b>funzione di ripartizione</b> e la
</p>
<ul class="org-ul">
<li>Densit√† di probabilit√† (variabili assolutamente continue);</li>
<li>Distribuzione di probabilit√† (variabili discrete).</li>
</ul>

<p>
Per tale ragione si usa parlare di "Distribuzione" di una variabile intendendo indifferentemente la sua ripartizione o
la sua densit√† (o distribuzione di probabilit√†).
</p>

<p>
La notazione \(X \sim F\) va letta come "la variabile \(X\) √® distribuita secondo \(F\)".
</p>
</div>

<div id="outline-container-orgedc442b" class="outline-4">
<h4 id="orgedc442b"><span class="section-number-4">2.3.1</span> Distribuzione Bernoulliana</h4>
<div class="outline-text-4" id="text-2-3-1">
<p>
Una variabile aleatoria \(X\) √® detta <i>distribuita secondo una Bernoulliana di parametro \(p\)</i>, \(p \in [0, 1]\), \(X \sim B(p)\),
se essa pu√≤ assumere solo i valori 1 e 0 rispettivamente con probabilit√† \(p\):
</p>
\begin{equation*}
p_X(t) =
\begin{cases}
1 - p &\text{se $t = 0$}\\
p     &\text{se $t = 1$}\\
0     &\text{altrimenti}
\end{cases}
\end{equation*}
\begin{equation*}
F_X(t)=
\begin{cases}
0 &\text{se $t < 0$}\\
1 - p &\text{se $0 \leq t < 1$}\\
1 &\text{se $t \geq 1$}
\end{cases}
\end{equation*}
<p>
L'importanza di questa semplice distribuzione √® ovvia, sono variabili di Bernoulli tutte quelle che individuano il verificarsi
di uno specifico evento e che valgono 1 se questo si verifica e 0 altrimenti.
</p>

<p>
Immediate sono le determinazioni della <i>media</i> e della <i>varianza</i> di una <i>Bernoulliana</i> che risultano essere:
\[ E[X] = 0 \cdot (1 - p) + 1 \cdot p = p\]
\[ V[X] = [0^2 \cdot (1 - p) + 1^2 \cdot p] - p^2 = (1 - p)p\]
</p>
</div>
</div>

<div id="outline-container-orgd9934e9" class="outline-4">
<h4 id="orgd9934e9"><span class="section-number-4">2.3.2</span> Distribuzione Binomiale</h4>
<div class="outline-text-4" id="text-2-3-2">
<p>
Siano \(X_1, \dots, X_n, n\) variabili Bernoulliane di identico parametro \(p\) e stocasticamente indipendenti tra loro. Sia poi \(X\)
una variabile aleatoria definita come somma delle \(X_i\) ovvero sia \(X = X_1 + \dots + X_n\). Una tale variabile √® detta
<i>distribuita secondo una Binomiale con parametri \(n\) e \(p\)</i>: \(X \sim \text{Bin}(n, p)\). Una tale variabile pu√≤ assumere qualsiasi
valore intero \(k\) compreso tra \(0\) ed \(n\) in accordo alla seguente probabilit√†:
\[P(X=k) = \binom{n}{k} \cdot p^k \cdot (1 - p)^{n-k}\]
</p>

<p>
La motivazione della precedente formula √® la seguente: \(p^k \cdot (1 - p)^{n-k}\) fornisce la probabilit√† che \(k\) delle \(n\) variabili \(X_i\)
assuma il valore 1 e che le restanti \((n-k)\) assumano valore 0.
</p>

<p>
\(\binom{n}{k} = \frac{n!}{(n-k)! k!}\) esprime il numero di combinazioni possibili per cui \(k\) variabili valgono 1 e \((n-k)\)
valgono 0.
</p>

<p>
In definitiva la <i>distribuzione di probabilit√†</i> e la <i>funzione di ripartizione</i> risultano essere
</p>

\begin{equation*}
p_X(t)=
\begin{cases}
\binom{n}{t}p^t(1-p)^{n-t} &\text{se $t \in \{0, 1, \dots, n\}$}\\
0 &\text{altrimenti}
\end{cases}
\end{equation*}
<p>
\[F_X(t) = \sum_{0 \leq k \leq n:k \leq t} \binom{n}{k} p^k(1-p)^{n-k} \quad \text{per ogni $t \in \mathbb{R}$}\]
L'indipendenza tra le variabili \(X_i\) consente di determinare facilmente il <i>valore atteso</i> e la <i>varianza</i> della
variabile \(X\):
\[E[X] = E[X_1 + \dots + X_n] = E[X_1] + \dots + E[X_n] = n \cdot p\]
\[V[X] = V[X_1] + \dots + V[X_n] = n \cdot (1-p) \cdot p\]
La principale applicazione della distribuzione binomiale consiste nella definizione di variabile che "contano" le realizzazioni
di eventi quando questi siano da considerarsi indipendenti e con identica probabilit√† di verificarsi.
</p>

<p>
Questo √® per esempio il caso della variabile \(X\) definita nei 2 seguenti esempi visti in precedenza:
</p>

<p>
Facciamo riferimento all'esempio degli appartamenti e consideriamo lo spazio \(\Omega\) e la probabilit√† \(P\) in esso definiti.
Una variabile aleatoria che ha senso considerare in questo caso potrebbe essere la \(X :=\) "numero di appartamenti venduti
a fine anno". Formalmente essa andrebbe definita come funziona da \(\Omega\) in \(\mathbb{R}\) che assegna:
</p>
<ul class="org-ul">
<li>\(X((0, 0, 0)) = 0\)</li>
<li>\(X((0, 0, 1)) = X((0, 1, 0)) = X((1, 0, 0)) = 1\)</li>
<li>\(X((0, 1, 1)) = X((1, 1, 0)) = X((1, 0, 1)) = 2\)</li>
<li>\(X((1, 1, 1)) = 3\)</li>
</ul>

<p>
In base alla definizione della variabile casuale \(X\) che abbiamo fornito, ha senso definire la probabilit√† che
esattamente un appartamento venga venduto \(X\) = 1. Infatti, vale quanto segue:
\[ P(X=1) = P(\omega \in \Omega : X(\omega) = 1) = P(\{(0, 0, 1), (0, 1, 0), (1, 0, 0)\}) = \frac{3}{8}\]
</p>

<p>
Riconsideriamo la variabile aleatoria definita nell'esempio precedente, e determiniamone la corrispondente funzione di
ripartizione. Per questo osserviamo prima di tutto che la \(X\) pu√≤ assumere solo i valori 0, 1, 2 e 3.
Quindi sicuramente sar√† \(F_X(t) = P(X \leq t) = 0\) per \(t < 0\). Avremo poi
</p>
\begin{align*}
&F_X(t) = P(X = 0) = P(\{0, 0, 0\}) = \frac{1}{8} \text{ per } t <0\\
&F_X(t) = P(X = 0 \text{ oppure } 1) = P(\{(0, 0, 0), (1, 0, 0), (0, 1, 0), (0, 0, 1)\}) = \frac{1}{2} \text{ per } 1 \leq t \leq 2\\
&F_X(t) = P(X = 0 \text{ oppure } 1 \text{ oppure } 2) = 1 - P(X = 3) = 1 - P(\{(1, 1, 1)\}) = 1 - \frac{1}{8} = \frac{7}{8} \text{ per } 2 \leq t < 3\\
&F_X(t) = P(X = 0 \text{  oppure  } 1 \text{ oppure } 2 \text{ oppure } 3) = P(\Omega) = 1 \text{ per } t \geq 3
\end{align*}

<p>
La funzione di ripartizione risulta essere descritta dal grafico nella figura sottostante:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-14_10-05-12.png" alt="screenshot_2018-03-14_10-05-12.png" />
</p>
</div>

<p>
In questi 2 esempi \(X\) risulta essere una variabile aleatoria distribuita secondo una Binomiale con parametri 3 e 1/2.
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-24_11-26-21.png" alt="screenshot_2018-03-24_11-26-21.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org2ee4694" class="outline-4">
<h4 id="org2ee4694"><span class="section-number-4">2.3.3</span> Distribuzione di Poisson</h4>
<div class="outline-text-4" id="text-2-3-3">
<p>
La distribuzione di <i>Poisson</i> pu√≤ essere vista come un caso particolare della distribuzione Binomiale che si ottiene quando il
numero di variabili \(X_i\) che compaiono in \(X = X_1 + \dots X_n\) tende ad infinito mentre il valore del parametro \(p\) tende a
zero in modo tale che il prodotto \(n \cdot p\) resti costante.
</p>

<p>
In questo caso, assumendo \(\lambda = n \cdot p\) diremo che la variabile \(X = X_1 + \dots + X_n\) √® distribuita secondo una Poisson con parametro
\(\lambda, \lambda \in \mathbb{R}_+\): \(X \sim \text{Poi}(\lambda)\).
</p>

<p>
Osserviamo che la variabile cos√¨ definita pu√≤ assumere un qualsiasi valore intero \(k\). Le probabilit√† associate ai valori
assumibili da \(X\) si ricavano dalla seguente relazione: \(P(X=k) = \binom{n}{k} \cdot p^k \cdot (1-p)^{n-k}\) con un passiaggio al limite per
\(n \to +\infty\) (sotto il vincolo \(\lambda = n \cdot p\) costante) e risultano:
\[ P(X=k) = \frac{\lambda^k}{k!} e^{-\lambda} \quad \forall k \in \mathbb{N}\]
In definitiva la <i>distribuzione di probabilit√†</i> e la <i>funzione di ripartizione</i> risultano essere:
</p>
\begin{equation*}
p_X(t) =
\begin{cases}
\frac{\lambda^t}{t!}\cdot e^{-\lambda} &\text{se $t \in \{0, 1, \dots\}$}\\
0 &\text{altrimenti}
\end{cases}
\end{equation*}
<p>
\[F_X(t) = \sum_{k \in \mathbb{N} : k \leq t} \frac{\lambda^k}{k!} \cdot e^{-\lambda} \quad \text{per ogni $t \in \mathbb{R}$}\]
Il <i>valore atteso</i> e la <i>varianza</i> di una tale variabile Poissoniana si ricavano facilmente da quelli delle Bernoulliane,
ricordando che \(\lambda = n \cdot p\).
</p>

<p>
Il <i>valore atteso</i> risulta essere
\[E[X] = n \cdot p = \lambda\]
mentre per calcolare la <i>varianza</i> √® necessario osservare che \(V[X] = n \cdot (1-p) \cdot p = n \cdot p - n \cdot p^2 = \lambda - \frac{\lambda^2}{n}\) e
che tale quantit√† diviene uguale a \(\lambda\) quando \(n\) tende ad infinito per cui
\[ V[X] = \lambda\]
La distribuzione di Poisson viene utilizzata quando si considerino grandi popolazioni di individui in cui ogni individuo ha
una probabilit√† \(p\) molto piccola di essere soggetto ad uno specifico evento in esame. Per tale ragione la <i>distribuzione
di Poisson viene anche detta degli eventi rari</i>.
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-24_11-47-08.png" alt="screenshot_2018-03-24_11-47-08.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org07e3d22" class="outline-4">
<h4 id="org07e3d22"><span class="section-number-4">2.3.4</span> Distribuzione Geometrica</h4>
<div class="outline-text-4" id="text-2-3-4">
<p>
Una variabile aleatoria \(X\) √® detta <i>distribuita secondo una Geometrica</i> di parametro \(p\), \(p \in [0, 1]\): \(X \sim \text{Geo}(p)\) se pu√≤
assumere qualsiasi valore intero non negativo \(k\) con probabilit√† \(P(X=k) = p \cdot (1-p)^k\) ovvero se ha la <i>distribuzione di probabilit√†</i>
e la <i>funzione di ripartizione</i> date da
</p>
\begin{equation*}
p_X(t)=
\begin{cases}
p \cdot (1-p)^t &\text{se $t \in \mathbb{N}$}\\
0 &\text{altrimenti}
\end{cases}
\end{equation*}
<p>
\[F_X(t) = \sum_{k \in \mathbb{N} : k \leq t} p \cdot (1-p)^k \quad \text{per ogni $t \in \mathbb{R}$}\]
Si consideri un esperimento, ripetuto a istanti rappresentati da numeri interi, di verifica di funzionamento di una macchina:
</p>

<p>
Se interpretiamo \(p\) come la probabilit√† che a un certo istante la macchina si guasti, la distribuzione geometrica d√† la
<i>distribuzione di probabilit√† del PRIMO guasto</i>, cio√® \(p_X(t)\) √® la probabilit√† che il guasto si verifichi al tempo \(t+1\)-mo
(nei primi \(t\) istanti funziona).
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-24_11-58-21.png" alt="screenshot_2018-03-24_11-58-21.png" />
</p>
</div>

<p>
<i>Valore atteso</i> e <i>varianza</i> di una variabile \(X\) con distribuzione Geometrica sono:
\[E[X] = \frac{1 - p}{p} \quad V[X] = \frac{1-p}{p^2}\]
L'importanza di questa distribuzione sta nella <i>propriet√† di assenza di memoria</i>: \(P(X=k+m|X \geq m) = P(X=k)\).
</p>

<p>
Per comprenderne il significato, supponiamo che \(X\) sia il tempo di vita di una macchina soggetta a guasti (possono
avvenire solo in corrispondenza di intervalli di tempo unitari), e supponiamo di aver rilevato che per \(m\) unit√† di
tempo essa non si sia guastata.
</p>

<p>
La propriet√† di assenza di memoria asserisce che la probabilit√† che la macchina si guasti all'istante \(k+m\)-esimo,
condizionata dall'evento \(X \geq m\), √® uguale alla probabilit√† iniziale che essa si guasti all'istante \(k\)-esimo.
</p>

<p>
In definitiva, la propriet√† di assenza di memoria asserisce che il tempo trascorso da quando abbiamo iniziato ad esaminare
il funzionamento della macchina non influisce sulla distribuzione del tempo restante al verificarsi del guasto.
</p>
</div>
</div>

<div id="outline-container-org6c47d94" class="outline-4">
<h4 id="org6c47d94"><span class="section-number-4">2.3.5</span> Distribuzione Uniforme</h4>
<div class="outline-text-4" id="text-2-3-5">
<p>
La <i>distribuzione uniforme</i> rappresenta la pi√π semplice distribuzione continua e viene adottata nel caso in cui
la variabile considerata possa assumere qualsiasi valore compreso in un dato intervallo con probabilit√† costante.
</p>

<p>
Formalmente diciamo che la variabile \(X\) √® <i>distribuita secondo una Uniforme di supporto</i> \([a, b]\): \(X \sim U[a, b]\) se
essa √® assolutamente continua con <i>densit√†</i> e <i>funzione di ripartizione</i>:
</p>
\begin{equation*}
f_X(t)=
\begin{cases}
\frac{1}{b-a} &\text{se $t \in [a, b]$}\\
0 &\text{altrimenti}
\end{cases}
\end{equation*}
\begin{equation*}
F_X(t) =
\begin{cases}
0 &\text{se $t < a$}\\
\frac{t-a}{b-a} &\text{se $t \in [a, b]$}\\
1 &\text{se $t > b$}
\end{cases}
\end{equation*}
<p>
Tramite semplici integrazioni √® possibile ricavare il <i>valore atteso</i> e la <i>varianza</i>:
\[ E[X] = \frac{a + b}{2} \quad V[X] = \frac{(b-a)^2}{12}\]
Come accennato in precedenza l'interesse in questa distribuzione √® giustificato dal fatto che essa descrive bene
situazioni nelle quali le variabili possono assumere valori in intervalli finiti di \(\mathbb{R}\) con probabilit√† uniforme
ovvero tale da essere identica per intervalli di medesima ampiezza (purch√© contenuti nel supporto della variabile stessa).
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-24_12-23-30.png" alt="screenshot_2018-03-24_12-23-30.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org993ceb7" class="outline-4">
<h4 id="org993ceb7"><span class="section-number-4">2.3.6</span> Distribuzione triangolare</h4>
<div class="outline-text-4" id="text-2-3-6">
<p>
Quando si considerano variabili aleatorie con supporto \([a, b] \subseteq \mathbb{R}\) pu√≤ essere limitativo pensare che i
valori assumibili abbiano tutti la stessa probabilit√† di presentarsi. Per questa ragione sono state introdotte in letteratura
diverse generalizzazioni della distribuzione uniforme. Una di queste √® la distribuzione triangolare, che assegna alla
densit√† di probabilit√† valori maggiori al centro del supporto e minori in prossimit√† degli estremi.
</p>

<p>
Formalmente diciamo che la variabile \(X\) √® <i>distribuita secondo una Triangolare di supporto</i> \([a, b]\): \(X \sim T[a, b]\)
se essa √® assolutamente continua con <i>densit√†</i> e <i>funzione di ripartizione</i>
</p>
\begin{equation*}
f_X(t)=
\begin{cases}
\frac{4 \cdot (t-a)}{(b-a)^2} &\text{se $t \in \left[a, \frac{a + b}{2}\right)$}\\
\frac{4 \cdot (b-t)}{(b-a)^2} &\text{se $t \in \left[\frac{a + b}{2}, b\right]$}
\end{cases}
\end{equation*}
\begin{equation*}
F_X(t)=
\begin{cases}
0 &\text{se $t < a$}\\
2 \cdot \frac{(t-a)^2}{(b-a)^2} &\text{se $t \in \left[a, \frac{a+b}{2}\right)$}\\
1 - 2 \cdot \frac{(b-t)^2}{(b-a)^2} &\text{se $t \in \left[\frac{a+b}{2}, b\right]$}
\end{cases}
\end{equation*}
<p>
Tramite integrazione √® possibile ricavare il <i>valore atteso</i> e la <i>varianza</i>
\[E[X] = \frac{a+b}{2} \quad V[X] = \frac{(b-a)^2}{24}\]
</p>
</div>
</div>

<div id="outline-container-org33f6b9a" class="outline-4">
<h4 id="org33f6b9a"><span class="section-number-4">2.3.7</span> Distribuzione esponenziale</h4>
<div class="outline-text-4" id="text-2-3-7">
<p>
La distribuzione esponenziale √® particolarmente importante nello studio di quelle variabili che descrivono i tempi
occorrenti al verificarsi di un evento (tempi di attesa per la vendita o per la costruzione di un immobile).
</p>

<p>
Formalmente, una variabile aleatoria \(X\) √® <i>distribuita secondo una Esponenziale di parametro \(\lambda\)</i>, con \(\lambda \in \mathbb{R}_+\):
\(X \sim \text{Exp}(\lambda)\) se essa √® assolutamente continua con <i>densit√†</i> e <i>funzione di ripartizione</i>
</p>
\begin{equation*}
f_X(t) =
\begin{cases}
\lambda \cdot e^{-\lambda t} &\text{se $t \geq 0$}\\
0 &\text{se $t < 0$}
\end{cases}
\end{equation*}
\begin{equation*}
F_X(t)=
\begin{cases}
1 - e^{-\lambda t} &\text{se $t \geq 0$}\\
0 &\text{se $t < 0$}
\end{cases}
\end{equation*}
<p>
Tramite integrazione si ricavano il <i>valore atteso</i> e la <i>varianza</i> che risultano essere
\[E[X] = \frac{1}{\lambda} \quad V[X] = \frac{1}{\lambda^2}\]
Propriet√† di assenza di memoria: \(P(X > s + t | X > s) = P(X > t)\).
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-24_14-44-08.png" alt="screenshot_2018-03-24_14-44-08.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgb6ebf6a" class="outline-4">
<h4 id="orgb6ebf6a"><span class="section-number-4">2.3.8</span> Distribuzione normale</h4>
<div class="outline-text-4" id="text-2-3-8">
<p>
Una variabile aleatoria \(X\) √® detta distribuita secondo una <i>Normale</i> con parametri \(\mu\) e \(\sigma\), con \(\mu \in \mathbb{R}\)
e \(\sigma \in \mathbb{R}_+\): \(X \sim N(\mu, \sigma)\) se essa √® <i>assolutamente continua</i> con densit√†
\[f_X(t) = \frac{1}{\sqrt{2 \cdot \pi \cdot \sigma^2}} \cdot e^{-\frac{(t - \mu)^2}{2 \cdot \sigma^2}}\]
per ogni \(t \in \mathbb{R}\).
</p>

<p>
Nonostante la funzione di densit√† della distribuzione Normale sia molto complessa, questa distribuzione √® fondamentale
nella statistica in virt√π del <i>teorema centrale limite</i> e delle numerose propriet√† da essa possedute che vedremo nel
seguito. Per ora limitiamoci ad osservare che tramite integrazioni non particolarmente semplici si ricavano
<i>valore atteso</i> e <i>varianza</i> date da
\[E[X] = \mu \quad V[X] = \sigma^2\]
Pertanto i parametri della distribuzione sono rispettivamente il <i>valore atteso</i> e la <i>deviazione standard</i> della distribuzione.
</p>

<p>
Inoltre, la variabile aleatoria ha supporto su tutto l'asse reale.
</p>

<p>
Graficamente la densit√† di una Normale risulta come quella presentata sotto:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-24_14-51-43.png" alt="screenshot_2018-03-24_14-51-43.png" />
</p>
</div>

<p>
Si osservi che la moda coincide con la media e che in corrispondenza dei valori \(\mu - \sigma\) e \(\mu + \sigma\) vi sono dei punti di flesso.
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-24_14-52-56.png" alt="screenshot_2018-03-24_14-52-56.png" />
</p>
</div>

<p>
Non √® facile, dati \(a\) e \(b \in \mathbb{R}\) con \(a < b\), determinare la probabilit√† che la variabile \(X \sim N(\mu, \sigma)\)
assuma valori in \([a, b]\) ovvero calcolare
\[P(X \in [a, b]) = \int_a^b \frac{1}{\sqrt{2 \cdot \pi \cdot \sigma^2}} \cdot e^{-\frac{(t - \mu)^2}{2 \cdot \sigma^2}}dt\]
in quanto la risoluzione dell'integrale non √® immediata.
</p>

<p>
Per questa ragione si ricorre ad opportune tavole che si riferiscono alla <i>distribuzione normale standard</i> ovvero
con parametri \(\mu=0\) e \(\sigma=1\) e che forniscono i valori di \(\int_0^z f_X(t)dt\) per un elevato numero di valodi
di \(z \in \mathbb{R}_+\).
</p>

<p>
Quando si sia interessati a determinare delle probabilit√† associate ad una generica \(X ~ N(\mu, \sigma)\) √® possibile
ricondursi al caso appena presentato osservando che la variabile \(Z = \frac{X - \mu}{\sigma}\) √® distribuita secondo
una <i>Normale Standard</i> ovvero vale la seguente propriet√†:
\[\text{se } X \sim N(\mu, \sigma) \text{ allora } Z = \frac{X - \mu}{\sigma} \sim N(0, 1)\]
In base a tale propriet√† ogni variabile \(X \sim N(\mu, \sigma)\) pu√≤ essere ricondotta ad una <i>Normale Standardizzata</i>, ovvero
ancora per ogni \([a, b] \subseteq \mathbb{R}\) si avr√†:
</p>
\begin{equation*}
P(X \in [a, b]) = P(a \leq X \leq b) = P\left(\frac{a - \mu}{\sigma} \leq \frac{X - \mu}{\sigma} \leq \frac{b - \mu}{\sigma}\right)
= P\left(Z \in \left[\frac{a - \mu}{\sigma}, \frac{b-\mu}{\sigma}\right]\right)
\end{equation*}

<p>
Per esempio, sia \(X\) una variabile aleatoria con distribuzione normale di parametri \(\mu = 10\) e \(\sigma = 1\) e si voglia
determinare la probabilit√† dell'evento "\(X \in [9.2, 11.35]\)".
In base a quanto appena esposto avremo:
\[P(X \in [9.2, 11.35]) = P \left(Z \in \left[\frac{9.2 - 10}{1}, \frac{11.35 - 10}{1}\right]\right) = P(Z \in [-0.8, 1.35])\]
L'ultimo valore di probabilit√† √® relativo ad una normale standard e pu√≤ essere calcolato tramite le tavole,
inoltre data la simmetria della normale si pu√≤ scrivere:
\[P(Z \in [-0.8, 0]) = P(Z \in [0, 0.8])\]
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-24_15-14-09.png" alt="screenshot_2018-03-24_15-14-09.png" />
</p>
</div>

<p>
Inoltre, dalle tavole si ricava \(P(Z \in [0, 1.35]) = 0.4115\) e \(P(Z \in [-0.8, 0]) = P(Z \in [0, 0.8]) = 0.2881\).
</p>

<p>
In definitiva avremo \(P(X \in [9.2, 11.35]) = P(Z \in [-0.8, 1.35]) = P(Z \in [0, 0.8]) + P(Z \in [0, 1.35]) = 0.44115 + 0.2881 = 0.6996\)
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-24_15-16-37.png" alt="screenshot_2018-03-24_15-16-37.png" />
</p>
</div>

<p>
Se invece avessimo voluto determinare la probabilit√† \(P(X \in [10.53, 12.15])\). Avremmo dovuto innanzitutto osservare
che \(P(X \in [10.53, 12. 15]) = P(Z \in [0.53, 2.15])\). Tramite le tavole determinare
\(P(Z \in [0.00, 0.53]) = 0.2019\) e \(P(Z in [0.00, 2.15]) = 0.4842\) ed osservare che
\(P(Z \in [0.53, 2.15]) = P(Z \in [0.00, 2.15]) - P(Z \in [0.00, 0.53]) = 0.4842 - 0.2019 = 0.2823\)
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-24_15-19-48.png" alt="screenshot_2018-03-24_15-19-48.png" />
</p>
</div>

<p>
Infine, se avessimo voluto determinare la probaiblit√† \(P(X \in [10.3, +\infty])\), avremmo dovuto innanzitutto osservare che
\(P(X \in [10.3, +\infty]) = P(Z \in [0.3, +\infty]) = 1 - P(Z \in [-\infty, 0.3])\). Poich√© in base alle tavole
\(P(Z \in [0, 0.3]) = 0.1179\) segue che
\(P(X \in [10.3, +\infty]) = 1 - P(Z \in [-\infty, 0.3]) = 1 - 0.5 - 0.1179 = 0.3821\)
</p>

<p>
<i>Regole di calcolo per normali standardizzate da tabelle per integrali</i> \(\int_0^b f(u)du\):
</p>
<ul class="org-ul">
<li>Integrali della forma \(\int_{-\infty}^b f(u)du\):
<ul class="org-ul">
<li>\(b\) finito &gt; 0: \(\int_{-\infty}^b f(u)du = \frac{1}{2} + \int_0^b f(u)du\);</li>
<li>\(b\) finito &lt; 0: \(\int_{-\infty}^b f(u)du = \frac{1}{2} - \int_0^b f(u)du\);</li>
</ul></li>
<li>\(\int_a^{+\infty} f(u)du = 1 - \int_{-\infty}^a f(u)du\);</li>
<li>\(\int_a^b f(u)du = \int_{-\infty}^b f(u)du - \int_{-\infty}^a f(u)du\);</li>
</ul>

<p>
In base a quanto presentato nell'esempio √® possibile verificare che per ogni variabile \(X\) con distribuzione Normale
e per qualsiasi valore dei suoi parametri valgono le seguenti eguaglianze:
</p>
<ul class="org-ul">
<li>\(P(X \in [\mu - \sigma, \mu + \sigma]) = 0.683\);</li>
<li>\(P(X \in [\mu - 2 \cdot \sigma, \mu + 2 \cdot \sigma]) = 0.954\);</li>
<li>\(P(X \in [\mu - 3 \cdot \sigma, \mu + 3 \cdot \sigma]) = 0.997\).</li>
</ul>
<p>
√à interessante verificare in base alla terza di tali uguaglianze che ogni variabile casuale \(X \sim N(\mu, \sigma)\) assumer√† valori compresi
tra \(\mu - 3\sigma\) e \(\mu + 3\sigma\) con probabilit√† molto prossima ad uno.
</p>

<p>
Una delle principali <i>propriet√†</i> della distribuzione normale √® quella <i>di chiusura rispetto all'operazione di somma di variabili
aleatorie stocasticamente indipendenti</i>:
</p>
<ul class="org-ul">
<li>Se \(X_1 \sim N(\mu_1, \sigma_1)\) e \(X_2 \sim N(\mu_2, \sigma_2)\) e se \(X_1\) e \(X_2\) sono indipendenti, allora la variabile \(Y = X_1 + X_2\) √® tale che
\(Y \sim N(\mu_1 + \mu_2, \sqrt{\sigma_1^2 + \sigma_2^2})\)</li>
</ul>
<p>
In altri termini la variabile somma di due variabili aleatorie stocasticamente indipendenti con distribuzioni normali √®
ancora una variabile aleatoria distribuita secondo una normale i cui parametri sono ricavabili facilmente da quelli delle
distribuzioni degli addendi.
</p>
</div>
</div>

<div id="outline-container-org9a9a2bf" class="outline-4">
<h4 id="org9a9a2bf"><span class="section-number-4">2.3.9</span> Distribuzione Chi-Quadro</h4>
<div class="outline-text-4" id="text-2-3-9">
<p>
Siano \(X_1, \dots, X_n\) \(n\) variabili con distribuzione normale di parametri 0 ed 1 (normali standardizzate) ed
indipendenti tra loro. Sia poi \(X\) una variabile aleatoria definita come somma dei quadrati delle \(X_i\)
ovvero sia \(X = X_1^2 + \dots + X_n^2\). Una tale variabile √® distribuita secondo una <i>Chi-Quadro con \(n\) gradi di libert√†</i>:
\(X \sim \chi_n^2\).
</p>

<p>
Notiamo che, essendo definita come somma di quadrati, una variabile con distribuzione Chi-Quadro pu√≤ assumere solo valori
non negativi.
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-24_16-06-24.png" alt="screenshot_2018-03-24_16-06-24.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgef7ce9a" class="outline-4">
<h4 id="orgef7ce9a"><span class="section-number-4">2.3.10</span> Distribuzione t di STUDENT</h4>
<div class="outline-text-4" id="text-2-3-10">
<p>
Siano \(Z \sim N(0, 1)\) e \(Y \sim \chi_n^2\) due variabili indipendenti. Sia poi \(X\) una variabile aleatoria definita come
\[X = \frac{Z}{\sqrt{\frac{Y}{n}}}\]
Una tale variabile √® distribuita secondo una <i>t di student</i> con \(n\) gradi di libert√†: \(X \sim t_n\). Questa distribuzione √®
di grande interesse come la distribuzione Normale e la distribuzione Chi-Quadro.
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-24_16-10-15.png" alt="screenshot_2018-03-24_16-10-15.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgc20ac14" class="outline-4">
<h4 id="orgc20ac14"><span class="section-number-4">2.3.11</span> Distribuzione F di FISHER</h4>
<div class="outline-text-4" id="text-2-3-11">
<p>
Siano \(U \sim \chi_m^2\) e \(V \sim \chi_n^2\) due variabili indipendenti. Sia poi \(X\) una variabile aleatoria definita come
\[X = \frac{\frac{U}{m}}{\frac{V}{n}}\]
Una tale variabile √® <i>distribuita secondo una \(F\) con \(m\) ed \(n\) gradi di libert√†</i>: \(X \sim F(m, n)\).
</p>

<p>
Questa distribuzione √® di grande interesse coma la distribuzione Normale, la distribuzione Chi Quadro e la distribuzione t
di Student.
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-03-24_16-12-57.png" alt="screenshot_2018-03-24_16-12-57.png" />
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org1e1407d" class="outline-3">
<h3 id="org1e1407d"><span class="section-number-3">2.4</span> Teoremi di Convergenza</h3>
<div class="outline-text-3" id="text-2-4">
<p>
In questo capitolo presentiamo 2 teoremi fondamentali nella statistica inferenziale:
</p>
<ul class="org-ul">
<li>Legge dei Grandi Numeri;</li>
<li>Teorema Limite Centrale.</li>
</ul>
<p>
Questi 2 teoremi richiedono la nozione di convergenza di variabili aleatorie.
</p>

<p>
<i>Convergenza in distribuzione</i>
</p>

<p>
Consideriamo una successione \(\{X_n, n \in \mathbb{N}\}\) di variabili aleatorie, e sia \(F_n\) la funzione di ripartizione
della generica variabile \(X_n\) della successione. Diremo che <i>la successione converge in distribuzione alla variabile
X</i> avente funzione di ripartizione \(F\) se vale \(\lim_{n \to \infty}F_n(t) = F(t)\) per ogni \(t \in \mathbb{R}\) che sia punto
di continuit√† per la \(F\). Verranno utilizzate le notazioni \(X_n \overset{d}{\to} X \quad F_n \overset{d}{\to} F\).
</p>

<p>
Per esempio, consideriamo una successione di variabili aleatorie \(\{X_n, n \in \mathbb{N}\}\) in cui la generica variabile
\(X_n\) ha funzione di ripartizione
</p>
\begin{equation*}
F_n(t) =
\begin{cases}
0 &\text{ se $t \leq 0$}\\
t^{\left(\frac{n}{n+1}\right)} &\text{ se $0 < t < 1$}\\
1 &\text{ se $t \geq 1$}
\end{cases}
\end{equation*}

<p>
Osserviamo ora che per ogni \(t \in (0, 1) \subseteq \mathbb{R}\) vale \(\lim_{n \to \infty}t^{\left(\frac{n}{n+1}\right)} = t\) da
cui se ne deduce che vale \(X_n \overset{d}{\to} X\) dove \(X\) ha funzione di ripartizione data da
</p>
\begin{equation*}
F_n(t) =
\begin{cases}
0 &\text{ se $t \leq 0$}\\
t &\text{ se $0 < t < 1$}\\
1 &\text{ se $t \geq 1$}
\end{cases}
\end{equation*}

<p>
Ovvero la successione di variabili aleatorie considerata converge ad una variabile aleatoria avente distribuzione
uniforme di supporto \([0, 1]\).
</p>

<p>
Il grafico della successione per \(n = 10\) mostra un comportamento molto simile a quello proprio di una variabile
aleatoria con distribuzione uniforme in \([0, 1]\).
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-04-26_15-50-00.png" alt="screenshot_2018-04-26_15-50-00.png" />
</p>
</div>

<p>
Nella definizione di convergenza in distribuzione vengono esclusi, nel passaggio al limite, i punti in cui la funzione
di ripartizione limite \(F\) √® discontinua, e ci√≤ affinch√© si abbia un concetto di convergenza il pi√π possibile vicino
all'intuizione.
</p>

<p>
Consideriamo ad esempio una successione di numeri reali \(\{a_n, n \in \mathbb{N}\}\) tale che sia \(a_n \overset{d}{\to} a\) per
\(n \to \infty\) dove \(a \in \mathbb{R}\) e pensiamo alle variabili aleatorie \(X_n\) aventi funzione di ripartizione
</p>
\begin{equation*}
F_n(t) =
\begin{cases}
0 &\text{ se $t < a_n$}\\
1 &\text{ se $t \geq a_n$}
\end{cases}
\end{equation*}

<p>
In pratica la generica variabile \(X_n\) assume valore \(a_n\) con probabilit√† uguale ad uno. Da un punto di vista intuitivo
siamo portati a pensare che valga \(X_n \overset{d}{\to} X\) dove la variabile \(X\) ha funzione di ripartizione
</p>
\begin{equation*}
F (t) =
\begin{cases}
0 &\text{ se $t < a$}\\
1 &\text{ se $t \geq a$}
\end{cases}
\end{equation*}
<p>
Ovvero \(X=a\) con probabilit√† uguale ad uno.
</p>

<p>
Osserviamo per√≤ che se la successione \({a_n, n \in \mathbb{N}}\) √® tale che \(a < a_n\) con \(n\) pari e \(a_n < a\) con \(n\)
dispari, allora risulta \(F_n(a) = 0\) per \(n\) pari e \(F_n(a) = 1\) per n dispari. Pertanto non esiste il limite
\(\lim_{n \to \infty} F_n(a)\).
</p>

<p>
Pertanto non saremmo autorizzati a dire che vale \(X_n \overset{d}{\to} X\). Non essendo definibile in \(a\) la funzione
di ripartizione limite \(F\).
</p>

<p>
Problemi di questo tipo non si verificano se si escludono, nella definizione di convergenza, i valori in cui la \(F\)
limite non √® continua. Si osservi infatti che per tutti gli altri valori di \(t\) risulta, correttamente:
</p>
\begin{gather*}
&\lim_{n \to \infty} F_n(t) = 0 = F(t) \quad \text{ se } t < a\\
&\lim_{n \to \infty} F_n(t) = 1 = F(t) \quad \text{ se } a < t
\end{gather*}

<p>
Osservazione: segnaliamo che la convergenza in distribuzione non √® l'unico tipo di convergenza tra variabili aleatorie
definito in letteratura. Due tipi di convergenza estremamente importanti sono ad esempio la
</p>
<ul class="org-ul">
<li>Convergenza quasi certa;</li>
<li>Converganza in probabilit√†;</li>
</ul>
<p>
che comunque possiamo non considerare ai fini della nostra trattazione.
</p>
</div>
<div id="outline-container-org5e3266b" class="outline-4">
<h4 id="org5e3266b"><span class="section-number-4">2.4.1</span> Legge dei grandi numeri</h4>
<div class="outline-text-4" id="text-2-4-1">
<p>
Consideriamo una successione \(\{X_i, i \in \mathbb{N}_+\}\) di variabili aleatorie, Indipendenti ed Identicamente
Distribuite (I.I.D). Consideriamo poi la variabile aleatoria definita come
\[ \bar{X}_n = \frac{X_1 + \dots + X_n}{n}\]
detta <i>media aritmetica \(n\)-sima della successione</i>.
</p>

<p>
Se le variabili \(X_i\) hanno <i>valore atteso e varianza esistenti e finiti</i> \(E[X_i] = \mu\) e \(V[X_i] = \sigma^2\) allora vale
\[\bar{X}_n \overset{d}{\to} M\]
dove \(M\) √® una variabile aleatoria che assume valore \(\mu\) con probabilit√† 1.
</p>

<p>
La propriet√† appena introdotta costituisce una <i>forma debole</i> del risultato noto sotto il nome di <i>Legge dei Grandi Numeri</i>.
</p>

<p>
La <i>Legge dei Grandi Numeri</i> asserisce che:
</p>

<p>
Se consideriamo una successione di variabili aleatorie I.I.D \(\{X_i, i \in \mathbb{N}_+\}\) per cui esistono valore atteso e
varianza (finiti) allora possiamo affermare che la successione \(\{\bar{X}_n, n \in \mathbb{N}\}\) delle corrispondenti medie
aritmetiche tende, al crescere di \(n\), ad una variabile che assume certamente il valore \(E[X_i] = \mu\).
</p>

<p>
In altre parole, se consideriamo una successione \(\{x_i, i \in \mathbb{N}_+\}\) di realizzazioni delle variabili
\(\{X_i, i \in \mathbb{N}_+\}\) e se consideriamo la successione \(\{\bar{x}_n, n \in \mathbb{N}_+\}\) delle corrispondenti
realizzazioni delle medie aritmetiche, abbiamo che questa seconda successione tende, per \(n\) tendente ad infinito,
al valore \(E[X_i] = \mu\).
</p>

<p>
Per esempio, supponiamo di avere acquistato 50 appartamenti dello stesso valore commerciale e di averli successivamente
ristrutturati con l'intenzione di rivenderli ottenendone un profitto. Supponiamo di sapere che, tenuto conto della
situazione di mercato e delle eventuali contrattazioni con gli acquirenti, il ricavato della vendita di ciascuno di
questi appartamenti (milioni di lire) sia rappresentabile con una variabile \(X_i, i = 1, \dots, 50\), avente distribuzione
triangolare di supporto \([5, 15]\). Supponiamo poi che sia lecito assumere che i singoli ricavi \(X_i\), siano indipendenti
tra loro.
</p>

<p>
La Legge dei Grandi Numeri consente di affermare che la <i>media aritmetica dei ricavi</i> che otterremo per ogni appartamento,
data dalla variabile \(\bar{X}_{50}\) non si discoster√† troppo dal valore atteso, della singola \(X_i\), ovvero da \(\frac{5 + 15}{2} = 10\).
Pertanto il ricavato totale dell'investimento non si discoster√† troppo da \(10 \cdot 50 = 500\).
</p>

<p>
Osservazione: in realt√† le ipotesi della Legge dei Grandi Numeri possono essere indebolite rispetto a quelle riportare in
precedenza. Infatti, esistono versioni alternative di questa propriet√† in cui non √® richiesta l'ipotesi che le variabili
\(X_i\) siano identicamente distribuite.
</p>
</div>
</div>
<div id="outline-container-orged4c3a6" class="outline-4">
<h4 id="orged4c3a6"><span class="section-number-4">2.4.2</span> Teorema Limite Centrale</h4>
<div class="outline-text-4" id="text-2-4-2">
<p>
La Legge dei Grandi Numeri assicura la convergenza \(\bar{X}_n \overset{d}{\to} M\), ma non specifica nulla circa la rapidit√† con
cui questa avviene. Non sappiamo dire per quale valore di \(n\) sar√† lecito pensare che una realizzazione \(\bar{x}_n\) assuma
valore \(\mu\) o un valore molto prossimo ad esso.
</p>

<p>
Nell'esempio visto si asserisce infatti che il ricavo totale dell'investimento sar√† prossimo a 500 milioni ma non quanto
prossimo.
</p>

<p>
√à intuitivo pensare che la convergenza sia tanto pi√π rapida quanto pi√π la varianza sar√† piccola. Quanto appena asserito
viene formalizzato tramite il <i>Teorema Limite Centrale</i>, il quale specifica quale sia la distribuzione della variabile
aleatoria \(\bar{X}_n\) per \(n\) <i>sufficientemente</i> grande e quali siano il valore atteso e la varianza della stessa.
</p>

<p>
Sia \(\{X_i, i \in \mathbb{N}_+\}\) una successione di variabili aleatorie che soddisfa le ipotesi della Legge dei Grandi
Numeri, ovvero siano le \(X_i\) I.I.D ed aventi valore atteso \(E[X_i] = \mu\) e varianza \(V[X_i] = \sigma^2\) entrambe esistenti e finiti.
</p>

<p>
Consideriamo la variabile aleatoria \(S_n\) definita come segue: \(S_n = X_1 + \dots + X_n\), vale
\[S_n \overset{d}{\to} X \sim N(n \cdot \mu, \sqrt{n} \cdot \sigma) = N(n \cdot \mu, n \cdot \sigma^2)\]
ovvero \(S_n\) converge in distribuzione ad una variabile distribuita come una Normale di media \(n \cdot \mu\) e deviazione
standard \(\sqrt{n} \cdot \sigma\).
</p>

<p>
Tale propriet√† √® una forma debole di un noto risultato che prende il nome di <i>Teorema Limite Centrale</i>. Osservato
che vale \(\bar{X}_n = \frac{S_n}{n}\), dalle seguenti relazioni:
\[S_n \overset{d}{\to} X \sim N(n \cdot \mu, \sqrt{n} \cdot \sigma) = N(n \cdot \mu, n \cdot \sigma^2)\]
\[E[a \cdot X + b] = a \cdot E[X] + b \quad \text{per ogni variabile $X$ e per ogni $a, b \in \mathbb{R}$}\]
si ricava
\[E[\bar{X}_n] = E\left[\frac{S_n}{n}\right] = \frac{1}{n} E[S_n] = \frac{1}{n} E[X_1 + \dots + X_n] = \frac{1}{n}(n \mu) = \mu\]
e dalle seguenti
\[S_n \overset{d}{\to} X \sim N(n \cdot \mu, \sqrt{n} \cdot \sigma) = N(n \cdot \mu, n \cdot \sigma^2)\]
\[V[a \cdot X + b] = a^2 \cdot V[X] \quad \text{per ogni variabile $X$ e per ogni $a, b \in \mathbb{R}$}\]
si ricava
\[V[\bar{X}_n] = V\left[\frac{S_n}{n}\right] = \frac{1}{n^2} V[S_n] = \frac{1}{n^2} V[X_1 + \dots + X_n] = \frac{1}{n^2}(n \sigma^2) = \frac{\sigma^2}{n}\]
</p>

<p>
Si conclude che
\[ \bar{X}_n \overset{d}{\to} X \sim N\left(\mu, \frac{\sigma}{\sqrt{n}}\right) = N \left(\mu, \frac{\sigma^2}{n}\right)\]
</p>

<p>
Praticamente il <i>Teorema Limite Centrale</i> asserisce che per \(n\) <i>sufficientemente</i> grande, possiamo approssimare le
variabili \(S_n\) e \(\bar{X}_n\) con delle variabili aventi distribuzione normale, i cui parametri dipendono da quelli
delle variabili \(X_i\). Relativamente all'espressione <i>per \(n\) sufficientemente grande</i> possiamo dire che in genere
si utilizza questa approssimazione tutte le volte che \(n \geq 30\).
</p>

<p>
Per esempio, riprendiamo in considerazione l'esempio dell'investimento immobiliare. Abbiamo visto che dobbiamo attenderci
un ricavo totale prossimo ai 500 milioni di lire. Supponiamo ora di avere pronto un preventivo delle spese da sostenere
per la ristrutturazione degli appartamenti e supponiamo che questo sia di 470 milioni di lire. Qual √® la probabilit√†
che il nostro ricavo sia inferiore alle spese che dobbiamo sostenere per le ristrutturazioni?
</p>

<p>
Per rispondere alla domande precedente possiamo fare ricorso al Teorema Limite Centrale. Infatti, questo teorema consente
di pensare alla variabile \(S_n\) (totale ricavi) \(S_n = X_1 + \dots + X_n\) come ad una variabile normalmente distribuita, i cui
parametri si ricavano da quelli delle variabili \(X_i\), che sono: \(E[X_i] = \frac{5 + 15}{2} = 10\) e
\(V[X_i] = \frac{(15 - 5)^2}{24} = 4.16\).
</p>

<p>
I parametri \(\mu\) e \(\sigma\) relativi alla seguente formula:
\[S_n \overset{d}{\to} X \sim N(n \cdot \mu, \sqrt{n} \cdot \sigma) = N(n \cdot \mu, n \cdot \sigma^2)\]
sono quindi rispettivamente 10 e 2.04, ed √® lecito pensare che \(S_n \sim N(50 \cdot 10, \sqrt{50} \cdot 2.04) = N(500, 14.42)\).
</p>

<p>
Per rispondere alla nostra domanda basta ora osservare che
\[P(\text{spesa supera ricavato}) = P(S_n \leq 470) = P \left(\frac{S_n - 500}{14.42} \leq \frac{470 - 500}{14.42}\right) =
P(Z \leq -2.08) = P(Z \geq 2.08) = 1 - P(Z \leq 2.08)\]
</p>

<p>
Dove \(Z\) √® una Normale Standardizzata.
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-04-26_19-22-21.png" alt="screenshot_2018-04-26_19-22-21.png" />
</p>
</div>

<p>
\[P(S_n \leq 470) = 1 - P(Z \leq 2.08) = 1 - 0.98124 = 0.01876\]
</p>
</div>
</div>
</div>
<div id="outline-container-org597d91d" class="outline-3">
<h3 id="org597d91d"><span class="section-number-3">2.5</span> Stime di parametri</h3>
<div class="outline-text-3" id="text-2-5">
<p>
La <i>statistica inferenziale</i> consente di dedurre particolari caratteristiche di una popolazione limitandosi ad analizzare
un numero finito e preferibilmente piccolo di suoi individui. Quando le <i>caratteristiche</i> che si vogliono individuare sono
<i>esprimibili numericamente</i>, allora esse sono dette <i>parametri</i>.
</p>

<p>
Per <i>stima di parametri</i> si intende quindi il problema della <i>deduzione</i> di <i>caratteristiche di tipo numerico</i> di una
<i>popolazione</i> facendo ricorso per questo all'analisi di un suo sottoinsieme finito opportunamente scelto detto <i>campione</i>.
</p>

<p>
Diverse tecniche possono essere utilizzate per effettuare delle stime di parametri. Noi ci limiteremo a considerare quelle
classiche basate sulla conoscenza delle <i>distribuzioni campionarie</i>, vale a dire distribuzioni di particolari indici
statistici associati alle caratteristiche del campione. Tecniche alternative vengono comunque succintamente descritte
nel paragrafo conclusivo di questo capitolo.
</p>
</div>
<div id="outline-container-orga0e362a" class="outline-4">
<h4 id="orga0e362a"><span class="section-number-4">2.5.1</span> Campionamento e campioni</h4>
<div class="outline-text-4" id="text-2-5-1">
<p>
Diverse ragioni possono portare a voler determinare le caratteristiche di una popolazione facendo ricorso esclusivamente
ad un numero limitato di suoi individui. Pu√≤ trattarsi di un problema economico o di tempo, pu√≤ altres√¨ capitare che non
tutti gli elementi della popolazione siano disponibili o ancora che le misure da effettuare "distruggano" le unit√† della
popolazione che vengono analizzate. In questi casi occorre allora effettuare un <i>campionamento</i>, vale a dire una scelta
degli individui che verranno analizzati per effettuare le inferenze sull'intera popolazione.
</p>

<p>
Questo √® un problema che non va trascurato, infatti dal metodo utilizzato nel condurre un campionamento dipende anche
la validit√† della tecnica utilizzata nella fase di inferenza.
</p>

<p>
Tutte le tecniche che verranno presentate in questo capitolo sono valide solo nel caso in cui il campione sia stato scelto
secondo una procedura detta <i>campionamento casuale</i>, che assegna la stessa probabilit√† di essere estratto ad ogni individuo
della popolazione.
</p>

<p>
Il metodo solitamente utilizzato per generare un <i>campione casuale</i> consiste nell'assegnare, in maniera progressiva, un
numero ad ogni individuo della popolazione, e quindi estrarre, con un qualsiasi generatore casuale, tanti numeri quanti
devono essere gli elementi del campione.
</p>

<p>
Questa procedura √® dispendiosa in termini di tempo, ma per contro occorre tener presente che altrimenti √® facile commettere
l'errore di <i>ritenere casuale un campione che invece non lo √®</i>.
</p>

<p>
Nel caso in cui la popolazione sulla quale condurre l'indagine sia costituita dagli abitanti di una citt√† potremmo essere
portati a scegliere il campione facendo uso di un elenco telefonico o fermando a caso le persone per strada.
</p>

<p>
Cos√¨ facendo non si ottiene un campione casuale:
</p>
<ul class="org-ul">
<li>Nel primo caso vengono escluse le persone che non posseggono un apparecchio telefonico;</li>
<li>Nel secondo caso le persone che raramente escono di casa hanno minore probabilit√† di essere parte del campione.</li>
</ul>

<p>
Un'altra considerazione che occorre sempre fare durante un'operazione di campionamento riguarda la possibilit√† di estrarre pi√π
volte uno stesso individuo (campionamento con ripetizione o senza ripetizione). La scelta tra queste 2 alternative diviene
rilevante quando la popolazione considerata √® di numerosit√† limitata e diviene trascurabile nel caso di popolazioni di
vaste dimensioni o infinite, e questo √® il caso che verr√† trattato d'ora in avanti.
</p>

<p>
Nel seguito introduciamo alcune definizioni e notazioni relative ai campioni casuali ed alle distribuzioni di variabili ad
essi associate.
</p>

<p>
A tale scopo denotiamo con \(X\) il carattere della popolazione su cui siamo interessati a fare dell'inferenza. Ovviamente
il valore assunto da questo carattere varia a seconda dell'individuo considerato. Pertanto conviene pensare ad \(X\) come
ad una variabile aleatoria la cui distribuzione (sconosciuta) corrisponde a quella che si otterrebbe facendo ricorso alle
tecniche della statistica descrittiva (potendo analizzare l'intera popolazione), e pensare invece ai valori assunti dai
singoli individui come a delle realizzazioni di \(X\).
</p>

<p>
Formalmente, ipotizzando di aver effettuato un <i>campionamento casuale da una popolazione di numerosit√† infinita</i>,
un <i>campione casuale di numerosit√† \(n\)</i> √® una \(n\)-pla \((X_1, \dots, X_n)\) di <i>variabili aleatorie stocasticamente
indipendenti</i> aventi ognuna la <i>stessa distribuzione del carattere \(X\)</i> della popolazione.
</p>

<p>
I valori \((x_1, \dots, x_n)\) assunti da questa \(n\)-pla sono una <i>realizzazione</i> di \((X_1, \dots, X_n)\).
</p>

<p>
Per comodit√† abbiamo l'espressione <i>distribuzione della popolazione</i> anzich√© il termine pi√π corretto <i>distribuzione
del carattere in esame della popolazione \(X\)</i>.
</p>

<p>
Un <i>parametro</i> √® un <i>valore numerico che descrive una caratteristica della popolazione</i>, e come tale √® una
grandezza associata alla sua distribuzione.
</p>

<p>
Una <i>stima</i> √® invece una <i>misura che descrive una caratteristica del campione</i>, o meglio un'espressione funzionale
delle realizzazioni \((x_1, \dots, x_n)\) di \((X_1, \dots, X_n)\).
</p>

<p>
Per esempio, si consideri la seguente tabella:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-04-26_22-01-26.png" alt="screenshot_2018-04-26_22-01-26.png" />
</p>
</div>

<p>
dove i valori rappresentano i costi al metro quadro di 80 appartamenti scelti a caso tra quelli di un determinato quartiere
di una citt√† italiana.
</p>

<p>
Possiamo pensare a tali valori come ad una realizzazione \((x_1, x_{80})\) di un campione \((X_1, \dots, X_{80})\) di numerosit√† \(n = 80\)
e che si riferisce alla popolazione \(X := \text{"costo al metro quadro degli appartamenti del quartiere"}\). Ovviamente
tale costo non √® lo stesso per ogni appartamento, per questa ragione si pensa ad \(X\) come ad una variabile aleatoria,
la cui distribuzione \(F\) coincide con la distribuzione di frequenza cumulata che si otterrebbe se fossero noti i costi al
metro quadro di tutti gli appartamenti del quartiere.
</p>

<p>
Il costo di ogni singolo appartamento corrisponde invece ad una specifica realizzazione di \(X\). Consideriamo ora il parametro
\(\mu\) "costo medio (al metro quadro) degli appartamenti del quartiere". Ovviamente non possiamo dire quale sia il valore di
tale parametro, non avendo a disposizione i dati relativi a tutti gli appartamenti. Per√≤ possiamo farne una stima considerando
la media aritmetica dei costi degli 80 appartamenti estratti con campionamento casuale, ovvero
\[ \bar{x} = \frac{1}{80} \sum_{i=1}^{80} x_i = 2.68\]
Presumibilmente il valore vero di \(\mu\) sar√† diverso da 2.68, ma questa √® comunque una sua stima, sulla cui accuratezza, come
vedremo, si possono fare diversi commenti.
</p>

<p>
Si osservi che, a priori, le stime non sono altro che delle realizzazioni di variabili aleatorie definite come funzione del
campione \((X_1, \dots, X_n)\) in cui non compare alcun parametro incognito, ovvero sono del tipo \(H_n = h(X_1, \dots, X_n)\) dove \(h\)
√® una funzione in \(n\) variabili.
</p>

<p>
Le variabili aleatorie definite in questo modo sono dette <i>statistiche campionarie</i> e sono dette <i>distribuzioni campionarie</i>
le loro distribuzioni.
</p>

<p>
Come vedremo, la conoscenza della distribuzione campionaria di una statistica √® fondamentale nella formulazione e nella
verifica di ipotesi fatte sulla popolazione partendo dai dati campionari. Concludiamo accennando ad alcuni metodi di
campionamento alternativi al campionamento casuale.
</p>

<p>
Un metodo noto √® quello detto <i>stratificato</i>, che presuppone una suddivisione preventiva della popolazione in gruppi detti
strati con caratteristiche omogenee.
</p>

<p>
Effettuata questa operazione gli individui che costituiscono il campione vengono poi estratti da ogni gruppo in
proporzione alla numerosit√† del gruppo stesso (<i>campionamento stratificato proporzionale</i>). Il vantaggio di tale metodo
consiste nel fatto che se i gruppi sono stati creati in maniera appropriata esso permette di ridurre la numerosit√† finale
del campione. A scapito di ci√≤ per√≤ tutte le formule classiche utilizzate nella fase inferenziale devono essere di volta
in volta modificate. Inoltre, la suddivisione della popolazione in strati comporta sempre un aumento del tempo necessario
al campionamento.
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-04-26_22-19-08.png" alt="screenshot_2018-04-26_22-19-08.png" />
</p>
</div>

<p>
Un secondo metodo di campionamento alternativo √® il <i>campionamento a grappoli</i> che prevede una fase di suddivisione della
popolazione in gruppi, in questo caso gruppi eterogenei, in modo tale che ogni singolo gruppo sia rappresentativo
dell'intera popolazione. Fatta questa operazione √® sufficiente limitarsi ad estrarre un singolo gruppo quale campione,
anzich√© estrarre dei singoli individui da ogni gruppo. Questo metodo presenta dei vantaggi in termini di raccolta dei dati
ma risulta generalmente meno efficiente degli altri in termini di inferenze.
</p>

<p>
Tra gli altri metodi ricordiamo il <i>campionamento longitudinale</i> ed il <i>casuale doppio</i>. Nella pratica √® poi uso comune
fare ricorso a pi√π di uno di questi metodi contemporaneamente.
</p>

<p>
Ricordiamo infine che un altro problema associato al campionamento √® quello della scelta della <i>numerosit√† del campione</i>.
I criteri da adottare per questa scelta risulteranno pi√π chiari con le nozioni presentate nei prossimi paragrafi.
</p>
</div>
</div>
<div id="outline-container-orgfe4fbf9" class="outline-4">
<h4 id="orgfe4fbf9"><span class="section-number-4">2.5.2</span> Principali distribuzioni campionarie</h4>
<div class="outline-text-4" id="text-2-5-2">
<p>
In base a quanto affermato in precedenza possiamo pensare al carattere della popolazione su cui vogliamo fare delle
inferenze come ad una <i>variabile aleatoria \(X\)</i>, avente una <i>funzione di ripartizione \(F\) sconosciuta</i>, ma <i>corrispondente
alla distribuzione di frequenza cumulata di tale carattere</i>, che si potrebbe ottenere se fosse possibile analizzare
per intero la <i>popolazione</i>.
</p>

<p>
Una stima di un parametro \(F\) √® costituita da una <i>funzione di una realizzazione</i> \((x_1, \dots, x_n)\) di un campione
casuale, che √® una \(n\)-pla \((X_1, \dots, X_n)\) di variabili stocasticamente indipendenti ed aventi tutte distribuzione \(F\).
</p>

<p>
In pratica una <i>stima</i> √® una <i>realizzazione di una statistica campionaria</i> \(H_n = h(X_1, \dots, X_n)\). Ogni statistica campionaria,
essendo una funzione di variabili aleatorie, √® una variabile aleatoria, e come tale avr√† una sua distribuzione.
</p>

<p>
Nel seguito prenderemo in considerazione alcune statistiche particolarmente importanti e ne descriveremo le principali
propriet√†. Nel seguito denoteremo con \(\mu\) e \(\sigma^2\) il <i>valore atteso</i> e la <i>varianza</i> della <i>popolazione \(X\)</i>
(distribuita secondo \(F\) ignota).
</p>

<p>
Considerato un campione \((X_1, \dots, X_n)\) estratto da una popolazione con distribuzione \(F\), media \(\mu\) e deviazione
standard \(\sigma\), √® detta <i>media campionaria \(n\)-sima</i> la variabile \(\bar{X}_n = \frac{X_1 + \dots + X_n}{n}\).
</p>

<p>
√à detta poi "<i>distribuzione campionaria della media \(n\)-sima</i>" la distribuzione della variabile \(\bar{X}_n\).
</p>

<p>
√à intuitivo pensare che la statistica \(\bar{X}_n\) sia appropriata per stimare la media \(\mu\) della popolazione e come
vedremo ci√≤ √® vero. In genere trovare l'espressione analitica della distribuzione campionaria di \(\bar{X}_n\)
conoscendo la distribuzione \(F\) di \(X\) non √® facile. √à per√≤ facile determinare il <i>valore atteso</i> e la <i>varianza</i> di
\(\bar{X}_n\).
</p>

<p>
Ricordando che si assume indipendenza tra le variabili \(X_1, \dots, X_n\) del campione e che queste hanno tutte <i>valore atteso</i>
uguale a \(\mu\) e <i>varianza</i> uguale a \(\sigma^2\). Allora in base alla seguente propriet√†:
\[E[a \cdot X + b \cdot Y] = a \cdot E[X] + b \cdot E[Y] \text{ per ogni coppia $X, Y$ e per ogni $a, b, \in \mathbb{R}$}\]
otterremo
\[E[\bar{X}_n] = E\left[\frac{X_1 + \dots + X_n}{n}\right] = \frac{1}{n} E[X_1 + \dots + X_n] = \frac{1}{n}(E[X_1] + \dots + E[X_n]) =
\frac{1}{n}(n \mu) = \mu\]
Mentre, in base alle seguenti propriet√†:
\[V[a \cdot X + b] = a^2 \cdot V[X] \quad \text{per ogni variabile $X$ e per ogni $a, b \in \mathbb{R}$}\]
otterremo
\[V[\bar{X}_n] = V\left[\frac{S_n}{n}\right] = \frac{1}{n^2} V[S_n] = \frac{1}{n^2} V[X_1 + \dots + X_n] = \frac{1}{n^2}(n \sigma^2) = \frac{\sigma^2}{n}\]
Osserviamo che mentre il valore atteso di \(\bar{X}_n\) non dipende dalla numerosit√† del campione \(n\), la sua varianza dipende
anche da \(n\) ed √® tanto minore quanto \(n\) √® pi√π grande. Questo vuol dire che le realizzazioni di \(\bar{x}_n\) di \(\bar{X}_n\)
saranno tanto pi√π vicine al valore incognito \(\mu\) quanto pi√π √® grande la numerosit√† del campione.
</p>

<p>
Inoltre abbiamo visto in precedenza che per \(n\) sufficientemente grande la variabile \(\bar{X}_n\) pu√≤ essere approssimata
con una variabile avente distribuzione normale di parametri \(\mu\) e \(\frac{\sigma^2}{n}\) e ci√≤ indipendentemente dall'espressione
della distribuzione \(F\).
</p>

<p>
Una considerazione particolare va fatta nel caso in cui la distribuzione della popolazione
sia gi√† normale in partenza. In questo caso, per la propriet√† di chiusura rispetto all'operazione di somma di variabili
aleatorie con distribuzione normale, la media campionaria \(\bar{X}_n\) √® anch'essa una variabile con distribuzione
normale, ovvero vale \(\bar{X}_n \sim N\left(\mu, \frac{\sigma^2}{n}\right)\).
</p>

<p>
La seconda statistica che viene introdotta √® solitamente usata per stimare la varianza della popolazione.
</p>

<p>
Considerato un campione \((X_1, \dots, X_n)\) estratto da una popolazione con distribuzione \(F\), media \(\mu\) e deviazione standard
\(\sigma\), √® detta <i>varianza campionaria \(n\)-sima</i> la variabile:
\[S_n^2 = \frac{1}{n} \cdot \sum_{i=1}^n (X_i - \bar{X}_n)^2\]
√à detta poi "<i>distribuzione campionaria della varianza \(n\)-sima</i>" la distribuzione della variabile \(S_n^2\).
</p>

<p>
Come nel caso precedente, trovare l'espressione analitica della distribuzione di \(S_n^2\) conoscendo \(F\) non √® facile.
√à per√≤ un po' pi√π facile determinare il valore atteso e la varianza di \(S_n^2\). Infatti, √® possibile dimostrare che valogno
le seguenti relazioni:
</p>
\begin{gather*}
E[S_n^2] = \frac{n-1}{n} \cdot \sigma^2\\
V[S_n^2] = \frac{1}{n}\left(E[(X - \mu)^4] - \frac{n-3}{n-1} \cdot \sigma^4 \right)
\end{gather*}
<p>
Anche per questa statistica √® possibile dimostrare, facendo ricorso al Teorema Limite Centrale, che per \(n\) sufficientemente
grande la sua distribuzione pu√≤ essere approssimata con una normale con parametri dati dalle formule precedenti.
</p>

<p>
Notiamo che la presenza del coefficiente \(\frac{n-1}{n}\) pu√≤ talvolta risultare scomoda e, per tale ragione, in molti processi
inferenziali si preferisce considerare alternativamente alla varianza campionaria, una nuova statistica detta
<i>varianza campionaria \(n\)-sima corretta</i>:
</p>
\begin{gather*}
E[S_n^2] = \sigma^2\\
\hat{S}_n^2 = \frac{n}{n-1} \cdot S_n^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X}_n)^2
\end{gather*}

<p>
Nel caso particolare in cui la popolazione sia normalmente distribuita si possono dimostrare due importanti risultati che
coinvolgono la statistica \(S_n^2\). A tale scopo √® utile introdurre due nuove variabili aleatorie:
</p>
\begin{gather*}
Q_n = \frac{n \cdot S_n^2}{\sigma^2} = \frac{(n-1) \cdot \hat{S}_n^2}{\sigma^2}\\
T_n = \frac{\bar{X}_n - \mu}{\frac{\hat{S}_n}{\sqrt{n}}}
\end{gather*}
<p>
dove \(\hat{S}_n = \sqrt{\hat{S}_n^2}\).
</p>

<p>
Le due quantit√† appena introdotte <i>non vengono dette statistiche</i>, in quanto esse sono funzioni anche dei parametri \(\mu\) e \(\sigma^2\),
che vanno pensati come non noti.
</p>

<p>
Si pu√≤ dimostrare che nell'ipotesi in cui \((X_1, \dots, X_n)\) sia un campione casuale estratto da una popolazione con distribuzione
Normale con parametri \(\mu\) e \(\sigma^2\), allora:
</p>
<ul class="org-ul">
<li>\(Q_n\) √® distribuito come una <i>Chi-quadro</i>: \(Q_n = \frac{n \cdot S_n^2}{\sigma^2} = \frac{(n-1) \cdot \hat{S}_n^2}{\sigma^2} \sim \chi_{n-1}^2\);</li>
<li>\(T_n\) √® distribuito coma una <i>t di Student</i>: \(T_n = \frac{\bar{X}_n - \mu}{\frac{\hat{S}_n}{\sqrt{n}}} \sim t_{n-1}\).</li>
</ul>
<p>
Entrambe con \((n-1)\) gradi di libert√†.
</p>

<p>
Si osservi che le distribuzioni delle quantit√† \(Q_n\) e \(T_n\) non dipendono dai parametri \(\mu\) e \(\sigma^2\) poich√© la Chi-quadro
e la t di Student hanno i gradi di libert√† \((n-1)\) quale unico parametro.
</p>
</div>
</div>
<div id="outline-container-org169fb56" class="outline-4">
<h4 id="org169fb56"><span class="section-number-4">2.5.3</span> Stimatori e stime puntuali</h4>
<div class="outline-text-4" id="text-2-5-3">
<p>
Sia \(\theta\) un parametro incognito della popolazione \(X\). Una statistica campionaria \(H_n = h(X_1, \dots, X_n)\) √® detta
<i>stimatore puntuale</i> quando viene utilizzata per stimare il parametro incognito \(\theta\).
</p>

<p>
√à detta invece <i>stima puntuale</i> del parametro \(\theta\), il valore \(\hat{\theta}(x_1, \dots, x_n)\) assunto dallo stimatore puntuale
\(H_n = h(X_1, \dots, X_n)\) nella realizzazione \(x_1, \dots, x_n\) del campione casuale.
</p>

<p>
Vi sono due propriet√† minime di cui una statistica campionaria deve godere affinch√© possa essere considerata uno stimatore
puntuale, queste sono:
</p>
<ul class="org-ul">
<li><i>Propriet√† di correttezza</i>: uno <i>stimatore</i> \(H_n = h(X_1, \dots, X_n)\) del parametro \(\theta\) √® detto <i>corretto</i> (<i>non distorto</i>),
se, qualunque sia l'effettivo valore del parametro \(\theta\) risulta \(E[H_n] = E[h(X_1, \dots, X_n)] = \theta\);</li>
<li><i>Propriet√† di consistenza</i>: uno <i>stimatore</i> \(H_n = h(X_1, \dots, X_n)\) del parametro \(\theta\) √® detto <i>consistente</i> se, qualunque
sia l'effettivo valore del parametro \(\theta\) risulta \(\lim_{n \to \infty} P[|H_n - \theta| \leq \epsilon] = 1\) per ogni \(\epsilon > 0\).</li>
</ul>

<p>
Talvolta √® difficile verificare se uno stimatore √® consistente. Comunque, √® possibile dimostrare che uno stimatore corretto 
√® anche consistente se vale \(\lim_{n \to \infty} V[H_n] = 0\).
</p>

<p>
Per esempio, consideriamo le due statistiche campionarie \(\bar{X}_n\) e \(\hat{S}_n^2\), stimatori puntuali dei parametri \(\mu\) e \(\sigma^2\)
della popolazione. Questi sono stimatori corretti, essendo:
\[E[\bar{X}_n] = \mu \quad E[\hat{S}_n^2] = \sigma^2\]
Inoltre, sono anche consistenti, infatti valgono
</p>
\begin{gather*}
\lim_{n \to \infty} V[\bar{X}_n] = \lim_{n \to \infty} \frac{\sigma^2}{n} = 0\\
\lim_{n \to \infty} V[\hat{S}_n^2] = \lim_{n \to \infty} \frac{n}{(n-1)^2} \left(E\left[(X - \mu)^4 \right] - \frac{n-3}{n-1} \sigma^4 \right) = 0\\
\hat{S}_n^2 = \frac{n}{n-1} \cdot S_n^2\\
V[\hat{S}_n^2] = V\left[\frac{n}{n-1} \cdot S_n^2 \right] = \frac{n^2}{(n-1)^2} V[S_n^2]\\
V[S_n^2] = \frac{1}{n} \left( E \left[(X - \mu)^4 \right] - \frac{n-3}{n-1} \sigma^4 \right)
\end{gather*}

<p>
Osservazione: in base a quanto appena affermato la <i>varianza campionaria corretta</i> \(\hat{S}_n^2\) √® uno <i>stimatore corretto</i>
di \(\sigma^2\). Occorre per√≤ fare attenzione che contrariamente a quanto si √® portati a pensare, la sua radice
\(\hat{S}_n = \sqrt{\hat{S}_n^2}\) non √® uno stimatore corretto della deviazione standard \(\sigma\) della popolazione:
\[E[\hat{S}_n] \neq \sigma\]
Proprio per tale ragione, nelle analisi statistiche troviamo sempre riportare le stime delle varianze anzich√© quelle delle
deviazioni standard.
</p>

<p>
Osserviamo che per stimare un generico parametro \(\theta\) possono essere definiti diversi stimatori. In molti casi √® possibile
stabilire un criterio per dire se uno stimatore √® preferibile ad un altro.
</p>

<p>
Siano per questo \(H_{1, n} = h_1 (X_1, \dots, X_n)\) e \(H_{2, n} = h_2 (X_1, \dots, X_n)\) due diversi stimatori, entrambi corretti, per un unico
parametro \(\theta\). Diremo che lo stimatore \(H_{1, n}\) √® pi√π efficiente di \(H_{2, n}\) se vale \(V[H_{1, n}] \leq V[H_{2, n}]\) per ogni
numerosit√† del campione \(n\) e per ogni effettivo valore del parametro \(\theta\) da stimare.
</p>

<p>
Per esempio, consideriamo i seguenti stimatori della media \(\mu\) di una popolazione:
\[H_{1, n} = \bar{X}_n = \frac{X_1 + \dots + X_n}{n} \quad \quad \quad H_{2, n} = \frac{X_1}{2} + \frac{X_2 + \dots + X_n}{2(n-1)}\]
Il secondo stimatore (definibile solo per \(n\) maggiore di 1) √® in pratica una variazione del primo e d√† maggior 
importanza alla prima componente del campione a cui √® assegnato un peso di \(\frac{1}{2}\) anzich√© \(\frac{1}{2(n-1)}\)
come avviene per le restanti componenti.
</p>

<p>
Come mostrato nell'esempio precedente, lo stiamtore \(H_{1, n}\) √® corretto e lo stesso vale anche per \(H_{2, n}\), infatti:
\[E[H_{2, n}] = E\left[\frac{X_1}{2}\right] + E \left[\frac{X_2 + \dots + X_n}{2(n-1)}\right] = \frac{1}{2} E[X_1] + \frac{1}{2(n-1)} E[X_2 + \dots + X_n]
= \left[\frac{1}{2} + \frac{n - 1}{2(n-1)}\right] E[X] = E[X] = \mu\]
Osserviamo poi che vale
\[V[H_{2, n}] = V \left[\frac{X_1}{2} \right] + V \left[\frac{X_2 + \dots + X_n}{2(n-1)}\right] = \frac{1}{4}V[X_1] + \frac{1}{4(n-1)^2}
V[X_2 + \dots + X_n] = \frac{1}{4}V[X] + \frac{n-1}{4(n-1)^2} V[X] = \left[\frac{1}{4} + \frac{1}{4(n-1)}\right] \sigma^2\]
</p>

<p>
Ricordando che \(V[H_{1, n}] = \frac{\sigma^2}{n}\), con pochi calcoli non √® difficile verificare che \(V[H_{1, n}] \leq V[H_{2, n}]\) per
ogni \(n\) maggiore o uguale a 2. Pertanto lo stimatore \(H_{1, n}\) √® pi√π efficiente di \(H_{2, n}\) e per questa ragione √® preferibile.
</p>

<p>
Lo stimatore \(H_{2, n}\) non √® neanche consistente, infatti risulta
\(V[H_{2, n}]= \left[\frac{1}{4} + \frac{1}{4(n-1)}\right] \sigma^2 \geq \frac{1}{4} \sigma^2 > 0\), e quindi la sua varianza
non pu√≤ tendere a 0 per \(n\) che tende ad infinito.
</p>

<p>
In particolare, uno stimatore di un parametro \(\theta\) √® detto <i>miglior stimatore</i> se √® pi√π efficiente di ogni altro stimatore
corretto e consistente.
</p>

<p>
Abbiamo gi√† visto che la media e la varianza campionaria corretta \(\bar{X}_n\) e \(\hat{S}_n^2\) sono 2 stimatori corretti e
consistenti dei parametri \(\mu\) e \(\sigma^2\). Per questi 2 stimatori in realt√† √® possibile dimostrare qualche cosa in pi√π, ovvero
che essi sono i <i>migliori stimatori</i> per media e varianza della popolazione.
</p>

<p>
Per esempio, riprendiamo in considerazione la seguente tabella:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-04-26_22-01-26.png" alt="screenshot_2018-04-26_22-01-26.png" />
</p>
</div>

<p>
Se pensiamo a questi 80 costi come alla realizzazione di un campione \((X_1, \dots, X_{80})\) estratto dalla popolazione
\(X := \text{"costo al metro quadro degli appartamenti del quartiere"}\), possiamo fornire una stima della media e della
varianza di \(X\) per mezzo della media e della varianza campionaria corretta, le cui realizzazioni risultano
</p>
\begin{gather*}
\bar{x}_{80} = \frac{x_1 + \dots + x_{80}}{80} = 2.68\\
\hat{s}_{80}^2 = \frac{1}{79} \sum_{i=1}^{80} (x_i -\bar{x}_{80}) = 1.49
\end{gather*}
<p>
I due valori ottenuti sono le stime dei 2 parametri.
</p>
</div>
</div>
<div id="outline-container-org59e7d29" class="outline-4">
<h4 id="org59e7d29"><span class="section-number-4">2.5.4</span> Stime intervallari</h4>
<div class="outline-text-4" id="text-2-5-4">
<p>
Abbiamo visto come trovare un valore approssimato di un parametro incognito della popolazione per mezzo di una stima puntuale.
Tali stime per√≤ non forniscono informazioni sul grado di approssimazione delle stesse. Per questo motivo alle stime
puntuali vengono preferite, quando possibile determinarle, le stime intervallari che sono stime espresse sotto forma di
intervalli (<i>intervalli fiduciari</i>) all'interno dei quali, con buona probabilit√†, si trova il valore vero del parametro da
stimare.
</p>

<p>
Pensiamo ad uno stimatore puntuale \(H_n\) di un parametro \(\theta\) e sia \(\hat{\theta} = h_n (x_1, \dots, x_n)\) una sua realizzazione.
</p>

<p>
Molto difficilmente il valore del parametro \(\theta\) di cui \(H_n\) √® stimatore corrisponder√† alla realizzazione sopra riportata.
Pensiamo allora ad un intervallo \(I = [\hat{\theta} - e_1, \hat{\theta} + e_2] \subseteq \mathbb{R}\). Un intervallo di questo tipo
conterr√† il reale valore di \(\theta\) con maggiore o minore probabilit√† a seconda della sua ampiezza, vale a dire a seconda dei
valori di \(e_1\) e di \(e_2\).
</p>

<p>
Quando sia nota la distribuzione campionaria dello stimatore \(H_n\) √® possibile calcolare esattamente tali probabilit√† al variare
di \(e_1\) e di \(e_2\). In altre parole √® possibile, dato \(\alpha \in [0, 1] \subseteq \mathbb{R}\), determinare dei corrispondenti valori
di \(e_1\) e di \(e_2\) tali che risulti \(P(\theta \in [\hat{\theta} - e_1, \hat{\theta} + e_2]) = 1 - \alpha\), dove \(\hat{\theta}\) √® una realizzazione
dello stimatore \(H_n\).
</p>

<p>
In questo caso il valore \(\alpha\) √® detto <i>livello di confidenza</i> della stima ed il corrispondente intervallo √® detto
<i>intervallo di confidenza</i>.
</p>

<p>
I valori solitamente utilizzati come livello di fiducia (confidenza) \(\alpha\) sono 0.1, 0.05 e 0.01.
</p>

<p>
Vedremo qui come si costruiscono degli intervalli di confidenza per la media di una popolazione. Nel farlo distingueremo
tra il caso in cui la popolazione non sia normalmente distribuita ed il caso in cui la popolazione sia normalmente
distribuita.
</p>

<p>
Suddividiamo il problema della determinazione di un intervallo di confidenza per il valor medio \(\mu\) in 4 sottocasi a
seconda che la popolazione sia o non sia normalmente distribuita e che la varianza sia o non sia nota.
</p>
</div>

<ol class="org-ol">
<li><a id="org2bc2ef5"></a><i>Popolazione non normalmente distribuita e varianza \(\sigma^2\) nota</i><br />
<div class="outline-text-5" id="text-2-5-4-1">
<p>
In questo caso la media campionaria \(\bar{X}_n = \frac{X_1 + \dots + X_n}{n}\) √® approssimabile per \(n \geq 30\), tramite una variabile
con distribuzione normale di media \(\mu\) e deviazione standard \(\frac{\sigma}{\sqrt{n}}\).
</p>

<p>
Pensiamo allora a \(\bar{X}_n \sim N \left(\mu, \frac{\sigma}{\sqrt{n}}\right)\), dove l'unico parametro incognito √® \(\mu\).
</p>

<p>
Normalizzando abbiamo quanto segue: \(Z = \frac{\bar{X}_n - \mu}{\frac{\sigma}{\sqrt{n}}} \sim N(0, 1)\).
</p>

<p>
I valori assunti dalla variabile \(Z\) cos√¨ definita dipenderanno ovviamente dalle realizzazioni di \(\bar{X}_n\) e
quindi dalle realizzazioni del campione \((X_1, \dots, X_n)\)
</p>

<p>
Nonostante ci√≤, in base alla relazione \(Z = \frac{\bar{X}_n - \mu}{\frac{\sigma}{\sqrt{n}}} \sim N(0, 1)\), siamo in grado di
determinare un valore \(z_{1 - \frac{\alpha}{2}}\) per cui valga la seguente relazione
\(P\left(Z \in \left[-z_{1 - \frac{\alpha}{2}} , z_{1-\frac{\alpha}{2}}\right]\right) = 1 - \alpha\)
e quindi anche
\(P \left(\mu - z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}} \leq \bar{X}_n \leq \mu + z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}\right) = 1 - \alpha\).
</p>

<p>
Pertanto, in base all'ultima relazione sappiamo che con probabilit√† \(1 - \alpha\) lo stimatore \(\bar{X}_n\) assume valori in
un ben definito intervallo, ma ancora dipendente da \(\mu\). A questo punto √® possibile scrivere
\[P \left(\bar{X}_n - z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X}_n + z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}\right) = 1 - \alpha\]
</p>

<p>
Pertanto, in base all'ultima relazione, possiamo dire che data una realizzazione \(\bar{x}_n\) di \(\bar{X}_n\), il
parametro incognito \(\mu\) √® compreso nell'intervallo
\(P \left(\bar{x}_n - z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}, \bar{x}_n + z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}\right)\)
con probabilit√† \((1 - \alpha)\). Pertanto questo √® proprio l'intervallo di confidenza cercato.
</p>

<p>
Occorre fare ancora 2 considerazioni.
</p>

<p>
La prima √® che quello cos√¨ ricavato non √® l'unico intervallo di confidenza
ottenibile per il livello di fiducia \(\alpha\). Esso √® quello chiamato <i>simmetrico</i> in cui i 2 estremi sono pensati alla stessa distanza
dalla realizzazione \(\bar{x}_n\). Avremmo per√≤ potuto scegliere anche diversi valori di \(z_1\) e \(z_2\) per cui
\(P(Z \in [-z_1, +z_2]) = 1 - \alpha\). Da questa espressione, ragionando come sopra, saremmo poi arrivati ad ottenere un intervallo di
fiducia alternativo, ovvero:
\(P \left(\bar{x}_n - z_1 \frac{\sigma}{\sqrt{n}}, \bar{x}_n + z_2 \frac{\sigma}{\sqrt{n}}\right)\)
</p>

<p>
Una seconda considerazione √® che occorre sempre ricordare che questo metodo √® applicabile quando la numerosit√† del campione √®
sufficientemente grande. In generale lo si applica quando \(n\) √® maggiore o uguale a 30, anche se √® ammissibile applicarlo
anche per valori pi√π piccoli (\(n = 10\)) nel caso in cui si sappia che la distribuzione della popolazione non si discosta molto da
una normale o almeno √® simmetrica rispetto al suo valor medio.
</p>
</div>
</li>

<li><a id="orga565bc9"></a><i>Popolazione non normalmente distribuita e varianza \(\sigma^2\) non nota</i><br />
<div class="outline-text-5" id="text-2-5-4-2">
<p>
In questo caso si ragiona analogamente a quanto sopra, andando per√≤ a sostituire al valore \(\sigma\) la sua stima \(\hat{s}_n\)
ottenuta come realizzazione della statistica \(\hat{S}_n = \sqrt{\hat{S}_n^2}\), dove \(\hat{S}_n^2\) √® la varianza campionaria
corretta definita precedentemente. Si pu√≤ mostrare infatti che per \(n\) sufficientemente grande, anche la variabile
\(Z = \frac{\bar{X}_n - \mu}{\frac{\hat{S}_n}{\sqrt{n}}}\) risulta essere approssimativamente una normale standardizzata.
</p>

<p>
Pertanto per \(n \geq 30\), quando non √® nota la varianza della popolazione, √® possibile definire un intervallo di confidenza
per la media \(\mu\):
\[P \left(\bar{X}_n - z_{1-\frac{\alpha}{2}} \frac{\hat{S}_n}{\sqrt{n}} \leq \mu \leq \bar{X}_n + z_{1-\frac{\alpha}{2}} \frac{\hat{S}_n}{\sqrt{n}}\right) = 1 - \alpha\]
</p>

<p>
Per esempio, riprendiamo nuovamente in considerazione la tabella
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-04-26_22-01-26.png" alt="screenshot_2018-04-26_22-01-26.png" />
</p>
</div>

<p>
e supponiamo di voler determinare un intervallo di confidenza per la media della popolazione richiedendo un livello di fiducia
\(\alpha = 0.05\). Poich√© nel nostro caso la varianza della popolazione non √® nota, avremo
\[\left[\bar{X}_{80} - z_{1-\frac{0.05}{2}} \frac{\hat{S}_{80}}{\sqrt{80}} \leq \mu \leq \bar{X}_{80} + z_{1-\frac{0.05}{2}}
\frac{\hat{S}_{80}}{\sqrt{80}}\right] \subseteq \mathbb{R}\]
L'intervallo ottenuto √® \(I = [2.41, 2.94]\) e con probabilit√† \((1 - 0.05) = 0.95\) contiene il valore effettivo della media \(\mu\).
</p>

<p>
Per lo stesso livello di fiducia avremmo potuto scegliere un diverso intervallo di confidenza. Supponiamo ad esempio di
essere interessati a determinare una limitazione superiore per il parametro \(\mu\) e sempre con livello di fiducia \(\alpha = 0.05\).
In questo caso occorre determinare il valore \(z_{1-\alpha}\) tale che \(P(Z \in [-\infty, +z_{1-\alpha}]) = 1 - \alpha\).
</p>

<p>
A questo punto osserviamo che dall'uguaglianza precedente si ottiene:
</p>
\begin{align*}
&P \left(\bar{X}_{80} - \infty \frac{\hat{S}_{80}}{\sqrt{80}} \leq \mu \leq \hat{X}_{80} + z_{1 - \alpha} \frac{\hat{S}_{80}}{\sqrt{80}}\right) =\\
&= P\left(-\infty \leq \mu \leq \hat{X}_{80} + z_{1 - \alpha} \frac{\hat{S}_{80}}{\sqrt{80}}\right) =\\
&= 1 - \alpha
\end{align*}

<p>
Il valore di \(z_{1-\alpha}\) si ricava facilmente dalle tavole della distribuzione normale come il quantile che lascia alla sua
destra un'area uguale a 0.05 e risulta \(z_{1 - \alpha} = 1.65\) per cui l'intervallo desiderato √® \((- \infty, 2.90)\). In definitiva
√® possibile affermare che il parametro \(\mu\) √® minore di 2.90 con probabilit√† 0.95.
</p>
</div>
</li>

<li><a id="org61ab4c2"></a><i>Popolazione normalmente distribuita e varianza \(\sigma^2\) nota</i><br />
<div class="outline-text-5" id="text-2-5-4-3">
<p>
In questo caso sappiamo che la media campionaria \(\bar{X}_n = \frac{X_1 + \dots + X_n}{n}\) √® ancora una variabile con distribuzione
normale di media \(\mu\) e deviazione standard \(\frac{\sigma}{\sqrt{n}}\).
</p>

<p>
Possiamo ragionare esattamente come per il caso di popolazione non normalmente distribuita e varianza nota con l'unica differenza
che ora non viene fatta alcuna richiesta sulla numerosit√† del campione. Si pu√≤ pertanto continuare ad utilizzare la formula:
\[P \left(\bar{X}_n - z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X}_n + z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}\right) = 1 - \alpha\]
</p>
</div>
</li>
<li><a id="org684418c"></a><i>Popolazione normalmente distribuita e varianza \(\sigma^2\) non nota</i><br />
<div class="outline-text-5" id="text-2-5-4-4">
<p>
La variabile di cui si fa uso in questo caso √® \(T_n = \frac{\bar{X}_n - \mu}{\frac{\hat{S}_n}{\sqrt{n}}}\),
che per quanto detto in precedenza √® distribuita secondo una t di Student con \((n-1)\) gradi di libert√†.
</p>

<p>
Facendo uso delle tavole della t di Student √® possibile determinare un valore \(t_{1-\frac{\alpha}{2}}\) per cui valga
\(P \left(T_n \in \left[-t_{1-\frac{\alpha}{2}, n-1}, t_{1-\frac{\alpha}{2}, n-1}\right]\right) = 1 - \alpha\)
e quindi anche
\(P\left(-t_{1-\frac{\alpha}{2}} \frac{\hat{S}_n}{\sqrt{n}} \leq \bar{X}_n - \mu \leq t_{1-\frac{\alpha}{2}} \frac{\hat{S}_n}{\sqrt{n}}\right) = 1 - \alpha\)
</p>

<p>
A questo punto la precedente diseguaglianza pu√≤ essere riscritta come
\[P\left(\bar{X}_n-t_{1-\frac{\alpha}{2}} \frac{\hat{S}_n}{\sqrt{n}} \leq \mu \leq \bar{X}_n + t_{1-\frac{\alpha}{2}} \frac{\hat{S}_n}{\sqrt{n}}\right) = 1 - \alpha\]
</p>

<p>
Ci√≤ significa che date le realizzazioni \(\bar{x}_n\) di \(\bar{X}_n\) ed \(\hat{s}_n\) di \(\hat{S}_n\), il parametro incognito \(\mu\)
√® compreso nell'intervallo
\[\left[\bar{x}_n - t_{1-\frac{\alpha}{2}} \frac{\hat{s}_n}{\sqrt{n}}, \bar{x}_n + t_{1-\frac{\alpha}{2}} \frac{\hat{s}_n}{\sqrt{n}}\right]\]
con probabilit√† \((1 - \alpha)\).
Pertanto \(\left(\bar{x}_n - t_{1-\frac{\alpha}{2}} \frac{\hat{s}_n}{\sqrt{n}}, \bar{x}_n + t_{1-\frac{\alpha}{2}} \frac{\hat{s}_n}{\sqrt{n}}\right)\)
√® l'intervallo di confidenza cercato.
</p>

<p>
Anche in questo caso √® necessario precisare che questo intervallo non √® l'unico ricavabile per il dato livello di fiducia.
</p>

<p>
Questo intervallo √® <i>simmetrico</i>, ovvero i 2 estremi sono pensati alla stessa distanza dalla realizzazione \(\bar{x}_n\).
Avremmo per√≤ potuto scegliere anche valori diversi di \(t_1\) e \(t_2\) per cui \(P(T_n \in [-t_1, t_2]) = 1 - \alpha\) da cui si ottiene
un intervallo di fiducia alternativo \(\left[\bar{x}_n - t_1 \frac{\hat{s}_n}{\sqrt{n}}, \bar{x}_n + t_2 \frac{\hat{s}_n}{\sqrt{n}}\right]\)
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-orgb047b2e" class="outline-4">
<h4 id="orgb047b2e"><span class="section-number-4">2.5.5</span> Intervalli di Confidenza per la Varianza</h4>
<div class="outline-text-4" id="text-2-5-5">
<p>
Vediamo ora come determinare un intervallo di confidenza per la varianza \(\sigma^2\) della popolazione. Purtroppo non possiamo dire
nulla quando la popolazione non √® normalmente distribuita. √à vero che la distribuzione campionaria della statistica \(S_n^2\)
per \(n\) sufficientemente grande pu√≤ essere approssimata da una normale. Purtroppo per√≤ l'espressione
\(V[S_n^2] = \frac{1}{n} \left(E[(X - \mu)^4] - \frac{n-3}{n-1} \cdot \sigma^4 \right)\) della varianza di tale statistica non consente di far
uso di questa propriet√†.
</p>

<p>
Possiamo invece definire un intervallo fiduciario per \(\sigma^2\) quando la popolazione da cui √® stato estratto il campione √®
normalmente distribuita facendo uso del fatto che in tale caso la variabile \(Q_n = \frac{(n-1) \cdot \hat{S}_n^2}{\sigma^2}\) √®
distribuita secondo una Chi-Quadro con \((n-1)\) gradi di libert√†.
</p>

<p>
Utilizzando le tavole della distribuzione Chi-Quadro, √® possibile determinare almeno 2 valori \(q_1\) e \(q_2\) per i quali vale
\(P(Q_n \in [q_1, q_2]) = 1 - \alpha\) e quindi \(P\left(q_1 \leq \frac{(n-1) \cdot \hat{S}_n^2}{\sigma^2} \leq q_2 \right) = 1 - \alpha\).
</p>

<p>
Risolvendo la diseguaglianza rispetto al parametro incognito \(\sigma^2\):
\[P \left(\frac{(n-1) \cdot \hat{S}_n^2}{q_2} \leq \sigma^2 \leq \frac{(n-1) \cdot \hat{S}_n^2}{q_1}\right) = 1 - \alpha\]
Ci√≤ significa che date le realizzazioni \(\hat{s}_n^2\) di \(\hat{S}_n^2\), il parametro incognito \(\sigma^2\) √® compreso nell'intervallo
\[\left[\frac{(n-1) \cdot \hat{s}_n^2}{q_2}, \frac{(n-1) \cdot \hat{s}_n^2}{q_1}\right]\]
con probabilit√† \((1 - \alpha)\) e pertanto questo √® l'intervallo di confidenza cercato.
</p>

<p>
Anche in questo caso occorre sengnalare che quello definito tramite
\[P \left(\frac{(n-1) \cdot \hat{S}_n^2}{q_2} \leq \sigma^2 \leq \frac{(n-1) \cdot \hat{S}_n^2}{q_1}\right) = 1 - \alpha\]
non √® l'unico intervallo di confidenza ottenibile per il livello \(\alpha\) in quanto √® possibile scegliere pi√π coppie di valori
\(q_1\) e \(q_2\). Solitamente viene utilizzata la coppia \(q_{\frac{\alpha}{2}} \quad q_{1-\frac{\alpha}{2}}\), costituita dai 2 quantili
\(\frac{\alpha}{2}\) e \(1 - \frac{\alpha}{2}\) della distribuzione Chi-Quadro con \((n-1)\) gradi di libert√†.
</p>

<p>
Per esempio, riprendiamo in considerazione i carichi a rottura delle travi di cemento dati dalla seguente tabella:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-04-27_17-36-57.png" alt="screenshot_2018-04-27_17-36-57.png" />
</p>
</div>

<p>
E sotto l'ipotesi di distribuzione normale si voglia determinare un intervallo di confidenza per la varianza con livello
di fiducia \(\alpha = 0.01\). Occorre allora far ricorso alla seguente formula:
\[P \left(\frac{(n-1) \cdot \hat{S}_n^2}{q_2} \leq \sigma^2 \leq \frac{(n-1) \cdot \hat{S}_n^2}{q_1}\right) = 1 - \alpha\]
scegliendo 2 opportuni valori \(q_1\) e \(q_2\).
</p>

<p>
Potremmo prendere ad esempio i 2 quantili della Chi-Quadro con 14 gradi di libert√† che lasciano rispettivamente un'area
uguale a 0.005 alla loro sinistra ed alla loro destra. Consultando le tavole della Chi-Quadro si vede che i 2 quantili
cercati sono \(q_{\frac{0.01}{2}} = 4.07 \quad q_{1-\frac{0.01}{2}} = 31.3\).
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-04-27_17-42-20.png" alt="screenshot_2018-04-27_17-42-20.png" />
</p>
</div>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-04-27_17-41-35.png" alt="screenshot_2018-04-27_17-41-35.png" />
</p>
</div>

<p>
Inoltre la realizzazione \(\hat{s}_{15}^2\) di \(\hat{S}_{15}^2\) √® \(\hat{s}_{15}^2 = 48266\).
</p>

<p>
L'intervallo di confidenza cercato √® \(I = \left[\frac{14 \cdot 48266}{31.3}, \frac{14 \cdot 48266}{4.07}\right] = [21588, 166025]\).
</p>

<p>
Ancora una volta avremmo potuto scegliere un intervallo diverso per lo stesso livello di confidenza, ad esempio prendendo
i quantili \(q_1 = 0\) e \(q_2 = 29.1\), ottenendo \(P(q_1 \leq Q_{15} \leq q_2) = 0.99\) quando \(Q_{15} \sim \chi_{14}^2\). Ragionando come sopra si ricava
l'intervallo fiduciario \(I = \left[\frac{14 \cdot \hat{s}_{15}^2}{q_2}, \frac{14 \cdot \hat{s}_{15}^2}{q_1}\right] = [23220, \infty]\).
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-04-27_17-47-55.png" alt="screenshot_2018-04-27_17-47-55.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-orgd7b1626" class="outline-4">
<h4 id="orgd7b1626"><span class="section-number-4">2.5.6</span> Considerazioni sulla Numerosit√† del Campione</h4>
<div class="outline-text-4" id="text-2-5-6">
<p>
In base alle formule:
\[P\left(\bar{X}_n-z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X}_n + z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}\right) = 1 - \alpha\]
\[P\left(\bar{X}_n-t_{1-\frac{\alpha}{2}} \frac{\hat{S}_n}{\sqrt{n}} \leq \mu \leq \bar{X}_n + t_{1-\frac{\alpha}{2}} \frac{\hat{S}_n}{\sqrt{n}}\right) = 1 - \alpha\]
appare evidente che mantenendo fisso il livello di confidenza \(\alpha\), l'ampiezza dell'intervallo si riduce al crescere di \(n\).
</p>

<p>
Questo accade anche nel caso della stima di \(\sigma^2\) per popolazioni normalmente distribuite anche se non √® evidente dalla formula
\[P \left(\frac{(n-1) \cdot \hat{S}_n^2}{q_2} \leq \sigma^2 \leq \frac{(n-1) \cdot \hat{S}_n^2}{q_1}\right) = 1 - \alpha\]
poich√© il restringimento dell'intervallo di fiducia segue dalla variazione dei gradi di libert√† della Chi-Quadro con cui √®
distribuita la statistica \(Q_n\).
</p>

<p>
Volendo, nella definizione di un intervallo di confidenza per il valor medio √® possibile decidere in anticipo l'ampiezza
dell'intervallo e quindi fissare di conseguenza la numerosit√† del campione come mostrato nell'esempio seguente.
</p>

<p>
Per esempio, riprendiamo in considerazione il problema nel quale si sono determinati 2 intervalli di confidenza per la
media \(\mu\) del costo al metro quadro delgli appartamenti di un dato quartiere di una citt√† italiana.
</p>

<p>
Si voglia determinare quanto deve essere grande il campione affinch√© l'intervallo di confidenza simmetrico abbia ampiezza non
superiore a 0.3 mantenendo sempre un livello di confidenza \(\alpha = 0.05\).
</p>

<p>
In base alla formula
\[P\left(\bar{X}_n-t_{1-\frac{\alpha}{2}} \frac{\hat{S}_n}{\sqrt{n}} \leq \mu \leq \bar{X}_n + t_{1-\frac{\alpha}{2}} \frac{\hat{S}_n}{\sqrt{n}}\right) = 1 - \alpha\]
√® immediato osservare che l'ampiezza di un intervallo di confidenza simmetrico per \(\alpha=0.05\) risulta essere uguale a:
\[ 2 \cdot z_{1 - \frac{\alpha}{2}} \cdot \frac{\hat{S}_n}{\sqrt{n}} = 2 \cdot 1.96 \cdot \frac{\hat{S}_n}{\sqrt{n}} = 3.92 \cdot \frac{\hat{S}_n}{\sqrt{n}}\]
Poich√© la deviazione standard non √® nota, possiamo sostituirla con una stima e la pi√π indicata √® ovviamente:
\(\hat{s}_n = \hat{s}_{80} = 1.22\).
</p>

<p>
Pertanto l'ampiezza risulta essere uguale a
\[\frac{3.92 \cdot 1.22}{\sqrt{n}} = \frac{4.783}{\sqrt{n}}\]
Notiamo che questa diminuisce con l'aumentare della numerosit√† del campione, pertanto, per avere l'ampiezza minore di 0.3,
occorrer√† avere \(n\) sufficientemente grande.
\[ \frac{4.783}{\sqrt{n}} \leq 0.3 \iff \frac{4.783}{0.3} \leq \sqrt{n} \iff 15.94 \leq \sqrt{n} \iff 254.13 \leq n\]
In particolare risulta un'ampiezza poco minore a 0.3 quando \(n=255\).
</p>
</div>
</div>
<div id="outline-container-orgba8f11c" class="outline-4">
<h4 id="orgba8f11c"><span class="section-number-4">2.5.7</span> Stime di parametri</h4>
<div class="outline-text-4" id="text-2-5-7">
<p>
Per effettuare stime puntuali di parametri esistono altri metodi oltre a quelli appena presentati. I due pi√π noti
vengono di seguito descritti.
</p>

<p>
Il primo prende il nome di <i>metodo dei momenti</i> e si applica nel caso in cui sia nota l'espressione funzionale della densit√†
di probabilit√† della popolazione a meno di uno o pi√π parametri incogniti. Supponiamo quindi che la popolazione considerata
\(X\) abbia una densit√† di probabilit√† \(f_X(t)\) dipendente da \(m\) parametri incogniti \(\theta_1, \dots, \theta_m\).
</p>

<p>
Consideriamo ora i primi \(m\) momenti centrali della variabile \(X\): \(\mu_k = E[X^k] \ k = 1, \dots, m\). I valori da essi assunti sono
delle funzioni dei parametri, ovvero: \(\mu_k = \mu_k (\theta_1, \dots, \theta_m)\) per ogni \(k = 1, \dots, m\). Consideriamo poi i corrispondenti primi
\(m\) momenti campionari definiti come \(\bar{X}_n^k = \frac{1}{n} \sum_{i=1}^n X_i^k\) con \(k = 1, \dots, m\) e dove \((X_1, \dots, X_n)\) √® il
campione estratto dalla popolazione.
</p>

<p>
Denotiamo infine con \(\bar{x}_n^k\) le realizzazioni (note) dei momenti campionari \(\bar{X}_n^k\). Le stime dei parametri
\(\theta_1, \dots, \theta_m\) si ottengono risolvendo rispetto ad esse il sistema in \(m\) equazioni ed \(m\) incognite:
</p>
\begin{equation*}
\begin{cases}
\mu_1 (\theta_1, &\dots, \theta_m) = \bar{x}_n^1\\
&\vdots\\
\mu_m (\theta_1, &\dots, \theta_m) = \bar{x}_n^{m}
\end{cases}
\end{equation*}

<p>
Per esempio, sia \(X\) una variabile che descrive il tempo necessario ad ottenere la concessione per la ristrutturazione di
un immobile in una determinata provincia italiana, in mesi, e si voglia stimare la sua distribuzione in base ad un
campione di numerosit√† 10 la cui realizzazione √® \((x_1, \dots, x_{10}) = (3, 4.1, 2.8, 5.5, 1.5, 2.2, 6, 1.2, 3.2, 0.9)\).
</p>

<p>
Supponiamo poi sia ragionevole pensare che la distribuzione di \(X\) sia una Gamma e di volerne stimare i parametri
\(\alpha\) e \(\lambda\) con il metodo dei momenti.
</p>

<p>
Una variabile aleatoria \(X\) √® distribuita secondo una Gamma di parametri \(\alpha\) e \(\lambda\), con \(\alpha\) e \(\lambda \in \mathbb{R}_+\):
</p>
\begin{equation*}
f_X(t) =
\begin{cases}
0 &\text{se $t < 0$}\\
\lambda e^{-\lambda t} \frac{(\lambda t)^{\alpha - 1}}{\Gamma (\alpha)} &\text{se $t \geq 0$}
\end{cases}
\end{equation*}
<p>
Media e varianza sono date da \(E[X] = \frac{\alpha}{\lambda}\) e \(V[X] = \frac{\alpha}{\lambda^2}\).
</p>

<p>
Essendo 2 i parametri da stimare, occorre allora calcolare i primi 2 momenti campionari:
\[\bar{x}_{10}^{1} = \frac{1}{10} \cdot \sum_{i=1}^{10} x_i = 3.04\]
\[\bar{x}_{10}^{-2} = \frac{1}{10} \cdot \sum_{i=1}^{10} x_i^2 = 11.95\]
ed i corrispondenti momenti teorici della distribuzione:
\[E[X] = \frac{\alpha}{\lambda}\]
\[E[X^2] = V[X] + (E[X])^2 = \frac{\alpha}{\lambda^2} + \frac{\alpha^2}{\lambda^2} = \frac{\alpha (\alpha +1 )}{\lambda^2}\]
</p>

<p>
Le stime dei parametri si ottengono risolvendo il sistema:
</p>
\begin{equation*}
\begin{cases}
E[X] = \frac{\alpha}{\lambda} &= 3.04 \quad &\implies x_{10}^{-1} = 3.04\\
E[X^2] = \frac{\alpha (\alpha + 1)}{\lambda^2} &= 11.95 \quad &\implies x_{10}^{-2} = 11.95
\end{cases}
\end{equation*}
<p>
che fornisce la soluzione \(\lambda = 1.123\) e \(\alpha = 3.415\).
</p>

<p>
Le stime ottenute con questo metodo che √® storicamente il pi√π antico non sono in genere particolarmente efficienti,
ma grazie alla semplicit√† con cui possono essere ottenute sono utili soprattutto nel fornire delle prime approssimazioni.
</p>

<p>
Un secondo metodo, decisamente pi√π valido dal punto di vista matematico, √® quello che porta il nome di
<i>metodo della massima verosimiglianza</i>. Anche questo metodo √® applicabile quando sia nota l'espressione funzionale
della densit√† di probabilit√† della popolazione a meno di uno o pi√π parametri incogniti che si vogliono stimare.
</p>

<p>
Per semplicit√†, supponiamo questa volta che la popolazione considerata \(X\) abbia una densit√† di probabilit√† \(f_X(t)\)
dipendente da un singolo parametro \(\theta\) incognito.
</p>

<p>
Consideriamo la funzione di densit√† congiunta di un campione \((X_1, \dots, X_n)\) di numerosit√† \(n\). Per via dell'indipendenza
tra le variabili \(X_i\) abbiamo \(f_{X_1, \dots, X_n} (t_1, \dots, t_n) = f_X(t_1) \cdot \dots \cdot f_X(t_n)\).
</p>

<p>
Ricordando che l'espressione di \(f_X\) √® nota a meno del parametro \(\theta\), osserviamo che tale densit√† congiunta pu√≤ essere
riscritta come \(f_{X_1, \dots, X_n} (t_1, \dots, t_n) = L(t_1, \dots, t_n, \hat{\theta})\).
</p>

<p>
La funzione \(L\) prende il nome di <i>funzione di verosimiglianza</i> di dimensione \(n\). Sia ora \((x_1, \dots, x_n)\) la realizzazione
del campione \((X_1, \dots, X_n)\). Notiamo che al variare del valore \(\hat{\theta}\) assegnato al parametro \(\theta\), varia anche la
quantit√† \(L(x_1, \dots, x_n, \hat{\theta})\) che possiamo pensare come la probabilit√† che il campione assuma valore \((x_1, \dots, x_n)\)
quando il parametro assume valore \(\hat{\theta}\).
</p>

<p>
Ovviamente il valore \(\hat{\theta}\) √® tanto pi√π indicato ad essere l'effettivo valore del parametro \(\theta\) quanto pi√π √® alta
tale probabilit√†, cio√® quanto pi√π esso √® verosimile.
</p>

<p>
√à detta quindi <i>stima di massima verosimiglianza</i> per il parametro \(\theta\) quel valore \(\hat{\theta}\) che massimizza la funzione
di verosimiglianza \(L(x_1, \dots, x_n, \hat{\theta})\).
</p>

<p>
Si pu√≤ dimostrare che le stime cos√¨ ottenute sono sempre consistenti e nella maggior parte dei casi sono anche corrette
e con la massima efficienza.
</p>

<p>
Per esempio, si consideri lo stesso problema dell'esempio precedente supponendo per√≤ questa volta di ritenere ragionevole
pensare che la variabile \(X\) sia distribuita secondo un'esponenziale il cui parametro \(\lambda\) √® da stimare.
</p>

<p>
Data quindi una realizzazione \((x_1, \dots, x_{10}) = (3, 4.1, 2.8, 5.5, 1.5, 2.2, 6, 1.2, 3.2, 0.9)\) del campione,
la funzione di verosimiglianza risulta:
\[L(x_1, \dots, x_n, \lambda) = \prod_{i=1}^{10} \lambda \cdot e^{-\lambda x_i} = \lambda^{10} \cdot e^{-\lambda \cdot \sum_{i=1}^{10} x_i} = \lambda^{10} \cdot e^{-30.4 \lambda}\]
La stima di massima verosimiglianza del parametro si ricava andando a determinare il valore di \(\lambda\) per cui risulta
massima la funzione \(L(x_1, \dots, x_n, \lambda)\). Calcolandone la derivata
\[L'(x_1, \dots, x_n, \lambda) = 10 \cdot \lambda^9 e^{-30.4 \cdot \lambda} - 30.4 \cdot \lambda^{10} e^{-30.4 \cdot \lambda} = \lambda^9 e^{-30.4 \cdot \lambda} \cdot (10 - 30.4 \lambda)\]
√à facile ora osservare che il massimo si ottiene per quel valore di \(\lambda\) per cui \((10 - 30.4 \lambda) = 0\).
</p>

<p>
Pertanto per \(\lambda = \frac{10}{30.4} = 0.329\).
</p>

<p>
Si osservi che in realt√†, in questo particolare caso, la stima appena ricavata corrisponde a quella che avremmo ottenuto
stimando il valore atteso \(\mu\) con la media campionaria \(\bar{x}_{10} = 3.04\), e quindi ricordando che per una variabile
esponenziale vale:
\[\lambda = \frac{1}{E[X]} = \frac{1}{\lambda} \implies \lambda = \frac{1}{3.04} = 0.329\]
Tale osservazione non pu√≤ comunque essere generalizzata a tutte le stime ottenute con il metodo della massima
verosimiglianza.
</p>
</div>
</div>
</div>
<div id="outline-container-org5222ead" class="outline-3">
<h3 id="org5222ead"><span class="section-number-3">2.6</span> Verifica di ipotesi: test parametrici</h3>
<div class="outline-text-3" id="text-2-6">
<p>
Un'affermazione relativa ad una caratteristica di una popolazione √® detta <i>ipotesi statistica</i> quando essa viene formulata sulla base
dell'esperienza o sulla base di considerazioni teoriche. Il problema della <i>verifica di ipotesi</i> consiste nella verifica, da effettuarsi
tramite l'analisi di informazioni campionarie, della validit√† di un'ipotesi statistica. Per esempio affermare in base alla propria
esperienza che mediamente in una data citt√† il costo degli appartamenti √® di 3,000 euro al metro quadro o che tale costo √® indipendente
dal quartiere in cui √® situato l'appartamento vuol dire formulare delle ipotesi che devono essere controllate tramite un'analisi prima di
essere accettate come veritiere.
</p>

<p>
Per effettuare tali verifiche si utilizzano procedure statistiche dette: <i>test di ipotesi</i>. esse di suddividono in:
</p>
<ul class="org-ul">
<li><i>Test parametrici</i> che si riferiscono ad ipotesi relative ai parametri della distribuzione della popolazione (media o varianza);</li>
<li><i>Test non parametrici</i> che riguardano il tipo di distribuzione ipotizzabile per la popolazione o altre caratteristiche non
esprimibili come parametri.</li>
</ul>
</div>

<div id="outline-container-org4540d26" class="outline-4">
<h4 id="org4540d26"><span class="section-number-4">2.6.1</span> Caratteristiche generali di un test di ipotesi</h4>
<div class="outline-text-4" id="text-2-6-1">
<p>
Sia \(X\) una popolazione su cui vogliamo effettuare un test per confermare (o rifiutare) una particolare ipotesi che denotiamo con \(H_0\).
Sia poi \(T\) una statistica campionaria la cui distribuzione √® nota quando l'ipotesi \(H_0\) da controllare √® vera, i test di ipotesi si
basano sull'osservazione delle realizzazioni di statistiche campionarie di questo tipo. Infatti, essendo nota la distribuzione di \(T\)
quando \(H_0\) √® vera abbiamo un'idea dei valori che essa tende ad assumere in questo caso. Saremo quindi portati ad <i>accettare l'ipotesi
\(H_0\)</i>, o meglio a <i>non rifiutarla</i> quando il valore assunto da \(T\) si trova in un sottoinsieme di valori altamente probabili tra
quelli da essa assumibili quando \(H_0\) √® vera e a rifiutarla in caso contrario.
</p>

<p>
Pi√π specificamente ogni test di ipotesi √® caratterizzato da:
</p>
<ul class="org-ul">
<li><i>Una popolazione statistica \(X\)</i> sulla quale viene effettuato il test;</li>
<li><i>Un'ipotesi nulla \(H_0\)</i>: ipotesi da convalidare (o rifiutare) sulla base dei valori assunti da un campione \((X_1, \dots, X_n)\) estratto da \(X\);</li>
<li><i>Un'ipotesi alternativa \(H_1\)</i>: ovvero un'ipotesi da considerare valida quando si rifiuta l'ipotesi nulla;</li>
<li><i>Una statistica campionaria \(T = T(X_1, \dots, X_n)\)</i> di cui √® nota la distribuzione quando l'ipotesi nulla √® vera;</li>
<li><i>Una regione di accettazione</i>, denotata con \(\bar{C}\) che √® l'insieme di valori assumibili dalla statistica \(T\) che portano ad
un'accettazione dell'ipotesi nulla;</li>
<li><i>Una regione critica</i>, denotata con \(C\) che √® l'insieme di valori assumibili dalla statistica \(T\) che portano ad un rifiuto dell'ipotesi nulla;</li>
<li><i>Un livello di significativit√† \(\alpha\)</i>, permette di individuare la regione di accettazione ed √® tale che quando l'ipotesi nulla √® vera
allora la statistica \(T\) assume valori nella regione critica con probabilit√† \(\alpha\).</li>
</ul>

<p>
Per esempio, si supponga di sapere che il reddito medio annuo per famiglia di un determinato quartiere di una citt√† italiana sia distribuito
secondo una normale il cui parametro \(\sigma^2\) √® noto ed √® di 144K di euro mentre il parametro \(\mu\) √® incognito. In base alla sua esperienza
personale, un nostro collaboratore sostiene che la media √® uguale a 30K di euro. Si supponga di voler controllare tale affermazione con
un'indagine campionaria e per tale ragione intervistare 10 famiglie del quartiere scelte a caso. Si supponga infine di accettare
l'affermazione del collaboratore se la media aritmetica dei redditi annui delle famiglie √® compresa tra 25K e 35K euro e di rifiutarla in
caso contrario, decidendo in tal caso di effettuare un'indagine campionaria pi√π approfondita.
</p>

<p>
Vediamo allora quali sono in questo caso gli oggetti sopra elencati che caratterizzano il test. La <i>popolazione \(X\)</i> √® costituita dai redditi
annui dei nuclei familiari del quartiere, mentre <i>l'ipotesi nulla</i> √® \(H_0 : \mu = 30K ‚Ç¨\) e <i>l'ipotesi alternativa</i> √® \(H_1 : \mu \neq 30K ‚Ç¨\).
La <i>statistica campionaria \(T\)</i> √® la media aritmetica \(\bar{X}_{10} = \frac{X_1 + \dots + X_{10}}{10}\) dove \((X_1, \dots, X_{10})\) √® un <i>campione casuale</i> di
numerosit√† 10 estratto da \(X\). Poich√© accettiamo \(H_0\) quando \(\bar{X}_{10}\) √® compresa tra 25K e 35K euro allora la <i>regione di accettazione</i>
√® \(\bar{C} = [25, 35] \subseteq \mathbb{R}\), mentre la <i>regione critica</i> \(C = (-\infty, 25) \cup (35, \infty) \subseteq \mathbb{R}\).
</p>

<p>
Per determinare il <i>livello di significativit√†</i> occorre ricordare qual √® la distribuzione campionaria di \(\bar{X}_{10}\).
A tale proposito sappiamo che se la popolazione \(X\) √® normalmente distribuita con parametri \(\mu\) e \(\sigma\) allora anche la media
campionaria \(\bar{X}_{10}\) risulta essere normalmente distribuita con parametri \(\mu\) e \(\frac{\sigma}{\sqrt{10}}\).
</p>

<p>
Nel caso in cui sia vera \(H_0\), allora \(\bar{X}_{10} \sim N(30, 3.79)\) e la probabilit√† che \(\bar{X}_{10}\) cada nella regione critica risulta
\[P(\bar{X} \in C) = 1 - P(\bar{X}_{10} \in [25, 35]) = 1 - P\left(\frac{\bar{X} - 30}{3.79} \in [-1.32, +1.32]\right) = 0.18\]
</p>

<p>
Diverse considerazioni si potrebbero fare in merito all'esempio appena proposto. Una di queste segue dall'osservazione che esiste
una probabilit√† non nulla che la statistica \(\bar{X}_{10}\) cada nella regione critica anche quando \(H_0\) √® vera: \(P(\bar{X}_{10} \in C) = 0.18\).
Pu√≤ quindi capitare che il test porti ad un rifiuto di \(H_0\) nonostante essa sia vera. Similmente pu√≤ accadere che sia vera l'ipotesi
alternativa ma nonostante ci√≤ la statistica \(\bar{X}_{10}\) cada nella regione di accettazione \(\bar{C}\). In questo caso il test porta
ad accettare \(H_0\) quando in realt√† essa √® falsa.
</p>

<p>
Occorre allora tener presente che, come nell'esempio, i test di ipotesi non portano mai ad ottenere risposte certe. Tutte le accettazioni
(non rifiuti) di ipotesi (o i loro rifiuti) possono essere sempre soggette ad errore e devono essere considerate valide solo in via
provvisoria per poter essere rimesse in discussione in presenza di nuovi dati. Lo stesso termine utilizzato per indicare l'insieme di
valori che portano a rifiutare \(H_0\) sottolinea la presenza del dubbio: infatti la regione √® detta "critica" perch√© √® improbabile che
\(H_0\) sia vera quando la statistica campionaria assume valori appartenenti ad essa ma non possiamo comunque escluderlo. Inoltre, √®
pi√π corretto non dire che un'ipotesi nulla viene accettata quando la statistica test cade nella regione di accetazione, preferendo
affermare invece che essa "non pu√≤ essere rifiutata". Questo accade proprio perch√© ci√≤ che si controlla effettuando il test √® se
il dato fornito dalla statistica √® compatibile con l'ipotesi nulla sottoposta a test.
</p>

<p>
Per chiarire questo fatto supponiamo di aver accettato un'ipotesi nulla dopo aver svolto un test appropriato e proviamo a variare tale
ipotesi magari di poco (passando da \(\mu = 30\) a \(\mu = 31\)). In molti casi ripetendo il test gli stessi dati porterebbero ad una
nuova accettazione e ci troveremmo ad aver accettato due ipotesi che non sono identiche. √à meglio affermare che queste due ipotesi
non possono essere rifiutate sulla base delle nostre osservazioni.
</p>

<p>
Detto questo, osserviamo che gli errori che si possono commettere nell'effettuazione di un test sono di due tipi:
</p>
<ul class="org-ul">
<li>Errori di prima specie (I specie): sulla base delle osservazioni campionarie si rifiuta \(H_0\) quando √® vera;</li>
<li>Errori di seconda specie (II specie): sulla base delle osservazioni campionarie si accetta \(H_0\) quando √® falsa.</li>
</ul>

<p>
La probabilit√† di compiere errori di prima specie √® nota e coincide con il livello di significativit√† \(\alpha\) del test, mentre in genere non
√® nota la probabilit√† di compiere errori di seconda specie \(\beta\). Tornando all'esempio precedente √® possibile osservare che in esso si
√® fissata una regione di accettazione per \(H_0\) e solo successivamente √® stato determinato il livello di significativit√† \(\alpha\), la
probabilit√† di compiere errori di prima specie. Nella pratica si procede all'inverso, fissando un valore per \(\alpha\) e solo successivamente,
in base anche alla dimensione del campione di cui si dispone, la regione critica viene determinata.
</p>

<p>
La <i>procedura per la formulazione di un test di ipotesi</i> solitamente prevede, nell'ordine:
</p>
<ul class="org-ul">
<li>L'individuazione dell'ipotesi nulla \(H_0\) e dell'ipotesi alternativa \(H_1\);</li>
<li>La scelta della significativit√† \(\alpha\);</li>
<li>La determinazione della statistica campionaria \(T\) da utilizzare nel test;</li>
<li>La determinazione delle regioni di accettazione e critica;</li>
<li>L'accettazione o il rifiuto di \(H_0\) in base all'osservazione dei dati campionari.</li>
</ul>

<p>
Una terza considerazione che pu√≤ essere fatta in merito all'esempio √® relativa alla scelta delle ipotesi \(H_0\) e \(H_1\). In effetti si
sarebbe potuti essere interessati a controllare l'ipotesi che il reddito medio annuo delle famiglie fosse superiore a 30K euro o
sufficientemente vicino a 30K o ancora inferiore a 20K euro. Avremmo allora potuto considerare ipotesi nulle diverse a cui sarebbero
state associate regioni critiche diverse.
</p>

<p>
Un'ipotesi statistica √® detta <i>semplice</i> se il sottoinsieme di valori che essa assegna ad un parametro √® costituito da un solo elemento,
√® detta <i>composta</i> in caso contrario.
</p>

<p>
L'ipotesi considerata nell'esempio precedente √® un caso di ipotesi semplice, mentre sarebbero state ipotesi composte le
\(H_0' : \mu \in [25, 35] \quad H_0'' : \mu > 30 \quad H_0''' : \mu = 30 \text{ oppure } 31\).
Infine, volendo controllare un'ipotesi composta del tipo della \(H_0''\) non avrebbe avuto senso considerare come regione critica quella
proposta nell'esempio precedente: \(C = (-\infty, 25) \cup (35, +\infty) \subseteq \mathbb{R}\). Infatti, sarebbe errato rifiutare l'ipotesi che la
media sia maggiore di 30K quando la statistica campionaria assume valori grandi. Una regione critica appropriata √® \(C = (-\infty, 25) \subseteq \mathbb{R}\).
</p>

<p>
Un test statistico √® detto <i>bidirezionale</i> se la regione critica √® costituita dall'unione di due sottoinsiemi disgiunti mentre diciamo
che un test √® <i>unidirezionale</i> se la regione critica √® costituita da un solo sottoinsieme. Ovviamente i <i>test bidirezionali</i> si utilizzano
quando si controllano ipotesi quali \(H_0 : \mu = 30K ‚Ç¨ \quad H_0' : \mu \in [25, 35]\), mentre i <i>test unidirezionali</i> vengono utilizzati per controllare
ipotesi quali \(H_0'' : \mu > 30\).
</p>
</div>
</div>
<div id="outline-container-orgd1ba168" class="outline-4">
<h4 id="orgd1ba168"><span class="section-number-4">2.6.2</span> Considerazioni sugli errori di I e II specie</h4>
<div class="outline-text-4" id="text-2-6-2">
<p>
Limitiamoci per il momento a considerare test statistici in cui l'ipotesi nulla √® semplice. Abbiamo visto che in questo caso nella fase
di costruzione del test siamo in grado di calcolare la probabilit√† di compiere errori di prima specie. Abbiamo anche accennato
al fatto che in realt√† le regioni di accettazione e di rifiuto dell'ipotesi nulla vengono determinate proprio in funzione di
tale propriet√†, detta livello di significativit√†. In generale non siamo in grado di calcolare la probabilit√† di compiere errori
di II specie. Saremmo in grado di farlo se sapessimo quale √® il reale valore del parametro a cui si riferisce il test, ma
purtroppo ci√≤ non √® possibile.
</p>

<p>
Per chiarire i termini del problema facciamo riferimento ancora una volta all'esempio precedente, supponendo che il reale
valore del parametro \(\mu\) sia 32K euro. Allora la popolazione \(X\) √® distribuita normalmente con parametri \(\mu = 32K\) e
\(\sigma^2 = 144K\) e la probabilit√† \(\beta(32)\) di compiere un errore di II specie risulta
</p>
\begin{align*}
\beta(32) &= P(\text{accettare } H_0 \text{ quando } \mu = 32)\\
&= P(\bar{X}_{10} \in [25, 35] \mid \bar{X}_{10} \approx N(32, 3.79))\\
&=P\left(\frac{\bar{X}_{10} - 32}{3.79} \in \left[\frac{25 - 32}{3.79}, \frac{35 - 32}{3.79}\right]\right)\\
&=P\left(\frac{\bar{X}_{10} - 32}{3.79} \in [-1.85, +0.79]\right)\\
&= 0.75
\end{align*}
<p>
Graficamente tale probabilit√† corrisponde all'area sottesa alla normale compresa tra i valori 25 e 35.
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-07_16-24-31.png" alt="screenshot_2018-06-07_16-24-31.png" />
</p>
</div>

<p>
In questo caso √® stato possibile determinare la probabilit√† di compiere un errore della II specie solo perch√© abbiamo
assunto come ipotesi alternativa \(\mu = 32\), escludendo che la media della popolazione possa assumere qualsiasi altro valore oltre che
30 e 32. In realt√† per√≤ \(\mu\) pu√≤ assumere qualsiasi altro valore \(\hat{\mu} \in \mathbb{R}-\{30\}\) ed ognuno di tali valori corrisponde
ad una diversa probabilit√† \(\beta(\hat{\mu})\) di compiere errori di II specie. Per tale ragione, nel descrivere le caratteristiche di un
test di ipotesi, la probabilit√† di compiere errori di II specie va pensata come una funzione anzich√© come uno specifico valore
numerico.
</p>

<p>
In particolare, √® uso comune considerare a tal fine una funzione detta <i>curva di potenza del test</i> che viene di seguito introdotta.
Sia a tal fine \(\theta\) il parametro a cui si riferisce il test e sia \(\theta^*\) il valore specificato dall'ipotesi nulla
\(H_0 : \theta = \theta^*\), denotiamo poi \(\beta(\hat{\theta}) = P(\text{accettare } H_0 \mid H_0 \text{ + falsa e } \theta = \hat{\theta})\), allora viene detta
<i>curva di potenza del test</i> la funzione \(\pi(\hat{\theta}) = \ - \beta(\hat{\theta})\). Un test risulta tanto migliore quanto pi√π la funzione
\(\pi(\hat{\theta})\) si avvicina, al variare di \(\hat{\theta}\) al valore 1.
</p>

<p>
Per esempio, supponiamo di voler effettuare un test di ipotesi relativo ad una popolazione \(X\) che sappiamo essere distribuita
secondo un'esponenziale di parametro \(\lambda\), e di voler controllare con significativit√† \(\alpha = 0.1\) l'ipotesi nulla \(H_0 : \lambda = 2\)
contro l'ipotesi alternativa \(H_1 : \lambda \neq 2\). Per rendere pi√π comprensibile l'esempio supponiamo di effettuare il test estraendo
un campione di numerosit√† 1 ovvero (\(X_1\)) e di rifiutare \(H_0\) se \(X_1\) assume valori "troppo piccoli" o "troppo grandi" per
poter pensare che sia distribuita secondo un'esponenziale di parametro \(\lambda = 2\). Prendiamo allora come regione di accettazione
del test l'intervallo \([t_1, t_2] \subseteq \mathbb{R}^+\), dove \(t_1\) e \(t_2\) sono tali che
\[P(X_1 \leq t_1 \mid X_1 \approx \text{Exp}(2)) = P(X_1 \geq t_2 \mid X_1 \approx \text{Exp}(2)) = \frac{\alpha}{2} = 0.05\]
In questo modo infatti risulta
</p>
\begin{align*}
P(\text{compiere errori di I specie}) &= P(\text{rifiutare $H_0$ quando $H_0$ √® vera})\\
&= P(X_1 \in (0, t_1) \cup (t_2, \infty) \mid X_1 \approx \text{Exp}(2))\\
&= \frac{\alpha}{2} + \frac{\alpha}{2} = \alpha
\end{align*}
<p>
Per determinare \(t_1\) e \(t_2\) ricordiamo che la funzione di ripartizione di una variabile aleatoria con distribuzione
Esponenziale di parametro 2 √®:
</p>
\begin{equation*}
F_2(t) =
\begin{cases}
0 &\text{se $t < 0$}\\
1 - e^{-2t} &\text{se $t \geq 0$}
\end{cases}
\end{equation*}
<p>
e che \(t_1\) e \(t_2\) devono essere tali da soddisfare
\[1 - e^{-2t_1} = F_2(t_1) = P(X_1 \leq t_1 \mid X_1 \approx \text{Exp}(2)) = 0.05\]
\[1 - e^{-2t_2} = F_2(t_2) = P(X_1 \leq t_2 \mid X_1 \approx \text{Exp}(2)) = 0.95\]
Con la formula inversa si ricava:
\[t_1 = -\frac{\ln{(1-0.05)}}{2} = 0.03 \quad t_2 = -\frac{\ln{(1 - 0.95)}}{2} = 1.50\]
Pertanto la regione di accettazione del test √® \(\bar{C} = [0.03, 1.50]\).
</p>

<p>
Vediamo ora di determinare le probabilit√† di compiere errori di II specie al variare dei possibili valori alternativi del
parametro
</p>
\begin{align*}
\beta(\hat{\lambda}) &= P(\text{accettare $H_0$ quando $\lambda = \hat{\lambda}$})\\
&= P(0.03 \leq X_1 \leq 1.50 \mid X_1 \approx \text{Exp}(\hat{\lambda}))\\
&= F_{\hat{\lambda}}(1.50) - F_{\hat{\lambda}}(0.03) = (1 - e^{-1.50 \hat{\lambda}}) - (1 - e^{0.03 \hat{\lambda}})\\
&= e^{-0.03 \hat{l}} - e^{-1.50 \hat{\lambda}}
\end{align*}
<p>
Come si pu√≤ osservare, tale quantit√† √® una funzione di \(\hat{\lambda}\):
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-07_17-31-26.png" alt="screenshot_2018-06-07_17-31-26.png" />
</p>
</div>

<p>
La <i>curva di potenza</i> √® la funzione \(\pi(\hat{\lambda}) = 1 - \beta(\hat{\lambda}) = 1 - e^{-0.03 \hat{l}} + e^{-1.50 \hat{\lambda}}\).
</p>

<p>
\(\pi(\hat{\lambda})\) si avvicina a 0 in corrispondenza di \(\hat{\lambda} = 2\) in quanto √® facile sbagliare ed accettare \(H_0\) quando il reale
valore di \(\lambda\) non si discosta troppo da quanto specificato dall'ipotesi nulla. Al contrario esso assume valori vicini ad 1 in
prossimit√† di \(\hat{\lambda} = 0\) e per valori grandi di \(\hat{\lambda}\) poich√© in questi casi difficilmente la statistica \(X_1\) assume
valori compresi nella regione di accettazione.
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-07_18-27-55.png" alt="screenshot_2018-06-07_18-27-55.png" />
</p>
</div>

<p>
Se nella costruzione di un test si desidera diminuire il livello di significativit√†, vale a dire la probabilit√† di compiere errori
di I specie, si pu√≤ ampliarne la regione di accettazione. In questo modo per√≤, com'√® facile osservare, diminuisce anche la
potenza del test, ovvero aumenta la probabilit√† di compiere errori della II specie.
</p>

<p>
Considerazioni analoghe a quelle fatte relativamente all'ampiezza degli intervalli fiduciari per la stima dei parametri
portano ad osservare che l'unica possibilit√† di far contemporaneamente diminuire il livello di significativit√† e aumentare
la potenza √® quella di aumentare la numerosit√† del campione. Questo infatti porta generalmente ad una diminuzione della
varianza della statistica campionaria \(T\) e quindi ad una maggiore sicurezza sui valori da essa assumibili condizionatamente
alle due ipotesi.
</p>

<p>
Per esempio, si consideri una popolazione \(X\) con distribuzione Bernoulliana di parametro incognito \(p\) e si supponga che \(p\)
possa assumere solo i due valori \(0.40\) e \(0.25\). Si supponga di voler controllare l'ipotesi \(H_0 : p = 0.25\) e di
estrarre per questo un campione di numerosit√† 30, considerarne la media campionaria \(\bar{X}_{30}\) e rifiutare l'ipotesi
nulla se essa assume un valore maggiore di 0.30. Vediamo quanto valgono in
questo caso il livello di significativit√† \(\alpha\) del test e al probabilit√† \(\beta(0.40)\) di compiere un errore di II specie.
</p>

<p>
Essendo la numerosit√† del campione sufficientemente grande si pu√≤ utilizzare un'approssimazione normale per \(\bar{X}_{30}\).
Ricordando che per una Bernoulliana di parametro \(p\) la media e la varianza valgono rispettivamente \(p\) e \((1-p)p\), e
considerando il Teorema Limite Centrale, si ricava che \(\bar{X}_{30} \sim N\left(p, \sqrt{\frac{(1-p)p}{30}}\right)\).
</p>

<p>
Se √® vera l'ipotesi nulla, allora:
</p>
\begin{align*}
\alpha &= P(\text{rifiutare $H_0 \mid H_0$ √® vera})\\
&= P(\bar{X}_{30} > 0.3 \mid \bar{X}_{30} \approx N(0.25, 0.08))\\
&= P\left(\frac{\bar{X}_{30} - 0.25}{0.08} > \frac{0.3 - 0.25}{0.08}\right)\\
&= 0.26
\end{align*}
<p>
Per determinare \(\beta(0.40)\) √® sufficiente osservare che
</p>
\begin{align*}
\beta &= P(\text{accettare $H_0 \mid H_1$ √® vera})\\
&= P(\bar{X}_{30} \leq 0.3 \mid \bar{X}_{30} \approx N(0.40, 0.09))\\
&= P\left(\frac{\bar{X}_{30} - 0.4}{0.09} \leq \frac{0.3 - 0.4}{0.09}\right)\\
&= 0.13
\end{align*}
<p>
Supponiamo ora di voler avere \(\alpha \leq 0.1\) e contemporaneamente \(\beta(0.40) \leq 0.1\). Per far diminuire la probabilit√† di compiere errori
della I specie basterebbe restringere la regione critica, ad esempio rifiutando \(H_0\) quando \(\bar{X}_{30} > 0.4\). In questo
caso infatti risulterebbe \(\alpha = 0.03\). Purtroppo per√≤, cos√¨ facendo, aumenterebbe \(\beta(0.40) = 0.5\). Per avere contemporaneamente
\(\alpha \leq 0.1\) e \(\beta(0.40) \leq 0.1\) occorre allora aumentare la numerosit√† del campione.
</p>

<p>
Se ad esempio viene posta uguale a 123 e se si mantengono la stessa regione critica e di accettazione, con i consueti calcoli si
verifica che \(\alpha = 0.1\) e \(\beta(0.40) = 0.012\).
</p>

<p>
Osserviamo che in questo esempio la probabilit√† di compiere errori di II specie √® un singolo valore numerico anzich√© una funzione
e ci√≤ perch√© l'ipotesi alternativa \(H_1 : p = 0.40\) √® un'ipotesi semplice, ovvero un solo valore assumibile alternativamente
a 0.25 dal parametro incognito.
</p>
</div>
</div>
<div id="outline-container-orgf6f53e7" class="outline-4">
<h4 id="orgf6f53e7"><span class="section-number-4">2.6.3</span> Test sulla media di una popolazione</h4>
<div class="outline-text-4" id="text-2-6-3">
<p>
Vediamo ora come si costruisce un test sulla media \(\mu\) di una popolazione \(X\) quando si formula l'ipotesi nulla che tale media
sia un valore fissato \(\mu_0\), ovvero quando si consideri \(H_0 : \mu = \mu_0\) e quando si dispone di un campione casuale
\((X_1, \dots, X_n)\) di numerosit√† \(n\) estratto da \(X\). Similmente a quanto fatto nel capitolo precedente per gli intervalli di confidenza,
la statistica utilizzata per effettuare il test varia a seconda che la popolazione considerata sia o meno normalmente distribuita
e che la sua varianza sia o non sia sconosciuta:
</p>
<ol class="org-ol">
<li><p>
<i>Popolazione normalmente distribuita e varianza \(\sigma^2\) nota</i>:
</p>

<p>
Sia \(\mu\) il valore reale del parametro. Ricordiamo che sotto le ipotesi di normalit√† di \(X\) la media campionaria
\(\bar{X}_n = \frac{X_1 + \dots + X_n}{n}\) ha distribuzione normale di media \(\mu\) e deviazione standard \(\frac{\sigma}{\sqrt{n}}\), ovvero
vale \(\tilde{Z} = \frac{\bar{X}_n - \mu}{\frac{\sigma}{\sqrt{n}}} \sim N(0, 1)\). Notiamo che \(\tilde{Z}\) non √® una statistica, infatti il valore
del parametro \(\mu\) non √® noto. Sia ora \(Z_n = \frac{\bar{X}_n - \mu_0}{\frac{\sigma}{\sqrt{n}}}\) che √® una statistica essendo \(\mu_0\)
una costante fissata. Ovviamente vale \(Z_n \sim N(0, 1)\) se e solo se vale \(H_0\). Il test si basa allora sull'osservazione
del valore assunto dalla realizzazione della statistica \(Z_n\), in particolare:
</p>
<ul class="org-ul">
<li>Rifiuteremo \(H_0\) se \(Z_n\) assumer√† valori "poco probabili" per una \(N(0, 1)\).</li>
</ul>
<p>
La definizione della regione critica per \(Z_n\) dipende dal livello di significativit√† adottato e dalla forma dell'ipotesi
alternativa. Possiamo infatti considerare le seguenti 3 ipotesi alternative:
</p>
<ol class="org-ol">
<li>Test bidirezionale: \(H_1' : \mu^2 \neq \mu_0^2\);</li>
<li>Test unidirezionale con coda a sinistra: \(H_1'' : \mu^2 < \mu_0^2\);</li>
<li>Test unidirezionale con coda a destra: \(H_1''' : \mu^2 > \mu_0^2\).</li>
</ol>
<p>
Pi√π in dettaglio:
</p>
<ol class="org-ol">
<li><p>
<i>Test bidirezionale</i>: \(H_1' : \mu \neq \mu_0\);
</p>

<p>
Ovviamente rifiuteremo l'ipotesi \(H_0\) in favore di \(H_1'\) quando \(Z_n\) assumer√† valori eccessivamente grandi o eccessivamente
piccoli per una \(N(0, 1)\). Specificamente, ragionando come nella definizione degli intervalli di confidenza per \(\mu\) o
come nel primo esempio del capitolo, fissato il livello di significativit√† \(\alpha\) del test, la regione critica per la
statistica \(Z_n\) risulta essere:
</p>
<ul class="org-ul">
<li>\(C' = (-\infty, -z_{1-\frac{\alpha}{2}}) \cup (+z_{1-\frac{\alpha}{2}}, +\infty)\) se \(H_1'\) √® l'ipotesi alternativa;</li>
<li>\(C'' = (-\infty, -z_{1-\alpha})\) se \(H_1''\) √® l'ipotesi alternativa;</li>
<li>\(C''' = (+z_{1-\alpha}, +\infty)\) se \(H_1'''\) √® l'ipotesi alternativa.</li>
</ul>
<p>
dove \(z_{1-\frac{\alpha}{2}}\) e \(z_{1-\alpha}\) sono rispettivamente i quantili di ordine \(1-\frac{\alpha}{2}\) e \(1-\alpha\) della normale standardizzata,
ovvero i valori per cui risulta \(P(Z \leq z_{1-\frac{\alpha}{2}}) = 1 - \frac{\alpha}{2}\) e \(P(Z \leq z_{1-\alpha}) = 1 - \alpha\) con \(Z_n \sim N(0, 1)\) e
sono ricavabili dalle tavole della normale standard.
</p>

<p>
Si perviene a tali regioni critiche osservando infatti che deve essere
\(\alpha = P(\text{rifiutare \(H_0 \mid H_0\) √® vera}) = P(Z_n \in C \mid Z_n \sim N(0, 1))\). Notiamo che in base all'esplicita
relazione che lega la statistica \(Z_n\) alla media campionaria \(\bar{X}_n\) avremmo potuto usare \(\bar{X}_n\) come
statistica test a cui corrispondono le regioni critiche:
</p>
<ul class="org-ul">
<li>\(C' = \left(-\infty, \mu_0 -z_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}\right) \cup \left(\mu_0 +z_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}, +\infty\right)\) se \(H_1'\) √® l'ipotesi alternativa;</li>
<li>\(C'' = \left(-\infty, \mu_0 -z_{1-\alpha} \frac{\sigma}{\sqrt{n}}\right)\) se \(H_1''\) √® l'ipotesi alternativa;</li>
<li>\(C''' = \left(\mu_0 +z_{1-\alpha} \frac{\sigma}{\sqrt{n}}, +\infty\right)\) se \(H_1'''\) √® l'ipotesi alternativa.</li>
</ul></li>
<li><p>
<i>Test unidirezionale con coda a sinistra</i>: \(H_1'' : \mu < \mu_0\).
</p>

<p>
Rifiuteremo l'ipotesi \(H_0\) in favore di \(H_1''\) quando \(Z_n\) assumer√† valori fortemente negativi, in tal caso \(\mu_0\) √® una
sovrastima della reale media, per cui \(Z_n\) tende ad assumere valori "negativi" essendo sicuramente
\(Z_n > \tilde{Z} \sim N(0, 1)\).
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-07_18-44-25.png" alt="screenshot_2018-06-07_18-44-25.png" />
</p>
</div></li>
<li><p>
<i>Test unidirezionale con coda a destra</i>: \(H_1''' : \mu < \mu_0\).
</p>

<p>
Rifiuteremo l'ipotesi \(H_0\) in favore di \(H_1'''\) quando \(Z_n\) assumer√† valori fortemente positivi, in tal caso \(\mu_0\) √® una
sottostima della reale media, per cui \(Z_n\) tende ad assumere valori "positivi" essendo sicuramente
\(Z_n < \tilde{Z} \sim N(0, 1)\).
</p>

<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-07_18-48-11.png" alt="screenshot_2018-06-07_18-48-11.png" />
</p>
</div></li>
</ol></li>
<li><p>
<i>Popolazione normalmente distribuita e varianza \(\sigma^2\) non nota</i>:
</p>

<p>
Ricordiamo che sotto le ipotesi di normalit√† di \(X\), la variabile \(\tilde{T} = \frac{\bar{X}_n - \mu}{\frac{\hat{S}_n}{\sqrt{n}}}\) √®
distribuita come una t di Student con \((n-1)\) gradi di libert√†. In questo caso \(\hat{S}_n\) √® la radice della varianza
campionaria corretta. Notiamo per√≤ che \(\tilde{T}\) non √® una statistica poich√© dipende dal parametro \(\mu\) che non √® noto.
Sia ora \(T_n = \frac{\bar{X}_n - \mu_0}{\frac{\hat{S}_n}{\sqrt{n}}}\), la quale √® una statistica, poich√© il valore \(\mu_0\) √® una
costante fissata. Ovviamente vale \(T_n \sim t_{n-1}\) se vale l'ipotesi nulla.
</p>

<p>
Il test si basa allora sull'osservazione del valore assunto dalla realizzazione della statistica \(T_n\), in particolare:
</p>
<ul class="org-ul">
<li>Rifiuteremo \(H_0\) se \(T_n\) assumer√† valori "poco probabili" per una \(t_{n-1}\).</li>
</ul>
<p>
Anche in questo caso la definizione della regione critica per \(T_n\) dipende dal livello di significativit√† prescelto e dalla
forma dell'ipotesi alternativa. Infatti, possiamo considerare le 3 ipotesi alternative:
</p>
<ul class="org-ul">
<li>Test bidirezionale: \(H_1' : \mu \neq \mu_0\);</li>
<li>Test unidirezionale con coda a sinistra: \(H_1'' : \mu < \mu_0\);</li>
<li>Test unidirezionale con coda a destra: \(H_1''' : \mu > \mu_0\)</li>
</ul>
<p>
definite precedentemente rifiutando \(H_0\) in favore di \(H_1'\) quando \(T_n\) assume valori troppo distanti dall'origine, in favore
di \(H_1''\) quando \(T_n\) assume valori fortemente negativi e in favore di \(H_1'''\) quando \(T_n\) assume valori fortemente positivi.
</p>

<p>
Specificamente, fissato il livello di significativit√† &alpha; del test, la regione critica per la statistica \(T_n\) risulta essere:
</p>
<ol class="org-ol">
<li>\(C' = (-\infty, -t_{1-\frac{\alpha}{2}}) \cup (+t_{1-\frac{\alpha}{2}}, +\infty)\) se \(H_1'\) √® l'ipotesi alternativa;</li>
<li>\(C'' = (-\infty, -t_{1-\alpha})\) se \(H_1''\) √® l'ipotesi alternativa;</li>
<li>\(C''' = (+t_{1-\alpha}, +\infty)\) se \(H_1'''\) √® l'ipotesi alternativa.</li>
</ol>
<p>
dove \(t_{1-\frac{\alpha}{2}}\) e \(t_{1-\alpha}\) sono rispettivamente i quantili di ordine \(1-\frac{\alpha}{2}\) e \(1-\alpha\) della t di Student con \((n-1)\) gradi di
libert√†, ovvero i valori per cui risulta \(P(T \leq t_{1-\frac{\alpha}{2}}) = 1 - \frac{\alpha}{2}\) e \(P(T \leq t_{1-\alpha}) = 1 - \alpha\) con \(T_n \sim t_{n-1}\) e
sono ricavabili dalle tavole della t di Student.
</p>

<p>
Anche in questo caso notiamo che in base all'esplicita relazione che lega la statistica \(T_n\) alla media campionaria \(\bar{X}_n\)
avremmo potuto usare \(\bar{X}_n\) come statistica test, a cui corrispondono le regioni critiche.
</p>
<ol class="org-ol">
<li>\(C' = \left(-\infty, \mu_0 -t_{1-\frac{\alpha}[2]}\frac{\hat{s}_n}{\sqrt{n}}\right) \cup \left(\mu_0 +t_{1-\frac{\alpha}{2}}\frac{\hat{s}_n}{\sqrt{n}}, +\infty\right)\)
se \(H_1'\) √® l'ipotesi alternativa;</li>
<li>\(C'' = \left(-\infty, \mu_0 -t_{1-\alpha} \frac{\hat{s}_n}{\sqrt{n}}\right)\) se \(H_1''\) √® l'ipotesi alternativa;</li>
<li>\(C''' = \left(\mu_0 +t_{1-\alpha} \frac{\hat{s}_n}{\sqrt{n}}, +\infty\right)\) se \(H_1'''\) √® l'ipotesi alternativa.</li>
</ol>
<p>
dove \(\hat{s}_n\) √® la realizzazione di \(\hat{S}_n\).
</p></li>
<li><p>
<i>Popolazione non normalmente distribuita</i>:
</p>

<p>
In questo caso per poter definire un test occorre avere un campione di numerosit√† sufficientemente elevate (\(n \geq 30\)).
Abbiamo gi√† visto che quando \(H_0\) sussiste allora la media campionaria \(\bar{X}_n\) √® approssimabile con una variabile
con distribuzione normale di media \(\mu\) e deviazione standard \(\frac{\sigma}{\sqrt{n}}\) quando \(\sigma\) √® nota, o di deviazione
\(\frac{\hat{s}_n}{\sqrt{n}}\) quando \(\sigma\) √® sconosciuta. Ci si pu√≤ allora ricondurre al caso di popolazione con
distribuzione normale e varianza nota, adottando le stesse regioni critiche sopra descritte.
</p>

<p>
Non si pu√≤ invece fare nulla, in generale, se la numerosit√† del campione √® inferiore a 30.
</p></li>
</ol>
</div>
</div>

<div id="outline-container-orgfe377a0" class="outline-4">
<h4 id="orgfe377a0"><span class="section-number-4">2.6.4</span> Test sulla varianza di una popolazione</h4>
<div class="outline-text-4" id="text-2-6-4">
<p>
Vediamo ora come si costruisce un test sulla varianza \(\sigma^2\) di una popolazione \(X\) quando si formula l'ipotesi nulla che tale varianza
√® pari ad un valore fissato \(\sigma_0^2\), vale a dire quando si consideri \(H_0 : \sigma^2 = \sigma_0^2\) e quando si dispone di un campione casuale
\((X_1, \dots, X_n)\) di numerosit√† \(n\) estratto da \(X\).
</p>

<p>
Purtroppo non √® possibile effettuare un test quando la popolazione ha una distribuzione diversa dalla normale, anche nel caso
in cui la numerosit√† del campione sia elevata, e questo per le stesse ragioni per cui non √® possibile definire un intervallo
di confidenza per la varianza di popolazioni non normalmente distribuite.
</p>

<p>
Al contrario, se la popolazione \(X\) √® normalmente distribuita, allora si pu√≤ costruire un test per l'ipotesi \(H_0\) facendo
ricorso al fatto che in tal caso la variabile \(\tilde{Q} = \frac{(n-1) \cdot \hat{S}_n^2}{\sigma^2}\) √® distribuita come una Chi-quadro con
\((n-1)\) gradi di libert√† e dove \(\hat{S}_n^2\) √® la varianza campionaria corretta. Si osservi che \(\tilde{Q}\) non √® una statistica,
infatti non √® noto il valori di \(\sigma^2\). Quando per√≤ l'ipotesi nulla \(H_0\) √® vera, allora vale
\(Q_n = \frac{(n-1) \cdot \hat{S}_n^2}{\sigma_0^2} \sim \chi_{n-1}^2\). Il test si basa sull'osservazione del valore assunto dalla realizzazione della
statistica.
</p>

<p>
Rifiuteremo \(H_0\) se \(Q_n\) assumer√† valori poco probabili per una Chi-quadro con \((n-1)\) gradi di libert√†.
</p>

<p>
Come nei test per il valor medio \(\mu\), la definizione della regione critica per \(Q_n\) dipende dal livello di significativit√†
adottato e dalla forma dell'ipotesi alternativa. Possiamo infatti considerare le seguenti 3 ipotesi alternative:
</p>
<ol class="org-ol">
<li>Test bidirezionale: \(H_1' : \sigma^2 \neq \sigma_0^2\);</li>
<li>Test unidirezionale con coda a sinistra: \(H_1'' : \sigma^2 < \sigma_0^2\);</li>
<li>Test unidirezionale con coda a destra: \(H_1''' : \sigma^2 > \sigma_0^2\).</li>
</ol>
<p>
Rifiuteremo \(H_0\) in favore di:
</p>
<ol class="org-ol">
<li>\(H_1'\) quando \(Q_n\) assume valori troppo grandi o piccoli per una Chi-quadro con \((n-1)\) gradi di libert√†;</li>
<li>\(H_1''\) quando \(Q_n\) assume valori troppo vicini a 0, infatti quando vale \(H_1''\), \(\sigma_0^2\) √® una sovrastima di \(\sigma^2\);</li>
<li>\(H_1'''\) quando \(Q_n\) assume valori fortemente positivi (per ragioni opposte a quanto sopra).</li>
</ol>
<p>
Specificamente, ragionando come nella definizione degli intervalli di confidenza per \(\sigma^2\) fissato il livello di significativit√†
\(\alpha\) del test, la regione critica per la statistica \(Q_n\) risulta essere:
</p>
<ol class="org-ol">
<li>\(C' = (0, q_{\frac{\alpha}{2}}) \cup (q_{1-\frac{\alpha}{2}}, +\infty)\) se \(H_1'\) √® l'ipotesi alternativa;</li>
<li>\(C'' = (0, q_{\alpha})\) se \(H_1''\) √® l'ipotesi alternativa;</li>
<li>\(C''' = (q_{1-\alpha}, +\infty)\) se \(H_1'''\) √® l'ipotesi alternativa.
Dove con il generico \(q_{\gamma}\) si intende il quantile di ordine \(\gamma\) della Chi-quadro con \((n-1)\) gradi di libert√†, ovvero quel
valore per cui risulta \(P(Q \leq q_{\gamma}) = \gamma\) con \(Q \sim \chi_{n-1}^2\) ed √® ricavabile dalle tavole della Chi-quadro.</li>
</ol>

<p>
Si perviene a tali regioni critiche osservando che deve essere:
\[\alpha = P(\text{rifiutare $H_0 \mid H_0$ √® vera}) = P(Q_n \in C \mid Q_n \approx \chi_{n-1}^2)\]
Notiamo che in base all'esplicit√† relazione che lega la statistica \(Q_n\) alla varianza campionaria \(S_n^2\) avremmo potuto usare
\(S_n^2\) come statistica test a cui corrispondono le regioni critiche.
</p>
<ol class="org-ol">
<li>\(C' = \left(0, q_{\frac{\alpha}{2}}\frac{\sigma_0^2}{n}\right) \cup \left(q_{1-\frac{\alpha}{2}}\frac{\sigma_0^2}{n}, +\infty\right)\) se \(H_1'\) √® l'ipotesi alternativa;</li>
<li>\(C'' = \left(0, q_{\alpha}\frac{\sigma_0^2}{n}\right)\) se \(H_1''\) √® l'ipotesi alternativa;</li>
<li>\(C''' = \left(-q_{1-\alpha}\frac{\sigma_0^2}{n}, +\infty\right)\) se \(H_1'''\) √® l'ipotesi alternativa.</li>
</ol>
<p>
Si osservi infine che per effettuare un test sulla varianza di una popolazione normalmente distribuita non occorre
conoscere il valor medio della popolazione stessa. Ci√≤ si deduce dal fatto che il parametro \(\mu\) e le sue stime non compaiono
nella definizione delle regioni critiche del test.
</p>

<p>
Per esempio, si riconsideri il problema del reddito medio annuo per famiglia (in migliaia di euro) di un determinato quartiere
di una citt√†. Si supponga, come nel primo esempio del capitolo, che tale reddito sia normalmente distribuito ma che non sia nota
la sua varianza \(\sigma^2\). Supponiamo di voler controllare con un livello di significativit√† \(\alpha = 0.05\) l'ipotesi che tale
varianza sia uguale a \(\sigma_0^2 = 25\) e di poter disporre di un campione di numerosit√† \(n = 10\). Vediamo allora qual √® la regione
critica del test quando l'ipotesi alternativa √® \(H_1 : \sigma^2 \neq 25\).
</p>

<p>
In base a quanto affermato sopra, la statistica da utilizzare √® la \(Q_n = \frac{(n-1) \cdot \hat{S}_n^2}{\sigma_0^2}\). Pertanto la regione
critica deve essere \(C = (0, q_{\frac{\alpha}{2}}) \cup (q_{1-\frac{\alpha}{2}}, +\infty)\) dove \(q_{\frac{\alpha}{2}} = q_{0.025} = 2.70\) e \(q_{1-\frac{\alpha}{2}} = q_{0.975} = 19\).
In definitiva, la regione critica sar√† \(C = (0, 2.7) \cup (19, +\infty)\).
</p>

<p>
Supponiamo ora di effettuare l'indagine e di osservare che la realizzazione del campione fornisca una varianza campionaria corretta.
\(\hat{s}_{10}^2 = 35.5\). La realizzazione della statistica risulta essere \(Q_{10} = \frac{(10-1) \cdot \hat{S}_{10}^2}{\sigma_0^2} = \frac{9 \cdot 35.5}{25} = 12.8\).
E poich√© tale valore non fa parte della regione critica del test accettiamo l'ipotesi \(H_0 : \sigma^2 = 25\), o meglio diremo che
l'ipotesi \(H_0\) non pu√≤ essere rifiutata.
</p>
</div>
</div>
<div id="outline-container-org78eeb3e" class="outline-4">
<h4 id="org78eeb3e"><span class="section-number-4">2.6.5</span> Test sulla differenza delle medie di due popolazioni</h4>
<div class="outline-text-4" id="text-2-6-5">
<p>
Il test che verr√† ora descritto non √® propriamente un test di tipo parametrico, in quanto non viene utilizzato per controllare
un possibile valore assunto da un parametro, bens√¨ per controllare l'ipotesi che le medie di due distinte popolazioni \(X\) ed \(Y\)
siano identiche. Nonostante ci√≤ viene solitamente considerato appartenente alla famiglia dei test parametrici per via delle
ipotesi di normalit√† a cui devono sottostare le popolazioni considerate.
</p>

<p>
Siano quindi \(X\) ed \(Y\) due popolazioni normalmente distribuite aventi rispettivamente valor medio \(\mu_x\) e \(\mu_y\) ed identica
varianza \(\sigma^2\) incognita. Sia \(\mu = \mu_X - \mu_Y\) e si voglia controllare l'ipotesi \(H_0 : \mu = 0\) disponendo di due campioni casuali
\((X_1, \dots, X_n)\) e \((Y_1, \dots, Y_m)\). Siano \(\bar{X}_n\) e \(\bar{Y}_m\) le medie campionarie e \(S_{X, n}^2\) e \(S_{Y, m}^2\) le varianze campionarie.
</p>

<p>
Il test si basa sul fatto che quando valgono le ipotesi sopra elencate, allora:
\[\tilde{T} = \frac{\bar{X}_n - \bar{Y}_m - \mu}{\sqrt{\frac{(n+m)(n \cdot S_{X, n}^2 + m \cdot S_{Y, m}^2)}{n \cdot m \cdot (n + m - 2)}}} \sim t_{n+m-2}\]
Si possono pertanto definire le regioni critiche del test considerando tale propriet√† e ragionando come nel caso del test per
la media di una popolazione normalmente distribuita con varianza incognita. Considerando cio√® le ipotesi alternative.
Sia \(\mu = \mu_X - \mu_Y\):
</p>
<ol class="org-ol">
<li>Test bidirezionale: \(H_1' : \mu \neq \mu_0\);</li>
<li>Test unidirezionale con coda a sinistra: \(H_1'' : \mu < \mu_0\);</li>
<li>Test unidirezionale con coda a destra: \(H_1''' : \mu > \mu_0\)</li>
</ol>
<p>
Le corrispondenti regioni critiche per la statistica
\[T_{n, m} = \frac{\bar{X}_n - \bar{Y}_m}{\sqrt{\frac{(n+m)(n \cdot S_{X, n}^2 + m \cdot S_{Y, m}^2)}{n \cdot m \cdot (n + m - 2)}}}\]
risultano essere:
</p>
<ol class="org-ol">
<li>\(C' = (-\infty, -t_{1-\frac{\alpha}{2}}) \cup (+t_{1-\frac{\alpha}{2}}, +\infty)\) se \(H_1'\) √® l'ipotesi alternativa;</li>
<li>\(C'' = (-\infty, -t_{1-\alpha})\) se \(H_1''\) √® l'ipotesi alternativa;</li>
<li>\(C''' = (+t_{1-\alpha}, +\infty)\) se \(H_1'''\) √® l'ipotesi alternativa.</li>
</ol>
<p>
dove \(t_{1-\frac{\alpha}{2}}\) e \(t_{1-\alpha}\) sono rispettivamente i quantili di ordine \(1-\frac{\alpha}{2}\) e \(1-\alpha\) della t di Student con \((n+m-2)\) gradi di
libert√†, ovvero i valori per cui risulta \(P(T \leq t_{1-\frac{\alpha}{2}}) = 1 - \frac{\alpha}{2}\) e \(P(T \leq t_{1-\alpha}) = 1 - \alpha\) con \(T_n \sim t_{n+m-2}\) e
sono ricavabili dalle tavole della t di Student.
</p>

<p>
Nota: ripetendo la sequenza di calcoli usata nel capitolo precedente, √® possibile utilizzare la variabile aleatoria:
\[\tilde{T} = \frac{\bar{X}_n - \bar{Y}_m - \mu}{\sqrt{\frac{(n+m)(n \cdot S_{X, n}^2 + m \cdot S_{Y, m}^2)}{n \cdot m \cdot (n + m - 2)}}} \sim t_{n+m-2}\]
per ottenere un intervallo di confidenza sulla differenza delle medie:
\[P\left[(\bar{X}_n - \bar{Y}_m) - t_{1 - \frac{\alpha}{2}}\sqrt{\frac{(n+m)(n \cdot S_{X, n}^2 + m \cdot S_{Y, m}^2)}{n \cdot m \cdot (n + m - 2)}} \leq \mu \leq
(\bar{X}_n - \bar{Y}_m) + t_{1 - \frac{\alpha}{2}}\sqrt{\frac{(n+m)(n \cdot S_{X, n}^2 + m \cdot S_{Y, m}^2)}{n \cdot m \cdot (n + m - 2)}}\right] = 1 - \alpha\]
Si osservi che tra le ipotesi necessarie per effettuare questo test compare la richiesta che le due popolazioni abbiano identica
varianza anche se sconosciuta. Questo potrebbe sembrare un grosso problema che pu√≤ essere risolto tramite il test nel prossimo
paragrafo.
</p>

<p>
Un test per la differenza delle medie di due popolazioni pu√≤ essere definito anche quando le varianze delle due popolazioni sono
diverse (purch√© note). Si pu√≤ dimostrare infatti che in questo caso vale
\[Z_{n, m} = \frac{(\bar{X}_n - \bar{Y}_m) - \mu}{\sqrt{\frac{\sigma_X^2}{n} + \frac{\sigma_Y^2}{m}}} \sim N(0, 1)\]
purch√©:
</p>
<ul class="org-ul">
<li>O \(X\) ed \(Y\) siano normalmente distribuite;</li>
<li>O le numerosit√† \(n\) ed \(m\) dei campioni siano sufficientemente grandi.</li>
</ul>
<p>
La definizione delle regioni critiche segue quindi con il solito procedimento.
</p>

<p>
In realt√† comunque non capita spesso di conoscere esattamente il valore delle due varianze.
</p>
</div>
</div>

<div id="outline-container-org7b2b17f" class="outline-4">
<h4 id="org7b2b17f"><span class="section-number-4">2.6.6</span> Test sull'uguaglianza delle varianze di due popolazioni</h4>
<div class="outline-text-4" id="text-2-6-6">
<p>
Abbiamo appena visto che per poter effettuare un test sulla differenza delle medie di due popolazioni normalmente distribuite
di cui non sono note le varianze occorre assumere che tali varianze siano identiche. Vediamo quindi come sia possibile
controllare tale ipotesi. Il test in questione si basa sul fatto che se \(X \sim N(\mu_X, \sigma_X)\) e \(Y \sim N(\mu_Y, \sigma_Y)\) allora la variabile
\(\tilde{V} = \frac{\sigma_Y^2 \cdot \hat{S}_{X, n}^2}{\sigma_X^2 \cdot \hat{S}_{Y, m}^2}\) risulta essere distribuita come una F con \((n-1)\) e \((m-1)\) gradi di libert√†.
\(\hat{S}_{X, n}\) e \(\hat{S}_{Y, m}^2\) sono le varianze campionarie corrette.
</p>

<p>
La \(\tilde{V}\) non √® propriamente una statistica poich√© essa dipende dai due parametri \(\sigma_Y^2\) e \(\sigma_X^2\) che sono incogniti, per√≤ quando
risulti soddisfatta l'ipotesi \(H_0 : \sigma_X^2 = \sigma_Y^2\) allora \(V_{n, m} = \frac{\hat{S}_{X, n}^2}{\hat{S}_{Y, m}^2}\) risulta essere distribuita come
una F con \((n-1)\) e \((m-1)\) gradi di libert√†. Si osservi che \(V_{n, m}\) invece √® proprio una statistica essendo definita solo
in funzione dei due campioni \((X_1, \dots, X_n)\) e \((Y_1, \dots, Y_m)\).
</p>

<p>
Consideriamo ora le 3 ipotesi alternative:
</p>
<ol class="org-ol">
<li>Test bidirezionale: \(H_1' : \frac{\sigma_Y^2}{\sigma_X^2}\neq 1\);</li>
<li>Test unidirezionale con coda a sinistra: \(H_1'' : \frac{\sigma_Y^2}{\sigma_X^2} < 1\);</li>
<li>Test unidirezionale con coda a destra: \(H_1''' : \frac{\sigma_Y^2}{\sigma_X^2} > 1\).</li>
</ol>
<p>
Rifiuteremo \(H_0\) in favore di:
</p>
<ol class="org-ol">
<li>\(H_1'\) quando \(V_{n, m}\) assume valori troppo grandi o piccoli per una \(F(n-1, m-1)\);</li>
<li>\(H_1''\) quando \(V_{n, m}\) assume valori troppo vicini a 0;</li>
<li>\(H_1'''\) quando \(V_{n, m}\) assume valori fortemente positivi.</li>
</ol>
<p>
Specificamente, ragionando come nella definizione degli intervalli di confidenza per \(\sigma^2\) fissato il livello di significativit√†
\(\alpha\) del test, la regione critica per la statistica \(V_{n, m}\) risulta essere:
</p>
<ol class="org-ol">
<li>\(C' = [0, f_{\frac{\alpha}{2}}) \cup (f_{1-\frac{\alpha}{2}}, +\infty)\) se \(H_1'\) √® l'ipotesi alternativa;</li>
<li>\(C'' = [0, f_{\alpha})\) se \(H_1''\) √® l'ipotesi alternativa;</li>
<li>\(C''' = (f_{1-\alpha}, +\infty)\) se \(H_1'''\) √® l'ipotesi alternativa.
Dove con il generico \(f_{\gamma}\) si intende il quantile di ordine \(\gamma\) della \(F(n-1, m-1)\), ovvero quel
valore per cui risulta \(P(V \leq f_{\gamma}) = \gamma\) con \(V \sim F(n-1, m-1)\) ed √® ricavabile dalle tavole della F.</li>
</ol>

<p>
Per esempio, consideriamo due diversi quartieri della stessa citt√† e supponiamo di essere interessati a confrontare il valor medio
dei redditi annui familiari in migliaia di euro. Si supponga che sia lecito assumere che tali redditi siano normalmente distribuiti.
Si supponga di estrarre un campione casuale per ogni quartiere di numerosit√† rispettivamente pari a 10 e 15. Utilizzando le notazioni
introdotte in precedenza, sia \(X\) la popolazione del primo quartiere ed \(Y\) la popolazione del secondo. Supponiamo che le
realizzazioni dei campioni relativi ad \(X\) ed \(Y\) siano \((22, 48, 51, 20, 28, 35, 38, 26, 50, 36)\) e
\((40, 42. 50, 26, 30, 34, 37, 25, 30, 32, 38, 22, 55, 40)\).
</p>

<p>
In base ai due campioni si ottiene: \(\bar{x}_{10} = 35.4\), \(\bar{y}_{15} = 35.3\), \(s_{X, 10}^2 = 118.2\) e \(s_{Y, 15}^2 = 79.7\).
</p>

<p>
Volendo controllare l'ipotesi \(H_0 : \mu_X = \mu_Y\) occorre considerare la statistica
\[T_{n, m} = \frac{\bar{X}_n - \bar{Y}_m}{\sqrt{\frac{(n+m)(n \cdot S_{X, n}^2 + m \cdot S_{Y, m}^2)}{n \cdot m \cdot (n + m - 2)}}}\]
che nel caso particolare assume valore \(t_{10, 15} = 0.024\).
</p>

<p>
Il valore ottenuto porta ad accettare \(H_0\) comunque si scelga l'ampiezza \(\alpha\) del test. Osserviamo per√≤ che tra le ipotesi
necessarie per effettuare il test della differenza delle medie con la statistica \(T_{n, m}\) vi √® quella che le due popolazioni
abbiano identica varianza. Prima di accettare definitivamente l'ipotesi \(H_0 : \mu_X = \mu_Y\) occorre quindi controllare l'ipotesi
\(H_0' : \sigma_X^2 = \sigma_Y^2\).
</p>

<p>
Utilizziamo per questo il test appena descritto e basato sulla statistica \(V_{n, m} = \frac{\hat{S}_{X, n}^2}{\hat{S}_{Y, m}^2}\)
la cui realizzazione nel nostro caso √® \(V_{10, 15} = \frac{\hat{S}_{X, 10}^2}{\hat{S}_{Y, 15}^2} = 1.54\).
</p>

<p>
Vediamo se questo nuovo dato ci porta a non rifiutare \(H_0'\) contro \(H_1 : \sigma_X^2 \neq \sigma_Y^2\) con un livello di significativit√† \(\alpha = 0.1\).
In questo caso, dalle tavole della F si ricava che per 9 e 14 gradi di libert√† i quantili sono \(f_{\frac{\alpha}{2}} = f_{0.05} = 0.38\) e
\(f_{1 - \frac{\alpha}{2}} = f_{0.95} = 2.65\).
</p>

<p>
Pertanto la regione di accettazione di \(H_0'\) √® \((0.38, 2.65)\).
</p>

<p>
Il valore della statistica \(V_{n, m} = \frac{\hat{S}_{X, n}^2}{\hat{S}_{Y, m}}\) √® \(\nu_{10, 15} = 1.54\).
</p>

<p>
Possiamo allora affermare, con un livello di significativit√† pari a 0.1, che le ipotesi per la validit√† del test per la differenza
delle medie non possono essere rifiutate e di conseguenza che non si pu√≤ rifiutare l'ipotesi \(H_0\) che siano uguali anche le due medie.
</p>
</div>
</div>
<div id="outline-container-orgd043965" class="outline-4">
<h4 id="orgd043965"><span class="section-number-4">2.6.7</span> Test di incorrelazione</h4>
<div class="outline-text-4" id="text-2-6-7">
<p>
Il test che viene ora presentato si riferisce ad un parametro che descrive il grado di correlazione tra due popolazioni \(X\) ed \(Y\),
ovvero tra due diversi caratteri di una popolazione bidimensionale \((X, Y)\). Tale parametro √® il coefficiente di correlazione lineare
di Pearson: \(\rho_{XY} = \frac{\sigma_{XY}}{\sigma_X \cdot \sigma_Y}\), dove \(\sigma_{XY} = E[(X - \mu_X) \cdot (Y - \mu_Y)]\) √® la covarianza tra i due caratteri.
</p>

<p>
Osserviamo che quando sono noti i dati \((x_i, y_i)\) di tutti gli individui della popolazione bidimensionale \((X, Y)\) allora \(\rho_{XY}\) coincide con
il coefficiente di correlazione lineare \(r_{xy}\) descritto nel primo capitolo:
\[r_{xy} = \frac{c_{xy}}{s_x \cdot s_y} = \frac{\frac{1}{N} \cdot \sum_{i=1}^N (x_i - \mu_X) \cdot (y_i - \mu_Y)}{\sigma_X \cdot \sigma_Y}\]
dove \(N\) √® il numero complessivo di individui della popolazione bidimensionale \((X, Y)\).
</p>

<p>
Ricordiamo che i parametri \(\rho_{XY}\) e \(r_{xy}\) possono assumere valori in \([-1, 1]\) e sono indici del grado di allineamento delle coppie di dati
\((x_i, y_i)\). Sono nulli quando la covarianza dei due caratteri √® nulla e sono uguali ad 1 in valore assoluto quando le coppie di dati si
trovano lungo una retta.
</p>

<p>
Data una popolazione bidimensionale \((X, Y)\) in contesti reali non √® mai possibile determinare il valore del coefficiente di correlazione
lineare \(\rho_{XY}\) e questo per gli stessi motivi per i quali non √® possibile determinare esattamente il valore dei parametri \(\mu_X\), \(\mu_Y\), \(\sigma_X\) e
\(\sigma_Y\). Come per questi parametri √® per√≤ possibile effettuarne una stima. A tal fine si usa lo stimatore \(R_n\) basato su un campione
\(((X_1, Y_1), \dots, (X_n, Y_n))\) definito come:
\[R_n = \frac{\sum_{i=1}^n (X_i - \bar{X}) \cdot (Y_i - \bar{Y})}{n \cdot S_{X, n} \cdot S_{Y, n}}\]
dove \(\bar{X}\) e \(\bar{Y}\) sono le medie campionarie dei due caratteri mentre \(S_{X, n}\) e \(S_{Y, n}\) sono le radici delle due varianze campionarie.
</p>

<p>
Il test di incorrelazione che ora presentiamo serve a verificare che il coefficiente \(\rho_{XY}\) assuma valore 0, cio√® che sussista incorrelazione tra
i due caratteri. Il test √® basato sul fatto che sotto l'ipotesi \(H_0 : \rho_{XY} = 0\), la statistica \(\hat{T}_n = R_n \cdot \sqrt{\frac{n-2}{1-R_n^2}}\) risulta
essere distribuita come una t di Student con \((n-2)\) gradi di libert√†. Questa propriet√† infatti pu√≤ essere utilizzata per confrontare \(H_0\) con
l'ipotesi alternativa \(H_1 : \rho_{XY} \neq 0\) non rifiutando \(H_0\) quando \(\hat{T}_n\) assume valori non troppo distanti dallo 0 e rifiutandola in favore
di \(H_1\) in caso contrario.
</p>

<p>
Ragionando al solito modo, si ottiene allora che per un livello di significativit√† \(\alpha\), la regione critica della statistica \(\hat{T}_n\) √®
\(C = \left(-\infty, -t_{1-\frac{\alpha}{2}}\right) \cup \left(+t_{1-\frac{\alpha}{2}}, +\infty\right)\), dove \(t_{1 - \frac{\alpha}{2}}\) √® il quantile di ordine \(1 - \frac{\alpha}{2}\) della t
di Student con \((n-2)\) gradi di libert√†.
</p>

<p>
Per esempio, si consideri una popolazione \((X, Y)\) di travi di cemento, in cui:
</p>
<ul class="org-ul">
<li>\(X\) indica il carico di prima lesione;</li>
<li>\(Y\) indica il carico a rottura finale.</li>
</ul>
<p>
Si supponga di avere un'ampia popolazione, ovvero di avere un elevato numero di queste travi, e di voler controllare, con livello di
significativit√† \(\alpha = 0.05\), se esiste una correlazione tra il carico di prima lesione ed il carico a rottura finale. A tal scopo si
supponga di aver effettuato delle prove su 15 travi ottenendo i risultati riportati nella seguente tabella:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-07_23-41-55.png" alt="screenshot_2018-06-07_23-41-55.png" />
</p>
</div>

<p>
In base ai consueti calcoli si verifica che una stima del coefficiente di correlazione lineare √®
\[R_n = \frac{\sum_{i=1}^{15} (X_i - \bar{X}) \cdot (Y_i - \bar{Y})}{15 \cdot S_{X, 15} \cdot S_{Y, 15}} = 0.9195\]
che risulta uguale al coefficiente di correlazione lineare trovato nell'esempio del primo capitolo, nel quale si supponeva che l'intera popolazione
fosse costituita solo dalle 15 travi esaminate. La statistica \(\hat{T}_n\) assume invece valore \(\hat{t}_{15} = 0.9195 \cdot \sqrt{15 - 2}{1 - 0.9195^2} = 8.43\).
</p>

<p>
Vediamo ora se il valore ottenuto consente di non rifiutare l'ipotesi \(H_0\) che non esiste correlazione tra i due caratteri. Per questo √®
sufficiente notare che la regione critica del test, relativamente alla statistica \(\hat{T}_{15}\) √® 
\(C = \left(-\infty, -t_{0.975}\right) \cup \left(+t_{0.975}, +\infty\right) = (-\infty, -2.16) \cup (+2.16, +\infty)\),
dove il quantile \(t_{0.975} = 2.16\) √® stato ricavato dalla tavola della distribuzione t di Student con 13 gradi di libert√†. Poich√© il valore da noi
osservato di \(\hat{T}_{15}\) cade nella regione critica del test √® lecito supporre che vi sia un legame lineare tra il carico di prima lesione
e il carico a rottura, ovvero rifiutando l'ipotesi nulla di incorrelazione tra carico di prima lesione e carico di rottura.
</p>

<p>
Osserviamo che la procedura descritta in questo paragrafo consente di sottoporre a test l'ipotesi di incorrelazione lineare tra due diversi
caratteri di una popolazione, vale a dire \(\rho_{XY} = 0\). Si tenga comunque presente che √® anche possibile effettuare dei test sul coefficiente
di correlazione di Pearson pi√π generici rispetto a quello qui considerato, cio√® con ipotesi nulle del tipo \(H_0 : \rho_{XY} = \rho^*\) con \(\rho^*\) diverso
da 0. In tal caso occorre per√≤ far ricorso a statistiche campionarie che non riteniamo opportuno introdurre qui.
</p>
</div>
</div>
</div>
<div id="outline-container-org9acb7a0" class="outline-3">
<h3 id="org9acb7a0"><span class="section-number-3">2.7</span> Verifica di Ipotesi: Test non parametrici</h3>
<div class="outline-text-3" id="text-2-7">
<p>
Nel capitolo precedente abbiamo visto dei test che si riferiscono ad alcuni parametri delle popolazioni. Essi richiedono sempre ipotesi forti
sulla distribuzione della popolazione, √® quasi sempre richiesto, ad esempio, che essa sia normalmente distribuita.
Ma come possiamo stabilire
quando una popolazione √® normalmente distribuita? Oppure, cosa possiamo fare quando non abbiamo elementi per affermare che una popolazione
non √® normalmente distribuita o quando siamo certi che non lo √®?
Per rispondere a queste domande sono stati studiati dei test appositi;
alcuni possono essere effettuati anche quando le ipotesi di normalit√† non sono soddisfatte, altri servono invece per stabilire quali tipi
di distribuzioni sono ipotizzabili per la popolazione considerata.
</p>

<p>
Tali test presentano inoltre altri vantaggi:
</p>
<ul class="org-ul">
<li>Sono utilizzabili anche nel caso in cui i campioni siano piccoli;</li>
<li>Sono di pi√π facile calcolo rispetto ai corrisponendenti test parametrici.</li>
</ul>
<p>
A loro discapito bisogna dire che:
</p>
<ul class="org-ul">
<li>I calcoli diventano pi√π complessi quando i campioni sono numerosi;</li>
<li>Sono meno potenti dei corrispondenti test parametrici (maggiore probabilit√† di compiere errore di II specie).</li>
</ul>

<p>
In questo capitolo verranno introdotti:
</p>
<ul class="org-ul">
<li><i>Test per la bont√† dell'adattamento</i> che servono per verificare se una popolazione segue una distribuzione prestabilita;</li>
<li><i>Test per confrontare le distribuzioni di due popolazioni</i> quando queste non siano necessariamente distribuite normalmente;</li>
<li><i>Test per verificare se sussiste indipendenza o incorrelazione tra due diversi caratteri di una popolazione</i>.</li>
</ul>
<p>
Anche per questi test valgono le considerazioni viste in merito agli errori di I e II specie ed alle regioni critiche e di accettazione
espresse relativamente ai test parametrici. Per tale ragione non le ripeteremo.
Infine, ricordiamo che tali test, proprio per la particolarit√† di non richiedere assunti sulla distribuzione dei dati, sono detti
<i>indipendenti dalla distribuzione</i>.
</p>
</div>
<div id="outline-container-org0222d5d" class="outline-4">
<h4 id="org0222d5d"><span class="section-number-4">2.7.1</span> Test per la bont√† dell'adattamento</h4>
<div class="outline-text-4" id="text-2-7-1">
<p>
I due test che verranno presentati servono per rispondere alla seguente domanda: "possiamo affermare che la popolazione \(X\) esaminata √®
distribuita secondo una specifica funzione di ripartizione \(F\)?"
</p>

<p>
Questi test sono detti di <i>bont√† dell'adattamento</i> proprio perch√© quello che si chiede √® se la distribuzione specificata \(F\) √® adatta a
descrivere la variazioni nella popolazione \(X\). Pertanto per entrambi i test considereremo l'ipotesi nulla
\(H_0 : F_X (t) = F(t)\) per ogni \(t \in \mathbb{R}\), dove \(F_X\) √® la reale distribuzione della popolazione \(X\), mentre \(F\) √® quella da
noi specificata. In entrambi i casi, l'ipotesi alternativa sar√†: \(H_1 : F_X(t) \neq F(t)\) per almeno un \(t \in \mathbb{R}\).
</p>
</div>
<ol class="org-ol">
<li><a id="org3b39155"></a>Test di Kolmogorov-Smirnov<br />
<div class="outline-text-5" id="text-2-7-1-1">
<p>
Il test di Kolmogorov-Smirnov si basa sulla nozione di distribuzione empirica che ora introdurremo. Sia \((X_1, \dots, X_n)\) un campione di numerosit√†
\(n\) estratto da una popolazione \(X\). √à detta <i>funzione di ripartizione empirica</i> della popolazione \(X\) basata su \((X_1, \dots, X_n)\) la funzione
aleatoria
\[\hat{F}_{X, n}(t) = \frac{1}{n}\sum_{i=1}^n U_{(-\infty, t]}(X_i) \quad \text{per ogni $t \in \mathbb{R}$}\]
dove
</p>
\begin{equation*}
U_{(-\infty, t]}(X_i) =
\begin{cases}
1 &\text{se $X_i \in (-\infty, t]$}\\
0 &\text{altrimenti}
\end{cases}
\end{equation*}
<p>
Notiamo che non possiamo sapere come questa funzione √® fatta fino a che non conosciamo la realizzazione \((x_1, \dots, x_n)\) di \((X_1, \dots, X_n)\).
</p>

<p>
Per esempio, in un passato esempio si assumeva che la variabile \(X\) che descrive il tempo necessario per ottenere la concessione per la
ristrutturazione di un immobile fosse distribuita con legge Esponenziale, il cui parametro \(\lambda\) veniva stimato facendo uso dei dati
\((3.0, 4.1, 2.8, 5.5, 1.5, 2.2, 6.0, 1.2, 3.2, 0.9)\) assunti da un campione di numerosit√† 10 estratto da \(X\). Vediamo ora qual √®
la funzione di ripartizione empirica che si ottiene considerando tale realizzazione del campione. A tale scopo conviene riordinare in maniera
crescente i dati di tale campione, ottenendo la sequenza \((0.9, 1.2, 1.5, 2.2, 2.8, 3.0, 3.2, 4.1, 5.5, 6.0)\).
</p>

<p>
La funzione di ripartizione empirica √® tale che in corrispondenza di ciascuno di tali valori essa compie un salto di ampiezza 0.1, partendo da
0 ed arrivando ad 1 in corrispondenza dell'ultimo valore, ovvero 6.0:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-08_00-25-02.png" alt="screenshot_2018-06-08_00-25-02.png" />
</p>
</div>

<p>
Si osservi che le funzioni di ripartizione empiriche sono sempre delle funzioni crescenti a "gradino".
</p>

<p>
√à facile rendersi conto poi che al crescere della numerosit√† del campione \(n\), la funzione di ripartizione empirica assomiglia
sempre di pi√π alla reale funzione di ripartizione della popolazione fino a coincidere con essa quando \(n\) corrisponde alla
numerosit√† dell'intera popolazione.
</p>

<p>
Il <i>test di Kolmogorov-Smirnov</i> si basa sulla statistica \(D_n = \text{sup}_{t \in \mathbb{R}} | F(t) - \hat{F}_{X, n}(t)|\) che specifica l'estremo superiore delle distanze
in valore assoluto tra la funzione di ripartizione che vogliamo controllare come possibile per \(X\) e quella empirica ottenuta
tramite il campione disponibile.
</p>

<p>
Si pu√≤ dimostrare che quando vale \(H_0\) e quando \(F\) √® una funzione continua, allora tale statistica √® indipendente dalla forma
di \(F\), ovvero ha la stessa distribuzione qualunque sia \(F\), ma ovviamente varier√† al variare di \(n\).
</p>

<p>
La distribuzione della statistica campionaria \(D_n\) al variare di \(n\) √® stata studiata dagli inventori del test, che hanno
fornito apposite tabelle per determinare i quantili di cui riportiamo un estratto:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-08_12-51-39.png" alt="screenshot_2018-06-08_12-51-39.png" />
</p>
</div>

<p>
Pertanto √® possibile fissare delle regioni di accettazione e critiche al variare di \(n\) e del livello di significativit√†. Per
questo notiamo che √® logico aspettarsi che \(D_n\) assuma valori piccoli se l'ipotesi nulla √® vera, ed assuma valori grandi quando
\(H_0\) √® falsa. Infatti, per ogni ampiezza \(\alpha\) del test, la regione critica risulta essere \(C = (d_{1-\alpha}, +1]\), dove il quantile
\(d_{1-\alpha}\) √® quel valore per cui risulta \(P(D_n \leq d_{1-\alpha}) = 1 - \alpha\) che pu√≤ essere determinato sulle apposite tavole. Si noti che \(D_n\)
non pu√≤ sicuramente assumere valori maggiori di 1.
</p>

<p>
Riprendiamo in considerazione l'esempio precedente e controlliamo l'ipotesi che la popolazione segua una distribuzione
esponenziale di parametro 0.35 con ampiezza \(\alpha = 0.05\). Per far ci√≤ occorre sovrapporre il grafico di ripartizione empirica
trovato nell'esempio precedente con il grafico della funzione di ripartizione
</p>
\begin{equation*}
F(t) =
\begin{cases}
1 \cdot e^{-0.35 t} &\text{se $t \geq 0$}\\
0 &\text{se $t < 0$}
\end{cases}
\end{equation*}
<p>
che vogliamo controllare.
</p>

<p>
Tale operazione viene riportata nella figura di seguito, dove √® possibile osservare che la massima distanza in valore assoluto
si ottiene per \(t=0.9\) e vale \(0.27\).
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-08_12-59-48.png" alt="screenshot_2018-06-08_12-59-48.png" />
</p>
</div>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-08_13-00-15.png" alt="screenshot_2018-06-08_13-00-15.png" />
</p>
</div>

<p>
Si osservi che la massima distanza tra la funzione di ripartizione \(F\) e la funzione di ripartizione empirica viene raggiunta
sempre in corrispondenza di uno dei salti della distribuzione empirica. Questo fatto pu√≤ essere utile nella determinazione di
\(D_n\), quando non √® possibile fare uso di rappresentazioni grafiche.
</p>

<p>
Osserviamo che il test di Kolmogorov-Smirnov non richiede particolari assunti sui dati o sulla distribuzione \(F\) per essere
impiegato, se non quello di continuit√† della \(F\) stessa.
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-orgc4dcbcc" class="outline-4">
<h4 id="orgc4dcbcc"><span class="section-number-4">2.7.2</span> Test del Chi-Quadro</h4>
<div class="outline-text-4" id="text-2-7-2">
<p>
Il test Chi-Quadro per la bont√† dell'adattamento pu√≤ essere utilizzato senza porre condizioni sulla \(F\).
Anche per poter descrivere questo test occorre introdurre alcune nozioni e notazioni e come al solito supporremo di poter estrarre un
campione \((X_1, \dots, X_n)\) di numerosit√† \(n\) della popolazione \(X\).
</p>

<p>
Sia \(F\) la funzione di ripartizione di cui vogliamo controllare quale sia la possibile distribuzione della popolazione \(X\).
Dividiamo il supporto di \(F\) in un numero finito di intervalli che formino una <i>partizione del supporto</i> stesso. Denotiamo con
\(I_k = [t_k, t_{k+1})\) gli intervalli cos√¨ ottenuti per \(k = 1, \dots, K+1\). Qui \(K\) rappresenta il numero di intervalli in cui abbiamo
diviso il supporto di \(F\), mentre i valori \(t_k\) sono gli estremi che delimitano gli intervalli. Per ogni \(k = 1, \dots, K\)
consideriamo poi le seguenti quantit√†:
</p>
<ul class="org-ul">
<li>\(n_k =\) numero di elementi \(X_i\) del campione che cadono in \(I_k\);</li>
<li>\(p_k =\) probabilit√† che il singolo \(X_i\) cada in \(I_k\) se \(H_0\) √® vera.</li>
</ul>
<p>
\[p_k = P(X \in I_k \mid X \approx F) = F(t_{k+1}) - F(t_k)\]
Le quantit√† \(n_k\) sono dette <i>frequenze osservate degli intervalli \(I_k\)</i>, mentre le \(p_k\) sono dette <i>probabilit√† teoriche</i>.
Notiamo che per ogni \(k = 1, \dots, K\), il prodotto \(n p_k\) fornisce un numero atteso di elementi del campione che dovrebbe cadere
in \(I_k\). Pertanto se \(H_0\) √® vera, le differenze \(n_k - np_k\) dovrebbero essere piccole in valore assoluto.
Consideriamo infine la statistica
\[W = \sum_{k=1}^K \frac{(n_k - np_k)^2}{np_k}\]
Si pu√≤ dimostrare che quando \(H_0\) √® vera e quando le \(n_k\) sono sufficientemente grandi (almeno \(\geq\) 5), la \(W\) √® approssimativamente
distribuita come una Chi-Quadro con:
</p>
<ul class="org-ul">
<li>\(K-1\) gradi di libert√† se la funzione di ripartizione \(F\) √® stata decisa arbitrariamente senza fare uno presentivo dei dati campionari;</li>
<li>\(K-r-1\) gradi di libert√† se nella funzione di ripartizione \(F\) compaiono \(r\) parametri che sono stati stimati facendo uso dei
dati campionari.</li>
</ul>
<p>
In base alle considerazioni appena fatte saremo portati a rifiutare l'ipotesi nulla quando \(W\) assume valori troppo lontani dallo 0
per essere una Chi-Quadro con opportuni gradi di libert√†.
</p>

<p>
Specificamente, per ogni livello di significativit√† \(\alpha\), la regione critica per \(W\) risulta essere \(C = (\chi_{1-\alpha}^2, +\infty)\), dove \(\chi_{1-\alpha}^2\)
rappresenta il quantile di ordine \((1-\alpha)\) della Chi-Quadro con \(K-1\) o \(K-r-1\) gradi di libert√† a seconda che i valori dei
parametri di \(F\) siano stati stimati con i dati campionari oppure no.
</p>

<p>
Riprendiamo in considerazione l'esempio precedente e come in precedenza controlliamo l'ipotesi che la popolazione segua una
distribuzione esponenziale di parametro \(0.35\) con ampiezza \(\alpha = 0.05\), facendo uso del test Chi-Quadro.
\[(0.9, 1.2, 1.5, 2.2, 2.8, 3.0, 3.2, 4.1, 5.5, 6.0)\]
Il supporto di \(F\) in questo caso pu√≤ essere suddiviso in 3 intervalli: \(I_1 = [0, 2)\), \(I_2 = [2, 4)\) e \(I_3 = [4, +\infty)\).
Per questi tre intervalli avremo le seguenti frequenze osservate: \(n_1 = 3\), \(n_2 = 4\) e \(n_3 = 3\). Notiamo che il numero di
elementi per ogni classe √® inferiore di 5, mentre il metodo pu√≤ essere utilizzato solo se tale numero √® maggiore o uguale a 5.
</p>

<p>
Pertanto √® necessario o diminuire il numero delle classi o aumentare il campione. Supponiamo di poter aumentare la numerosit√† del
campione, arrivando ad \(n=20\) e supponiamo che con l'aggiunta dei nuovi 10 casi, il campione assuma valori
\((3.0, 4.1, 2.8, 5.5, 1.5, 2.2, 6.0, 1.2, 3.2, 0.9)\) e \((2.9, 1.7, 4.8, 4.3, 2.0, 7.1, 5.4, 0.9, 1.3, 3.4)\).
</p>

<p>
Allora avremo \(n_1 = 6 \quad p_1 = F(2) - F(0) = 0.50\), \(n_2 = 7 \quad p_2 = F(4) - F(2) = 0.25\) e \(n_3 = p_3 = F(+\infty) - F(4) = 0.25\),
utilizzando \(F(t) = 1 - e^{-0.35 t}\).
</p>

<p>
Di conseguenza, la statistica \(W\) assume valore
</p>
\begin{align*}
W &= \frac{(n_1 - 20p_1)^2}{20p_1} + \frac{(n_2 - 20p_2)^2}{20p_2} + \frac{(n_3 - 20p_3)^2}{20p_3}\\
&= \frac{((6 - 20 \cdot 0.5))^2}{20 \cdot 0.5} + \frac{((7 - 20 \cdot 0.25))^2}{20 \cdot 0.25} + \frac{((7 - 20 \cdot 0.25))^2}{20 \cdot 0.25}\\
&= 3.2
\end{align*}
<p>
Poich√© il valore del parametro \(\lambda\) della distribuzione esponenziale che stiamo controllando quale possibile distribuzione di \(X\)
non √® stato ricavato con stime campionarie, ma arbitrariamente nel nostro caso la statistica \(W\) √® distribuita coma una Chi-Quadro
con \(K - 1 = 2\) gradi di libert√†.
</p>

<p>
La regione critica si ricava cercando nelle tavole della Chi-Quadro, nella riga relativa ai 2 gradi di libert√†, che per \(\alpha = 0.05\)
offre \(C = (5.99, +\infty)\), da cui segue il non rifiuto dell'ipotesi nulla.
</p>

<p>
Ripetiamo il test effettuato nell'esempio precedente, sempre con ampiezza \(\alpha = 0.05\), controllando questa volta l'ipotesi che la
popolazione segua una distribuzione esponenziale il cui parametro \(\lambda\) viene stimato utilizzando i dati del campione
\((X_1, \dots, X_{20})\). Per stimare \(\lambda\) potremmo usare il metodo di massima verosimiglianza, oppure ricordare che \(\lambda = \frac{1}{E[X]}\)
e quindi ricavarlo stimando \(E[X]\) con la media campionaria \(\bar{X}_{20} = 3.075 \implies \lambda = 0.325\).
</p>

<p>
Suddividiamo ora il supporto di \(F\) negli stessi 3 intervalli in cui era suddiviso in precedenza, ovvero gli intervalli
\(I_1 = [0, 2)\), \(I_2 = [2, 4)\) e \(I_3 = [4, +\infty)\).
</p>

<p>
In questo caso avremo \(n_1 = 6 \quad p_1 = F(2) - F(0) = 0.48\), \(n_2 = 7 \quad p_2 = F(4) - F(2) = 0.25\) e \(n_3 = p_3 = F(+\infty) - F(4) = 0.27\).
</p>

<p>
Di conseguenza la statistica \(W\) assume valore
\[W = \sum_{i=1}^3 \frac{(n_i - 20 \cdot p_i)^2}{20 \cdot p_i} = \frac{(6 - 20 \cdot 0.48)^2}{20 \cdot 0.48} + \frac{(4 - 20 \cdot 0.25)^2}{20 \cdot 0.25} +
\frac{(7 - 20 \cdot 0.27)^2}{20 \cdot 0.27} = 2.62\]
Poich√© il valore del parametro \(\lambda\) √® stato ricavato da stime campionarie, allora questa volta la statistica \(W\) √® distribuita
come una Chi-Quadro con \(K-r-1 = 3-1-1 = 1\) gradi di libert√†.
</p>

<p>
Qui \(r=1\) poich√© 1 √® il numero di parametri di \(F\) che sono stati stimati.
</p>

<p>
La regione critica si trova andando a cercare sulle tavole della Chi-Quadro, nella riga relativa ad 1 grado di libert√†, ottenendo
cos√¨ per \(\alpha = 0.05\) la regione critica \(C = (3.84, +\infty)\) (\(W = 2.62\)), da cui segue il non rifiuto dell'ipotesi nulla.
</p>

<p>
Notiamo che partendo dagli stessi dati campionari negli ultimi 2 esempi, abbiamo accettato due ipotesi diverse, ovvero abbiamo
accettato inizialmente l'ipotesi che \(X\) fosse distribuita secondo un'esponenziale di parametro \(\lambda = 0.35\) e poi che fosse
distribuita secondo un'esponenziale di parametro \(\lambda = 0.325\). In effetti per√≤ occorre segnalare che in entrambi i casi non
abbiamo realmente accettato le ipotesi nulle, bens√¨ ci siamo limitati a non rifiutarle.
</p>

<p>
Dall'ultimo esempio abbiamo poi rilevato che una prima importante differenza tra il test di Kolmogorov-Smirnov ed il test Chi-Quadro
√® che il secondo necessita di un campione di maggiori dimensioni rispetto al primo per poter essere applicato. In compenso per√≤,
il test Chi-Quadro pu√≤ essere utilizzato anche quando la distribuzione \(F\) da controllare non √® continua.
</p>

<p>
Per esempio, un nostro collaboratore sostiene che non sussista relazione tra il momento in cui viene presentata la domanda per la
concessione di una ristrutturazione ed il momento in cui questa viene approvata. Egli sostiene invece che il comune rilascia
mensilmente un numero di concessioni limitato e distribuito secondo una legge di Poisson indipendentemente da quante domande
sono state presentate e quando. Per questa ragione decidiamo di controllare la sua ipotesi andando a rilevare il numero di
concessioni rilasciate negli ultimi 24 mesi, ottenendo i seguenti dati:
\[(3, 5, 2, 8, 3, 4, 2, 3, 0, 5, 7, 5, 3, 2, 1, 1, 2, 4, 0, 4, 6, 2, 3, 1)\]
e di controllare l'ipotesi del nostro collaboratore con il metodo del Chi-Quadro con livello di significativit√† \(\alpha = 0.05\).
</p>

<p>
Decidiamo di stimare il valore del parametro \(\lambda\) della distribuzione di Poisson facendo uso dei dati del campione, ricordando
che per tale distribuzione vale \(\lambda = E[X]\). Possiamo pertanto utilizzare \(\bar{X}_{24}\) come stima puntuale di \(\lambda\), ottenendo il
valore \(\bar{x}_{24} = 3.17\).
</p>

<p>
Decidiamo poi di dividere il supporto della distribuzione di Poisson in 4 intervalli, scegliendoli in modo che le corrispondenti
frequenze osservare \(f_k\) siano sufficientemente grandi.
</p>

<p>
Si decide per esempio di considerare i seguenti intervalli: \(I_1 = \{0, 1\}\), \(I_2 = \{2\}\), \(I_3 = \{3\}\), \(I_4 = \{4, \dots, +\infty\}\),
ai quali corrispondono le seguenti frequenze: \(n_1 = 5\), \(n_2 = 5\), \(n_3 = 5\) e \(n_4 = 9\).
</p>

<p>
Determiniamo ora le probabilit√† teoriche di ogni intervallo. Supponiamo per questo che sia vera l'ipotesi nulla, ovvero che \(X\)
sia distribuita secondo una Poisson di parametro \(\lambda = 3.17\) e quindi sia \(P(X = k) = \frac{\lambda^k}{k!} e^{-\lambda} = \frac{(3.17)^k}{k!}e^{-3.17}\)
per ogni \(k \in \mathbb{N}\).
</p>

<p>
Pertanto avremo
</p>
\begin{gather*}
p_1 = P(X=0 \text{ oppure } X=1) = P(X=0) + P(X=1) = \frac{(3.17)^0}{0!}e^{-3.17} + \frac{(3.17)^1}{1!}e^{-3.17} = 0.175\\
p_2 = P(X=2) = \frac{(3.17)^2}{2!}e^{-3.17} = 0.211\\
p_3 = P(X=3) = \frac{(3.17)^3}{3!}e^{-3.17} = 0.223\\
p_4 = 1 - P(X=0 \text{ oppure } X=1 \text{ oppure } X=3) = 0.391
\end{gather*}
<p>
La statistica \(W\) vale quindi \(w = \sum_{i=1}^4 \frac{(n_i - 24 \cdot p_i)^2}{24 \cdot p_i} = 0.17\).
</p>

<p>
Poich√© il valore del parametro \(\lambda\) √® stato ricavato da stime campionarie, allora la statistica \(W\) risulta essere distribuita
come una Chi-Quadro con \(K-r-1 = 4-1-1 = 2\) gradi di libert√†. Abbiamo posto \(r=1\) in quanto 1 √® il numero di parametri di \(F\)
che sono stati stimati facendo uso del campione.
</p>

<p>
La regione critica si trova andando a cercare sulle tavole della Chi-Quadro, nella riga relativa a 2 gradi di libert√†, ottenendo
cos√¨ per \(\alpha = 0.05\), la regione critica \(C = (5.99, +\infty)\) (\(w = 0.17\)).
</p>
</div>
</div>
<div id="outline-container-orgd0ddb61" class="outline-4">
<h4 id="orgd0ddb61"><span class="section-number-4">2.7.3</span> Test per il confronto delle distribuzioni di due popolazioni</h4>
<div class="outline-text-4" id="text-2-7-3">
<p>
Di seguito vengono presentati 3 test per verificare o rifiutare l'ipotesi che le distribuzioni di due distinte popolazioni \(X\) ed \(Y\)
siano identiche (non necessariamente gaussiane).
</p>

<p>
Denotate con \(F_X\) la distribuzione di \(X\) e con \(F_Y\) la distribuzione di \(Y\), sia \(H_0 : F_X(t) = F_Y(t)\) per ogni \(t \in \mathbb{R}\).
</p>

<p>
Quale ipotesi alternativa considereremo sempre e soltanto \(H_1 : F_X(t) \neq F_Y(t)\) per almeno un \(t \in \mathbb{R}\).
</p>

<p>
Il primo di questi metodi prende il nome di <i>test dei segni</i>, e si basa sui segni negativi o positivi delle differenze tra le
coppie di elementi presi dai campioni estratti dalle due popolazioni considerate.
</p>

<p>
Siano \((X_1, \dots, X_n)\) e \((Y_1, \dots, Y_n)\) due <i>campioni appaiati</i>, estratti da \(X\) ed \(Y\) rispettivamente. Questo significa che ogni
coppia \((X_i, Y_i)\) √® relativa allo stesso individuo o elemento (es.: il livello \(X_i\) di colesterolo di un paziente prima di aver
ricevuto una cura ed il livello di colesterolo \(Y_i\) dello stesso paziente dopo aver ricevuto la cura). Contiamo allora quante
volte si verifica \(X_i > Y_i\), \(X_i < Y_i\) e \(X_i = Y_i\).
</p>

<p>
Siano:
</p>
<ul class="org-ul">
<li>\(S^+ = \text{numero di volte che \(X_i > Y_i\)}\);</li>
<li>\(S^- = \text{numero di volte che \(X_i < Y_i\)}\);</li>
<li>\(S^= = \text{numero di volte che \(X_i = Y_i\)}\).</li>
</ul>

<p>
Se l'ipotesi nulla √® vera, allora √® logico aspettarsi che le quantit√† \(S^+\) ed \(S^-\) non si discostino molto tra loro. Infatti
se l'ipotesi nulla √® vera e se \(n-S^=\) √® sufficientemente grande (\(n - S^= \geq 10\)), la quantit√† \(S_n = S^+ - S^-\) risulta essere
normalmente distribuita con \(\mu = 0\) e \(\sigma^2 = \frac{n - S^=}{2}\).
</p>

<p>
Si pu√≤ quindi costruire una regione critica per \(S_n\) ragionando nel solito modo, rifiutando \(H_0\) quando \(S_n\) si discosta troppo
dallo 0 per essere una normale \(N\left(0, \sqrt{\frac{n-S^=}{2}}\right)\).
Specificamente per un fissato livello di significativit√† \(\alpha\), la regione critica per \(S_n\) risulta essere
\(C = \left(-\infty, -z_{1 - \frac{\alpha}{2}}\right) \cup \left(+z_{1 - \frac{\alpha}{2}}, +\infty\right)\), dove \(z_{1-\frac{\alpha}{2}}\) √® il quantile di ordine \(1 - \frac{\alpha}{2}\)
della normale standardizzata.
</p>

<p>
√à possibile effettuare il test anche quando la quantit√† \(n - S^=\) √® piccola. In questo caso si pu√≤ considerare la statistica
\(S^+\) e tener conto del fatto che quando sussiste l'ipotesi nulla, essa √® distribuita come una Binomiale di parametri
\(n - S^=\) e \(\frac{1}{2}\).
</p>

<p>
Segnaliamo l'esistenza di un test simile a quello dei segni ma pi√π elaborato, nel senso che tiene conto non solo dei segni
delle differenze ma anche delle ampiezze di queste differenze, e che porta il nome di <i>test dei segni di Wilcoxon</i>.
</p>

<p>
Per esempio, facciamo riferimento al problema gi√† descritto nel capitolo precedente, del confronto tra i redditi medi annui
delle famiglie di due diversi quartieri di una data citt√†. Ora trascuriamo per√≤ l'assunto che tali redditi siano normalmente
distribuiti e domandiamoci se √® ammissibile pensare che le due distribuzioni dei redditi siano identiche, utilizzando a tale
scopo il test dei segni appena introdotto, con un livello di significativit√† \(\alpha = 0.10\).
</p>

<p>
Sia \(X\) la popolazione del primo quartiere ed \(Y\) quella del secondo quartiere.
</p>

<p>
I campioni riportati nell'esempio citato non sono adatti a questo test, poich√© non hanno la stessa numerosit√†. Per tale ragione,
del secondo campione considereremo ora solo i primi 10 dati, ottenendo: \((22, 48, 51, 20, 28, 35, 39, 26, 50, 36)\) e
\((40, 42, 50, 26, 30, 34, 37, 28, 25, 30)\).
</p>

<p>
Per le 10 coppie considerate i segni delle differenze \(x_i - y_i\) che sono riportati nella tabella sotto:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-08_15-11-55.png" alt="screenshot_2018-06-08_15-11-55.png" />
</p>
</div>

<p>
Necessario sottolineare che i campioni devono essere appaiati, in altre parole la coppia \((X_i, Y_i)\) deve essere relativa alla
stessa unit√†, entit√† o individuo. Nel nostro caso potremmo ipotizzare che l'indice \(i\) sia relativo allo stesso nucleo
famigliare che viveva in precedenza nel quartiere della citt√†, associato alla popolazione \(X\) e poi √® andato a vivere in un
quartiere della citt√† associato alla popolazione \(Y\).
</p>

<p>
La quantit√† \(X_i - Y_i\) misura la differenza di reddito tra la famiglia \(i\), quando abitava nel quartiere \(X\), e adesso che si
√® trasferita nel quartiere \(Y\) (misura il prima - dopo, sebbene impropriamente detto).
</p>

<p>
Abbiamo quindi: \(S^+ = 6\), \(S^- = 4\) e \(S^= = 0\).
</p>

<p>
La statistica \(S_{10} = S^+ - S^- = 2\).
</p>

<p>
Notiamo che per \(\alpha = 0.10\), la regione critica del test, usando un'approssimazione alla normale, risulta essere
\(C = \left(-\infty, -z_{0.95}\sqrt{\frac{10}{2}}\right) \cup \left(+z_{0.95}\sqrt{\frac{10}{2}}, +\infty\right) = (-\infty, -3.67) \cup (+3.67, +\infty)\).
</p>

<p>
Pertanto non possiamo rifiutare l'ipotesi che le due distribuzioni siano le stesse, infatti il valore della statistica non
appartiene alla regione critica.
</p>

<p>
Il secondo test per il confronto delle distribuzioni di due popolazioni che ora consideriamo √® il <i>test dei ranghi di Wilcoxon</i>
o <i>test U di Mann-Whitney</i>.
</p>

<p>
Fornire un'espressione funzionale della statistica su cui questo test √® basato √® abbastanza complesso, pertanto ci limiteremo
a descrivere il procedimento da seguire per effettuare il test senza cercare di fornire un'interpretazione anche solo
intuitiva di esso. Sottolineiamo comunque che rispetto al test dei segni, ha il vantaggio di essere pi√π potente ed utilizzabile
anche per campioni non appaiati.
</p>

<p>
Siano quindi \((X_1, \dots, X_n)\) e \((Y_1, \dots, Y_m)\) due campioni di numerosit√† \(n\) ed \(m\) estratti da \(X\) ed \(Y\) rispettivamente.
Le fasi della procedura del test sono le seguenti:
</p>
<ul class="org-ul">
<li>Si ordina in senso crescente l'insieme di tutti i dati e si associa a ciascun dato il proprio rango, ovvero la posizione
in cui si trova nella sistemazione in ordine crescente dei dati;</li>
<li>Si sommano separatamente i ranghi relativi ai due campioni;</li>
<li><p>
Si calcolano le statistiche \(U_X = n \cdot m + \frac{n \cdot (n+1)}{2} - R_X\) e \(U_Y = n \cdot m + \frac{m \cdot (m+1)}{2} - R_Y\).
</p>

<p>
Se i conti sono corretti la somma di \(U_X\) ed \(U_Y\) deve essere uguale al prodotto tra le numerosit√† dei due campioni, vale
a dire che deve essere \(U_X + U_Y = n \cdot m\);
</p></li>
<li><p>
Si considera poi la statistica \(U = \text{min}\{U_X, U_Y\}\).
</p>

<p>
Si pu√≤ dimostrare che per \(n\) ed \(m\) sufficientemente grandi (in genere maggiori di 8), quando vale \(H_0\), la \(U\) √® approssimabile
tramite una normale con parametri \(\mu_U = \frac{n \cdot m}{2}\) e \(\sigma_U^2 = \frac{n \cdot m \cdot (n + m + 1)}{12}\).
</p>

<p>
Vale quindi \(\hat{Z}_{n, m} = \frac{U - \frac{n \cdot m}{2}}{\sqrt{\frac{n \cdot m . (n+m+1)}{12}}} \sim N(0, 1)\).
</p>

<p>
Per definire la regola di decisione del test si procede nel solito modo, ovvero fissata l'ampiezza \(\alpha\) del test, la regione
critica risulta essere \(C = \left(-\infty, -z_{1 - \frac{\alpha}{2}}\right) \cup \left(+z_{1 - \frac{\alpha}{2}}, +\infty\right)\), dove \(z_{1-\frac{\alpha}{2}}\) √® il
quantile di ordine \(1 - \frac{\alpha}{2}\) della normale standardizzata.
</p>

<p>
Nel caso in cui non sia verificata la condizione \(n, m > 8\), allora √® possibile ricorrere ad apposite tavole per determinare
la regione critica per \(U\).
</p></li>
</ul>

<p>
Riconsideriamo ancora il problema citato nell'ultimo esempio, del confronto tra i redditi medi annui delle famiglie di due
diversi quartieri di una citt√†. Come nell'esempio precedente trascuriamo l'assunto che tali redditi siano normalmente
distribuiti e domandiamoci se √® ammissibile pensare che le due distribuzioni dei redditi siano identiche. Utilizziamo questa
volta il test dei ranghi appena descritto, sempre con un livello di significativit√† \(\alpha = 0.10\) e, poich√© non √® necessario che
i due campioni abbiano egual numerosit√†, riconsideriamo i campioni cos√¨ come erano stati dati originariamente, vale a dire:
\((22, 48, 51, 20, 28, 35, 38, 26, 50, 36)\) e \((40, 42, 50, 26, 30, 34, 37, 28, 25, 30, 32, 38, 22, 55, 40)\).
</p>

<p>
Nella tabella sottostante vengono riportati i ranghi associati a ciascuno dei dati che compaiono nei due campioni:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-08_15-36-38.png" alt="screenshot_2018-06-08_15-36-38.png" />
</p>
</div>

<p>
Notiamo che tra i dati alcuni valori compaiono pi√π volte. In questo caso i loro ranghi sono definiti come il valor medio tra le
loro posizioni in ordine crescente. Sommiamo ora i ranghi di ciascuno dei due campioni ottenendo \(r_X = 127.5\) e \(r_Y = 197.5\)
</p>

<p>
Calcoliamo poi le realizzazioni delle statistiche \(U_X\) ed \(U_Y\), ottenendo \(u_X = 10 \cdot 15 + \frac{10 \cdot (10 + 1)}{2} - r_X = 77.5\) e
\(u_Y = 10 \cdot 15 + \frac{15 \cdot (15 + 1)}{2} - r_Y = 72.5\).
</p>

<p>
Notiamo che vale \(u_X + u_Y = 10 \cdot 15 = 150\).
</p>

<p>
La realizzazione di \(U = \text{min}\{U_X, U_Y\}\) risulta essere il valore \(u = 72.5\).
</p>

<p>
Poich√© i due campioni sono entrambi di numerosit√† maggiore di 8, si pu√≤ approssimare \(U\) con una normale con
\(\mu_U = \frac{10 \cdot 15}{2} = 75\) e \(\sigma_U = \sqrt{\frac{10 \cdot 15 \cdot (10 + 15 + 1)}{12}} = 18\).
</p>

<p>
A questo punto consideriamo la \(\hat{Z}_{10, 15} = \frac{U - 75}{18}\) che assume valore \(\hat{z}_{10, 15} = 0.14\).
</p>

<p>
Pertanto accetteremo (non rifiuteremo) l'ipotesi \(H_0\), essendo \(C = (-\infty, -1.65) \cup (1.65, +\infty)\) la regione critica con un
livello di significativit√† \(\alpha = 0.10\).
</p>

<p>
Il terzo test per il confronto delle distribuzioni due due popolazioni che ora presentiamo √® un <i>adattamento del test di
Kolmogorov-Smirnov</i> al caso di due campioni.
</p>

<p>
Questo adattamento non richiede che i due campioni siano appaiati, cio√® con pari numerosit√† ed estratti da \(X\) ed \(Y\),
ma in compenso pu√≤ essere utilizzato solo quando ci siano validi motivi per pensare che la distribuzione delle popolazioni
da confrontare sia continua.
</p>

<p>
Siano quindi \((X_1, \dots, X_n)\) e \((Y_1, \dots, Y_m)\) due campioni di numerosit√† \(n\) ed \(m\) estratti da \(X\) ed \(Y\) rispettivamente. Siano
poi \(F_{X, m}\) ed \(F_{Y, m}\) le funzioni di ripartizione empiriche di \(X\) ed \(Y\) ottenute con i campioni e sia
\[D_{n, m} = \text{sup}_{t \in \mathbb{R}}|F_{X, n}(t) - F_{Y, m}(t)|\]
la statistica che specifica l'estremo superiore delle distanze, in valore assoluto, tra le due funzioni di ripartizione
empiriche. Anche in questo caso si pu√≤ dimostrare che quando \(H_0\) √® vera e quando \(F_X\) √® una funziona continua, allora \(D_{n, m}\)
√® indipendente dalla forma di \(F_X\), ovvero ha la stessa distribuzione qualunque sia \(F_X\) (ma varier√† al variare di \(n\)).
</p>

<p>
Anche per la distribuzione della statistica campionaria \(D_{n, m}\), al variare di \(n\) ed \(m\), esistono apposite tabelle per
determinare i quantili. √à quindi possibile fissare, al solito, delle regioni di accettazione e critiche al variare di \(n\)
ed \(m\) e del livello di significativit√†.
</p>

<p>
Specificamente rifiuteremo \(H_0\) quando \(D_{n, m}\) assume valori "grandi", cio√® quando cade nella regione critica \(C = (d_{1 - \alpha}, 1]\),
dove il quantile \(d_{1 - \alpha}\) √® quel valore per cui risulta \(P(D_{n, m} \leq d_{1 - \alpha}) = 1 - \alpha\), che pu√≤ essere determinato tramite le
apposite tavole.
</p>
</div>
</div>
<div id="outline-container-org19d8445" class="outline-4">
<h4 id="org19d8445"><span class="section-number-4">2.7.4</span> Test di indipendenza</h4>
<div class="outline-text-4" id="text-2-7-4">
<p>
Un problema che si pone frequentemente nelle applicazioni √® quello di stabilire se due caratteri di una popolazione bidimensionale
sono tra loro stocasticamente indipendenti oppure no. Per rispondere a questa domanda sono stati inventati diversi test, ma uno
in particolare viene sempre utilizzato. Esso prende il nome di <i>test del Chi-Quadro per l'indipendenza</i>, e come vedremo,
ricorda molto, nella sua formulazione, il test del Chi-Quadro per la bont√† dell'adattamento.
</p>

<p>
Si consideri una popolazione bidimensionale \((X, Y)\) e si supponga di poter estrarre da essa un campione casuale
\(((X_1, Y_1), \dots, (X_n, Y_n))\). Si vuole controllare, con livello di significativit√† \(\alpha\), l'ipotesi :
</p>
<ul class="org-ul">
<li>\(H_0\) : i caratteri \(X\) ed \(Y\) sono indipendenti,</li>
</ul>
<p>
considerando quale ipotesi alternativa quella ovvia, ovvero,
</p>
<ul class="org-ul">
<li>\(H_1\) : i caratteri \(X\) ed \(Y\) non sono indipendenti.</li>
</ul>

<p>
Per effettuare il test del Chi-Quadro, occorre inizialmente fare una partizione dei due supporti dei caratteri \(X\) ed \(Y\) in
un numero finito di intervalli ciascuno. Denotiamo con \(I_k^X\), per \(k = 1, \dots, M_X\) ed \(I_j^Y\), per \(j = 1, \dots, M_Y\), gli
intervalli che formano una partizione del supporto di \(X\) ed \(Y\).
</p>

<p>
Per ogni coppia \((k, j)\) consideriamo le seguenti quantit√†:
</p>
<ul class="org-ul">
<li>\(n_k^X =\) numero di elementi \(X_i\) del campione che cadono in \(I_k^X\);</li>
<li>\(n_j^Y =\) numero di elementi \(Y_i\) del campione che cadono in \(I_j^Y\);</li>
<li>\(n_{k, j} =\) numero di elementi \((X_i, Y_i)\) del campione che cadono in \(I_k^X \times I_j^Y\);</li>
<li>\(f_k^X = \frac{n_k^X}{n} =\) frequenza relativa di \(I_k^X\);</li>
<li>\(f_j^Y = \frac{n_j^Y}{n} =\) frequenza relativa di \(I_j^Y\);</li>
<li>\(f_{k, j} = \frac{n_{k, j}}{n} =\) frequenza relativa di \(I_k^X \times I_j^Y\).</li>
</ul>

<p>
Le quantit√† \(f_{k, j}\) sono dette <i>frequenze relative osservate</i> delle regioni \(I_k^X \times I_j^Y\).
</p>

<p>
Notiamo che per ogni coppia \((k, j)\), il prodotto \(f_k^X \cdot f_j^Y\) fornisce invece una <i>frequenza relativa attesa</i> di elementi del
campione che dovrebbero cadere in \(I_k^X \times I_j^Y\) se fosse vera l'ipotesi nulla \(H_0\), poich√© in questo caso la frequenza di ogni regione
deve essere uguale al prodotto delle frequenze marginali di quella regione.
</p>

<p>
Se \(H_0\) √® vera quindi, le differenze \(f_{k, j} - f_k^X \cdot f_j^Y\) dovrebbero essere piccole in valore assoluto.
</p>

<p>
Consideriamo infine la statistica \(W = n \cdot \sum_{k=1}^{M_X}\sum_{j=1}^{M_Y} \frac{(f_{k, j} - f_k^X \cdot f_j^Y)^2}{f_k^X \cdot f_j^Y}\).
</p>

<p>
Si pu√≤ mostrare che quando l'ipotesi nulla √® vera e quando le \(n_{k, j}\) sono sufficientemente grandi, almeno maggiori o uguali a 5,
allora \(W\) √® approssimativamente distribuita come una Chi-Quadro con \((M_X - 1) \cdot (M_Y - 1)\) gradi di libert√†.
</p>

<p>
La regola di decisione del test segue in base alle considerazioni fatte sopra, saremo portati a rifiutare l'ipotesi nulla
quando la \(W\) assume valori troppo lontani dallo 0 per essere una Chi-Quadro con opportuni gradi di libert√†. Specificamente
per ogni livello di significativit√† \(\alpha\) la regione critica per \(W\) risulta essere \(C = (\chi_{1 - \alpha}, +\infty)\), dove \(\chi_{1-\alpha}^2\) rappresenta
il quantile di ordine \((1 - \alpha)\) della Chi-Quadro con \((M_X - 1)(M_Y - 1)\) gradi di libert√†.
</p>

<p>
Per esempio, considerata la popolazione costituita dai nuclei famigliari residenti in un quartiere di una data citt√†, si
supponga di voler stabilire se esiste una dipendenza tra i due caratteri:
</p>
<ul class="org-ul">
<li>\(X =\) reddito medio annuo della famiglia (in migliaia)</li>
<li>\(Y =\) et√† media del nucleo famigliare.</li>
</ul>
<p>
A tale scopo si effettua un'indagine su un totale di 200 nuclei famigliari scelti in modo casuale tra quelli del quartiere
andando ad osservare, per ogni nucleo, i valori di questi due caratteri.
</p>

<p>
Come risultato dell'indagine si ottiene la tabella sotto riportata:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-08_17-36-00.png" alt="screenshot_2018-06-08_17-36-00.png" />
</p>
</div>

<p>
Viene spontaneo, in questo caso, considerare le cinque classi in cui √® stato suddiviso il supporto del carattere \(X\) e le quattro
classi in cui √® stato suddiviso il supporto del carattere \(Y\), come agli intervalli su cui costruire il test. Avremo
\(M_X = 5\) e \(M_Y = 4\). Inoltre avremo \(I_1^X = [0, 20] \quad I_2^X = (20, 30] \quad I_3^X = (30, 40] \quad I_4^X = (40, 50] \quad I_5^X = (50, \infty]\)
e \(I_1^Y = [0, 20] \quad I_2^/ = (20, 30] \quad I_3^Y = (30, 50] \quad I_4^Y = (50, \infty]\).
</p>

<p>
Le frequenze assolute \(n_{k, j}\) sono quindi quelle che compaiono nella tabella introdotta in precedenza. Notiamo che in tale tabella
sono riportate anche le frequenze assolute marginali dei due caratteri. Poich√© le frequenze assolute osservate sono riportare
anche le frequenze assolute marginali dei due caratteri. Poich√© le frequenze assolute osservate assumono sempre valore non inferiore
a 5, non abbiamo problemi ad applicare il metodo del Chi-Quadro per effettuare il test.
</p>

<p>
Calcoliamo quindi le frequenze relativa, ottenendo quanto riportato nella tabella seguente:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-08_17-42-04.png" alt="screenshot_2018-06-08_17-42-04.png" />
</p>
</div>

<p>
Questa tabella contiene tutto quanto necessario per calcolare la realizzazione della statistica \(W\) su cui si base il test.
In essa, infatti, si trovano le quantit√† \(f_{k, j}, f_k^X, f_j^Y\) per ogni \(k = 1, \dots, 5\) e \(j = 1, \dots, 4\).
</p>

<p>
Si ottiene allora il seguente valore: \(W = 200 \cdot \sum_{k=1}^5 \sum_{j=1}^4 \frac{(f_{k, j} - f_k^X \cdot f_j^Y)^2}{f_k^X \cdot f_j^Y} = 26.4\).
</p>

<p>
Supponiamo di aver fissato un livello di significativit√† \(\alpha = 0.05\) per il test, allora per determinare l'estremo \(\chi_{1-\alpha}^2\) della
regione critica, occorre cercare il quantile di ordine 0.95 relativo alla Chi-Quadro con \((5-1)(4-1) = 12\) gradi di libert√†.
Essendo in questo caso \(\chi_{0.95}^2 = 21\) la regione critica per \(W\), risulta essere \(C = (21, +\infty)\), portando a rifiutare l'ipotesi
nulla che i due caratteri siano indipendenti.
</p>

<p>
Come nel caso del test Chi-Quadro per la bont√† dell'adattamento, anche il test Chi-Quadro per l'indipendenza ha il vantaggio di
essere utilizzabile quando si considerano caratteri con distribuzione non continue.
</p>

<p>
Addirittura esso pu√≤ essere utilizzato considerando caratteri con modalit√† non numeriche.
</p>

<p>
Ora riconsideriamo come popolazione quella costituita dai nuclei famigliari residenti nel solito quartiere della solita citt√†.
Si supponga di voler stabilire se esiste una dipendenza tra i due caratteri:
</p>
<ul class="org-ul">
<li>\(X =\) reddito medio annuo della famiglia (in migliaia);</li>
<li>\(Y =\) titolo di studio del capofamiglia.</li>
</ul>
<p>
A tale scopo si effettua una nuova indagine su un totale di 100 nuclei famigliari scelti in modo casuale tra quelli del
quartiere andando ad osservare per ogni nucleo i valori di questi due caratteri.
</p>

<p>
Come risultato dell'indagine si ottiene la tabella sotto riportata:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-08_17-55-03.png" alt="screenshot_2018-06-08_17-55-03.png" />
</p>
</div>

<p>
Viene spontaneo in questo caso considerare le 5 classi in cui √® stato suddiviso il supporto del carattere \(X\) ed alle 4 in cui
√® stato suddiviso il supporto del carattere \(Y\), come agli intervalli su cui costruire il test. Avremo \(M_X = 5\) e \(M_Y = 4\).
</p>

<p>
In questo caso per√≤ vi sono diverse frequenze assolute osservate che hanno valore minore di 5. Occorre pertanto raggruppare
ulteriormente le osservazioni in modo da avere tutte frequenze osservare maggiori 0 uguali a 5.
</p>

<p>
Nella tabella seguente √® proposto un nuovo raggruppamento che soddisfa la condizione richiesta:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-08_17-58-00.png" alt="screenshot_2018-06-08_17-58-00.png" />
</p>
</div>

<p>
Utilizzando questo raggruppamento per effettuare il test, avremo allora \(M_X = 3\) e \(M_Y = 4\).
</p>

<p>
Inoltre, avremo \(I_1^X = [0, 30] \quad I_2^X = (30, 50] \quad I_3^X = (50, \infty)\) e
\(I_1^Y = \text{media inferiore} \quad I_2^Y = \text{media superiore} \quad I_3^Y = \text{maturit√†} \quad I_4^Y = \text{laurea}\).
</p>

<p>
Le frequenze assolute \(n_{k, j}\) sono quindi quelle che compaiono nella tabella introdotta in precedenza. Notiamo che in tale
tabella sono riportate anche le frequenze assolute marginali dei due caratteri.
</p>

<p>
Poich√© le frequenze assolute osservate assumono sempre valore non inferiore a 5, non abbiamo problemi ad applicare il metodo del
Chi-Quadro per effettuare il test.
Calcoliamo quindi le frequenze relativa ottenendo quanto riportato nella tabella seguente:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-08_18-03-57.png" alt="screenshot_2018-06-08_18-03-57.png" />
</p>
</div>

<p>
Si ottiene allora il seguente valore: \(W = 100 \cdot \sum_{k=1}^3 \sum_{j=1}^4 \frac{(f_{k, j} - f_k^X \cdot f_j^Y)^2}{f_k^X \cdot f_j^Y} = 3.15\).
</p>

<p>
Supponiamo di aver fissato un livello di significativit√† \(\alpha = 0.05\) per il test, allora per determinare l'estremo \(\chi_{1-\alpha}^2\) della
regione critica, occorre cercare il quantile di ordine 0.95 relativo alla Chi-Quadro con \((3-1)(4-1) = 6\) gradi di libert√†.
Essendo in questo caso \(\chi_{0.95} = 12.6\), la regione critica per \(W\) risulta essere \(C = (12.6, +\infty)\) (\(w = 3.15\)) che non consente
di rifiutare l'ipotesi nulla che sussista indipendenza tra i redditi medi annui familiari ed i titoli di studio.
</p>
</div>
</div>
<div id="outline-container-org8acd98f" class="outline-4">
<h4 id="org8acd98f"><span class="section-number-4">2.7.5</span> Test di incorrelazione</h4>
<div class="outline-text-4" id="text-2-7-5">
<p>
Il test di incorrelazione che presentiamo ora non √® basato sul coefficiente di correlazione lineare di Pearson, ma su una
statistica campionaria che porta il nome di <i>coefficiente di correlazione dei ranghi \(R_S\) di Spearman</i>. Esso viene incluso
nei test di tipo non-parametrico in quanto la determinazione di \(R_S\) non coinvolge direttamente i valori numerici assunti
dai dati campionari, ma solo i loro ranghi di cui viene fornita la definizione.
</p>

<p>
Consideriamo un campione \(((X_1, Y_1), \dots, (X_n, Y_n))\) di numerosit√† \(n\) estratto in modo casuale dalla popolazione bidimensionale
\((x, y)\). Ordiniamo in senso crescente prima l'insieme dei dati di tipo \(x_i\) e successivamente quelli di tipo \(y_i\).
</p>

<p>
√à detto rango di ciascun dato la posizione che esso assume nella sequenza cos√¨ ottenuta di dati dello stesso tipo.
</p>

<p>
Ad ogni coppia \((x_i, y_i)\) associamo ora la corrispondente coppia di ranghi \((r_i^x, r_i^y)\) e denotiamo con \(d_i\) le loro
differenze \(d_i = r_i^x - r_i^y\).
</p>

<p>
√® detto <i>coefficiente di correlazione dei ranghi di Spearman</i> la statistica
\[R_s = 1 - \frac{6 \cdot \sum_{i=1}^n d_i^2}{n^3 - n}\]
Il coefficiente \(R_S\) soddisfa propriet√† simili a quelle di cui gode il coefficiente di correlazione lineare di Pearson e
consente di definire un nuovo tipo di incorrelazione (che chiameremo incorrelazione nel senso di Spearman) che si ha quando
\(R_S\) assume valore zero.
</p>

<p>
La possibilit√† di utilizzare \(R_S\) in un test di ipotesi deriva dal fatto che indipendentemente dalla forma della distribuzione
congiunte \((X, Y)\), quando i caratteri \(X\) ed \(Y\) sono incorrelati, nel senso di Spearman, e la numerosit√† del campione √® maggiore
di 10, allora la statistica
\[\tilde{T}_n = R_S \cdot \sqrt{\frac{n-2}{1 - R_S^2}}\]
risulta essere approssimativamente distribuita come una t di Student con \((n-2)\) gradi di libert√†.
</p>

<p>
Dovendo controllare l'ipotesi
</p>
<ul class="org-ul">
<li>\(H_0\) : i caratteri \(X\) ed \(Y\) sono incorrelati secondo Spearman;</li>
</ul>
<p>
contro
</p>
<ul class="org-ul">
<li>\(H_1\) : i caratteri \(X\) ed \(Y\) sono correlati secondo Spearman.</li>
</ul>
<p>
Possiamo pensare di non rifiutare \(H_0\) quando \(\tilde{T}_n\) assume valori non troppo distanti dallo 0 e di rifiutarla in favore di
\(H_1\) in caso contrario.
</p>

<p>
Ragionando nel solito modo, si ottiene che per un livello di significativit√† \(\alpha\), la regione critica per la statistica \(\tilde{T}_n\)
√® la seguente: \(C = \left(-\infty, -t_{1-\frac{\alpha}{2}}\right) \cup \left(+t_{1-\frac{\alpha}{2}}, +\infty\right)\) dove \(t_{1 - \frac{\alpha}{2}}\) √® il quantile di ordine
\(1 - \frac{\alpha}{2}\) della t di Student con \((n-2)\) gradi di libert√†.
</p>

<p>
Prima di mostrare un esempio di applicazione del test di incorrelazione basato sul coefficiente di Spearman, osserviamo che esso pu√≤
essere utilizzato alternativamente al test Chi-Quadro per verificare la dipendenza tra 2 caratteri di una popolazione.
</p>

<p>
Infatti, ricordiamo che l'indipendenza di due caratteri √® una propriet√† pi√π forte dell'incorrelazione, nel senso che
l'indipendenza implica l'incorrelazione. Viceversa possiamo affermare che se non sussiste incorrelazione allora non sussiste
neanche l'indipendenza.
</p>

<p>
Disponendo di un campione di numerosit√† limitata, come visto, in genere non √® possibile applicare il test Chi-Quadro; per tale
ragione si pu√≤ allora provare a controllare l'incorrelazione tra i caratteri ed affermare che tra essi sussiste dipendenza
quando l'ipotesi nulla di incorrelazione viene rifiutata.
</p>

<p>
Per esempio, si riconsideri il problema presentato precedentemente relativo alla popolazione \((X, Y)\) dei redditi medi annui
(in migliaia) e dell'et√† media dei nuclei familiari di un quartiere di una data citt√†.
</p>

<p>
Ora per√≤ si supponga di disporre solo di un campione di numerosit√† 10 la cui realizzazione √®
\(((21.4, 51), (23.0, 25), (40.5, 35), (57.0, 48), (30.0, 20))\) e
\(((32.5, 22), (35.5, 68), (60.0, 41), (29.0, 33), (42.0, 27))\).
</p>

<p>
Con tale numerosit√† √® impensabile effettuare un test Chi-Quadro per l'indipendenza poich√© esso richiede frequenze osservate
maggiori o uguali a 5 per ogni classe.
</p>

<p>
Proviamo allora a chiederci solo se sussiste incorrelazione tra i due caratteri della popolazione utilizzando il coefficiente
di correlazione dei ranghi di Spearman e facendo un test con significativit√† \(\alpha = 0.05\).
</p>

<p>
A tale scopo associamo i ranghi ai dati campionari e riportiamo il risultato nella tabella seguente:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-08_18-42-41.png" alt="screenshot_2018-06-08_18-42-41.png" />
</p>
</div>

<p>
La correlazione \(R_S\) di Spearman assume allora valore \(r_S = 1 - \frac{6 \cdot \sum_{i=1}^n d_i^2}{10^3 - 10} = 0.212\), da cui si ricava la
realizzazione della statistica \(\tilde{T}_n\): \(\tilde{t}_{10} = r_S \cdot \sqrt{\frac{10-2}{1-r_S^2}} = 0.212 \cdot \sqrt{\frac{8}{0.995}} = 0.613\).
</p>

<p>
Controlliamo ora se il valore ottenuto dalla statistica consente di accettare l'ipotesi \(H_0\) che non esiste correlazione tra i
due caratteri. Per questo √® sufficiente notare che la regione critica del test, relativamente alla statistica \(\tilde{T}_n\) √®
la seguente: \(C = (-\infty, -t_{0.975}) \cup (+t_{0.975}, +\infty) = (-\infty, -2.30) \cup (+2.30, +\infty)\), dove il quantile \(t_{0.975} = 2.30\) √® stato ricavato
dalla tavola della distribuzione t di Student sulla riga relativa ad 8 gradi di libert√†.
</p>

<p>
Poich√© il valore da noi osservato cade nella regione di accettazione del test, non possiamo rifiutare l'ipotesi che vi sia
incorrelazione tra reddito ed et√†.
</p>

<p>
Il fatto che non si possa escludere l'incorrelazione purtroppo non fornisce informazioni sull'indipendenza; infatti i caratteri
possono essere incorrelati ma non indipendenti.
</p>

<p>
Concludiamo con due brevi considerazioni sull'ultimo test descritto.
</p>

<p>
Abbiamo visto che esso pu√≤ essere effettuato anche con campioni di piccole dimensioni. In effetti si pu√≤ dire che oltre le 30
misure, l'aumento del tempo nella sua esecuzione non √® compensato da un aumento della potenza del test. Bisognerebbe poi
considerare l'eventualit√† che alcuni dati compaiano pi√π volte nel campione. In questo caso la definizione del coefficiente
\(R_S\) va modificata con opportuni termini correttivi.
</p>

<p>
Come si pu√≤ notare, per determinare il coefficiente \(R_S\) non occorre conoscere esattamente i valori numerici dei dati campionari,
ma √® succifiente poter definire un ordinamento tra essi (dovendo definire i ranghi). Per questa ragione, il coefficiente \(R_S\)
di Spearman viene talvolta utilizzato come indice di correlazione tra caratteri di tipo qualitativo per cui sia possibile
creare una relazione d'ordine nell'insieme di qualit√† da essi assumibili.
</p>
</div>
</div>
</div>

<div id="outline-container-orge58cbc3" class="outline-3">
<h3 id="orge58cbc3"><span class="section-number-3">2.8</span> Regressione Lineare</h3>
<div class="outline-text-3" id="text-2-8">
<p>
Consideriamo una popolazione \((m+1)\) dimensionale \((X_1, \dots, X_m, Y)\). In molti casi applicativi risulta particolarmente utile o
interessante stabilire se tra i caratteri della popolazione sussistano legami di dipendenza che descrivano uno di essi come
espressione funzionale degli altri, ovvero se esista una relazione del tipo \(Y = f(X_1, \dots, X_m)\) dove la funzione \(f\) pu√≤
essere indifferentemente deterministica o contenente parametri aleatori.
</p>

<p>
Trovarsi a conoscenza di una relazione di questo tipo consente infatti di risolvere molti problemi pratici soprattutto quando
si incontrano difficolt√† a rilevare i valori assunti dal carattere \(Y\). Si pensi ad esempio ad una popolazione costituita dagli
immobili di una grande citt√†, al carattere \(Y\) come al loro valore commerciale ad ai caratteri \(X_k\) come ai valori associati a
diverse loro caratteristiche (anno di costruzione, distanza dal centro, metratura, ecc.). Solitamente √® difficile fornire un
valore commerciale dell'immobile, mentre risulta facile determinare altre caratteristiche. Per tale ragione sarebbe utile
poter esprimere il valore \(Y\) in funzione di quelli assunti dagli altri caratteri.
</p>

<p>
Osserviamo poi che √® intuitivo pensare che tra il valore commerciale e le altre caratteristiche dell'immobile sussista una
relazione tipo quella introdotta in precedenza, ovvero \(Y = f(X_1, \dots, X_m)\), seppure senza conoscerne l'espressione, ovvero la
forma della funzione \(f\).
</p>

<p>
Un'equazione del tipo \(Y = f(X_1, \dots, X_m)\) viene detta <i>equazione di regressione del carattere \(Y\) rispetto ai caratteri
\(X_1, \dots, X_m\)</i>. √à detta <i>variabile di risposta</i>, o dipendente, la \(Y\), mentre sono dette <i>variabili esplicative</i>, o
indipendenti, o regressori, le \(X_1, \dots, X_m\).
</p>

<p>
Con <i>analisi di regressione</i> si intende invece la verifica dell'ammissibilit√† di una relazione del tipo \(Y = f(X_1, \dots, X_m)\) e,
in caso affermativo, la determinazione di una stima della funzione \(f\) che lega la variabile di risposta alle variabili
esplicative, o ad un sottoinsieme di esse.
</p>

<p>
Si noti che un'analisi di regressione deve essere effettuata facendo ricorso all'estrazione di un campione di numerosit√† finita,
e quindi verificando l'ammissibilit√† della relazione \(Y = f(X_1, \dots, X_m)\) ricorrendo ai metodi della statistica inferenziale,
poich√©, come al solito, non possiamo pensare di poter analizzare tutti gli individui appartenenti alla popolazione. Lo stesso
vale per la determinazione di una stima di \(f\).
</p>

<p>
In questo capitolo ci limiteremo a considerare un caso particolare di equazione di regressione lineare a cui √® dedicata vasta
letteratura statistica. √à questo il caso in cui si suppone che la \(f\) sia una funzione lineare nelle variabili esplicative
\(X_k\) e in un addendo aleatorio \(E\), ovvero il caso in cui la relazione cercata √® del tipo
\[Y = \alpha_0 + \alpha_1 \cdot X_1 + \dots + \alpha_m \cdot X_m + E\]
dove \(\alpha_k, k = 0, \dots, m \in \mathbb{R}\) ed \(E \sim N(0, \sigma^2)\).
</p>

<p>
In questo caso si parla di <i>regressione lineare</i> riferendosi in particolare alla <i>regressione lineare semplice</i> se nella relazione
sopra compare una sola variabile esplicativa e alla <i>regressione lineare multipla</i> in caso contrario.
</p>

<p>
Il termine aleatorio \(E\) √® detto solitamente <i>residuo</i> o <i>errore</i>. Considerando il valore che ci si deve attendere per la
variabile di risposta conoscendo le realizzazioni degli altri caratteri \(\hat{Y} = \alpha_0 + \alpha_1 \cdot X_1 + \dots + \alpha_m \cdot X_m\), il residuo
descrive scostamenti da tale valore atteso, imputabili a cause aleatorie e non controllabili quali ad esempio, errori di misura,
dipendenze da variabili non considerate o valutazioni soggettive.
</p>

<p>
Si osservi che la scrittura \(Y = \alpha_0 + \alpha_1 \cdot X_1 + \dots + \alpha_m \cdot X_m + E\) potrebbe risultare ambigua, nel senso che potrebbe portare a pensare
che il residuo abbia lo stesso valore per ogni singolo individuo della popolazione. In realt√† il residuo ha solo la stessa
distribuzione per ogni singolo valore.
</p>

<p>
L'equazione \(Y = \alpha_0 + \alpha_1 \cdot X_1 + \dots + \alpha_m \cdot X_m + E\) descrive infatti la distribuzione del carattere \(Y\) come distribuzione della somma
di \(m+1\) variabili, tra cui una che esprime gli scostamenti aleatori.
</p>

<p>
Per ovviare al rischio di incomprensioni, preferiamo quindi riscrivere la precedente relazione esplicitando il fatto che, tanto
il residuo quanto i valori assunti dalle variabili esplicative, variano per ogni individuo della popolazione, considerando
d'ora in poi l'equazione:
\[Y_i = \alpha_0 + \alpha_1 \cdot X_{1, i} + \dots + \alpha_m \cdot X_{m, i} + E_i\]
dove l'indice \(i\) varia da 1 ad \(N\), totale degli individui della popolazione.
</p>

<p>
In questo capitolo tratteremo in modo particolare la regressione lineare semplice che √® il caso pi√π interessante da un punto di
vista didattico. Dedicheremo solo una sezione conclusiva alla regressione lineare multipla, accennando rapidamente ai
problemi ad essa connessi.
</p>

<p>
In particolare vedremo prima come si stimano le costanti del modello lineare, ovvero la varianza dei residui e le costanti
\(\alpha_k\), e poi come si controlla l'ammissibilit√† del modello lineare per descrivere le eventuali dipendenze tra i caratteri della
popolazione.
</p>

<p>
Notiamo che istintivamente verrebbe naturale provare subito a controllare la validit√† del modello lineare e solo successivamente,
in caso di risultati positivi, determinare la costanti che in esso compaiono.
</p>

<p>
Si procede in realt√† al contrario per due motivi fondamentali:
</p>
<ol class="org-ol">
<li>Abbiamo visto nel capitolo 6 che lo statistico non effettua mai un test per vedere se una certa ipotesi √® vera, bens√¨ per vedere
se tale ipotesi non pu√≤ essere rifiutata. Nella regressione lineare, in genere si assume a priori la validit√† della relazione
\(Y_i = \alpha_0 + \alpha_1 \cdot X_{1, i} + \dots + \alpha_m \cdot X_{m, i} + E_i\) e solo successivamente si controlla se i dati portano ad un rifiuto di tale ipotesi;</li>
<li>I test di ammissibilit√† della relazione \(Y_i = \alpha_0 + \alpha_1 \cdot X_{1, i} + \dots + \alpha_m \cdot X_{m, i} + E_i\) si basano principalmente su particolari
statistiche, la cui realizzazione pu√≤ essere determinata solo dopo aver effettuato le stime delle costanti (varianza dei
residui e costanti \(\alpha_k\)).</li>
</ol>
</div>
<div id="outline-container-org569a306" class="outline-4">
<h4 id="org569a306"><span class="section-number-4">2.8.1</span> Stima delle costanti del modello</h4>
<div class="outline-text-4" id="text-2-8-1">
<p>
Consideriamo una popolazione bidimensionale \((X, Y)\) ed assumiamo che tra i due caratteri esista un <i>legame di dipendenza
esprimibile tramite un'equazione di regressione lineare (semplice)</i>. Per ogni individuo \(i = 1, \dots, N\), sia quindi
\(Y_i = \alpha_0 + \alpha_1 \cdot X_i + E_i\). In primo luogo potremmo essere interessati a determinare il <i>valore delle costanti</i> \(\alpha_0\) e \(\alpha_1\).
Ovviamente, a meno di non disporre dei dati relativi a tutti gli \(N\) individui della popolazione, di tali costanti non
potremo fare altro che <i>determinarne delle stime numeriche</i> che denoteremo con \(a_0\) e \(a_1\).
</p>

<p>
Supponiamo quindi di disporre di un campione \(\{(X_1, Y_1), \dots, (X_n, Y_n)\}\) di numerosit√† \(n\). Tre ipotesi devono essere fatte per
determinare le stime \(a_0\) e \(a_1\). Per ora le assumeremo valide, rimandando ai prossimi paragrafi le tecniche utilizzabili per
accertarne la validit√†. Tali ipotesi, che si riferiscono ai residui, sono le seguenti:
</p>
<ul class="org-ul">
<li>\(E[E_i] = 0 \quad \forall i = 1, \dots, N\);</li>
<li>\(V[E_i] = \sigma^2 \quad \forall i = 1, \dots, N\);</li>
<li>Le variabili \(E_i\) sono incorrelate tra loro.</li>
</ul>

<p>
L'ipotesi \(V[E_i] = \sigma^2 \quad \forall i = 1, \dots, N\) viene solitamente detta <i>ipotesi di omoschedasticit√†</i>.
</p>

<p>
Ovviamente, pur supponendo la validit√† di queste 3 ipotesi, ancora non conosciamo il <i>valore della varianza</i> che viene per ora
comunque <i>indicato come costante nota</i>.
</p>

<p>
Gli <i>stimatori puntuali</i> utilizzati per <i>stimare le costanti</i> sono le statistiche
</p>
<ul class="org-ul">
<li>\(A_0 = \bar{Y} - A_1 \cdot \bar{X}\);</li>
<li>\(A_1 = \frac{\sum_{i=1}^n (X_i - \bar{X})\cdot(Y_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2}\).</li>
</ul>
<p>
Dove \(\bar{X} = \frac{\sum_{i=1}^n X_i}{n}\) e \(\bar{Y} = \frac{\sum_{i=1}^n Y_i}{n}\).
</p>

<p>
√à possibile osservare che tali stimatori sono definiti analogamente alle costanti \(q\) ed \(m\) della <i>retta dei minimi quadrati</i>
\(Y = m \cdot X + q\) per <i>descrivere al meglio un legame lineare tra due caratteri</i> di una serie di dati.
</p>

<p>
In effetti, gli <i>stimatori \(A_0\) ed \(A_1\)</i> vengono determinati allo stesso modo, come <i>valori per cui risulta minima la quantit√†</i>
\(\sum_{i=1}^n [A_1 \cdot X_i + A_0 - Y_i]^2\).
</p>

<p>
Supposto quindi che \(\{(x_1, y_1), \dots, (x_n, y_n)\}\) sia una realizzazione del campione \(\{(X_1, Y_1), \dots, (X_n, Y_n)\}\), due stime puntuali
di \(\alpha_0\) e \(\alpha_1\) sono i valori:
</p>
<ul class="org-ul">
<li>\(a_0 = \bar{Y} - a_1 \cdot \bar{X}\);</li>
<li>\(a_1 = \frac{\sum_{i=1}^n (x_i - \bar{x})\cdot(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2}\).</li>
</ul>
<p>
Dove \(\bar{x} = \frac{\sum_{i=1}^n x_i}{n}\) e \(\bar{y} = \frac{\sum_{i=1}^n y_i}{n}\).
</p>

<p>
I due <i>stimatori \(A_0\) e \(A_1\)</i> proposti, sono tali che, <i>sotto le tre ipotesi specificate</i> precedentemente, essi <i>soddisfano le
seguenti propriet√†</i>:
</p>
<ul class="org-ul">
<li>\(E[A_0] = \alpha_0 \quad V[A_0] = \sigma^2 \cdot \left[\frac{1}{n} + \frac{x^{-2}}{\sum_{i=1}^n (x_i - \bar{x})^2}\right]\);</li>
<li>\(E[A_1] = \alpha_1 \quad V[A_1] = \sigma^2 \cdot \left[\frac{1}{\sum_{i=1}^n (x_i - \bar{x})^2}\right]\);</li>
</ul>
<p>
Da cui si deduce che \(A_0\) e \(A_1\) sono due <i>stimatori corretti</i> e pertanto adatti a fare inferenze sui coefficienti \(\alpha_0\) e \(\alpha_1\).
</p>

<p>
In particolare, se valgono le ipotesi
</p>
<ul class="org-ul">
<li>\(E[E_i] = 0 \quad \forall i = 1, \dots, N\);</li>
<li>\(V[E_i] = \sigma^2 \quad \forall i = 1, \dots, N\);</li>
<li>Le variabili \(E_i\) sono incorrelate tra loro.</li>
</ul>
<p>
si pu√≤ dire qualcosa di ancora pi√π forte, infatti in questo caso, <i>\(A_0\) ed \(A_1\)</i> sono, tra gli <i>stimatori</i> corretti per
\(\alpha_0\) e \(\alpha_1\), i <i>pi√π efficienti</i>, ovvero quelli cui corrisponde varianza minima.
</p>

<p>
Questa propriet√† √® solitamente riferita in letterature con il termine di <i>Teorema di Gauss-Markov</i>.
</p>

<p>
Dall'espressione delle varianze dei due stimatori si vede che esse dipendono non solo dalla numerosit√† \(n\) del campione,
ma anche dalla disposizione sull'asse delle \(x\) delle osservazioni \(x_i\).
</p>

<p>
Se la dispersione di tali osservazioni sull'asse √® piccola, allora la quantit√† \(\sum_{i=1}^n (x_i - \bar{x})^2\) risulta piccola e le
varianze diventano grandi. In questo caso allora cresce la probabilit√† che le stime \(a_0\) e \(a_1\) siano lontane dai valori reali
\(\alpha_0\) e \(\alpha_1\). Per questa ragione sarebbe preferibile avere campioni in cui siano presenti grandi scostamenti dei valori assunti
dal carattere \(X\).
</p>

<p>
Supponiamo di voler effettuare delle stime intervallari per le costanti \(\alpha_0\) e \(\alpha_1\). Occorre allora aggiungere una <i>nuova ipotesi
sui residui</i>. Tale ipotesi √® la seguente:
</p>
<ul class="org-ul">
<li>Le variabili \(E_i\) sono normalmente distribuite.</li>
</ul>
<p>
Notiamo che essa, aggiunga alle altre, equivale a dire che <i>ogni residuo √® normalmente distribuito con media nulla ed identica
varianza \(\sigma^2\)</i>.
</p>

<p>
Questa <i>non √® un'ipotesi molto restrittiva o irrealistica</i>, in effetti √® logico aspettarsi che gli <i>errori</i> siano <i>normalmente
distribuiti, in quanto somma di numerosi fattori casuali indipendenti</i>.
</p>

<p>
Si ricordi infatti che per il <i>Teorema Centrale Limite</i>, la <i>somma di numerosi fattori aleatori, tende a distribuirsi come una
normale</i>.
</p>

<p>
Si pu√≤ mostrare che condizionalmente alle 4 ipotesi:
</p>
<ul class="org-ul">
<li>\(E[E_i] = 0 \quad \forall i = 1, \dots, N\);</li>
<li>\(V[E_i] = \sigma^2 \quad \forall i = 1, \dots, N\);</li>
<li>Le variabili \(E_i\) sono incorrelate tra loro;</li>
<li>Le variabili \(E_i\) sono normalmente distribuite.</li>
</ul>
<p>
Anche gli <i>stimatori \(A_0\) ed \(A_1\) sono normalmente distribuiti</i>, con:
</p>
<ul class="org-ul">
<li>\(A_0 \cong N\left(\alpha_0, \sigma^2 \cdot \left[\frac{1}{n} + \frac{x^{-2}}{\sum_{i=1}^n (x_i - \bar{x})^2}\right]\right)\);</li>
<li>\(A_1 \cong N\left(\alpha_1, \sigma^2 \cdot \left[\frac{1}{\sum_{i=1}^n (x_i - \bar{x})^2}\right]\right)\);</li>
</ul>
<p>
La conoscenza della distribuzione dei due stimatori potrebbe essere utilizzata per determinare degli intervalli, come visto nel
Capitolo 5.
</p>

<p>
Notiamo per√≤ che il parametro \(\sigma^2\) che compare nelle formule precedenti non √® noto. Per ovviare a tale mancanza si sostituisce con
una stima data dalla realizzazione della statistica \(S_{\text{RES}} = \frac{1}{n-2} \cdot \sum_{i=1}^n (Y_i - \hat{Y}_i)^2\), dove le quantit√† \(\hat{Y}_i\)
sono i valori teorici che dovrebbero essere assunti dal carattere \(Y\) se si trovassero sulla retta di regressione stimata, ovvero
\(\hat{Y}_i = a_0 + a_1 \cdot X_i, \forall i = 1, \dots, n\).
</p>

<p>
Notiamo che la statistica \(S_{\text{RES}}^2\) non √® altro che una <i>varianza campionaria che descrive lo scostamento tra le osservazioni
\(y_i\) del carattere \(Y\) e le loro stime \(\hat{y}_i = a_0 + a_1 \cdot x_i\) ottenute tramite la regressione</i>.
</p>

<p>
Quindi essa √® proprio la <i>varianza campionaria dei residui</i> \(E_i = Y_i -(\alpha_0 + \alpha_1 \cdot X_i)\).
</p>

<p>
La presenza del termine \(\frac{1}{n-2}\) √® giustificata dal fatto che cos√¨ definito, lo stimatore \(S_{\text{RES}}^2\) di \(\sigma^2\) risulta
corretto, ovvero vale \(E[S_{\text{RES}}] = \sigma^2\).
</p>

<p>
Andiamo quindi a sostituire nelle
</p>
<ul class="org-ul">
<li>\(A_0 \cong N\left(\alpha_0, \sigma^2 \cdot \left[\frac{1}{n} + \frac{x^{-2}}{\sum_{i=1}^n (x_i - \bar{x})^2}\right]\right)\);</li>
<li>\(A_1 \cong N\left(\alpha_1, \sigma^2 \cdot \left[\frac{1}{\sum_{i=1}^n (x_i - \bar{x})^2}\right]\right)\);</li>
</ul>
<p>
a quantit√† \(\sigma^2\) con il suo stimatore \(S_{\text{RES}}^2\) e consideriamo le variabili:
</p>
<ul class="org-ul">
<li>\(T_0 = \frac{A_0 - \alpha_0}{\sqrt{S_{\text{RES}}^2 \cdot \left[\frac{1}{n} + \frac{\bar{X}^2}{\sum_{i=1}^n (X_i - \bar{X})^2}\right]}}\);</li>
<li>\(T_1 = \frac{A_1 - \alpha_1}{\sqrt{S_{\text{RES}}^2 \cdot \left[\frac{1}{\sum_{i=1}^n (X_i - \bar{X})^2}\right]}}\).</li>
</ul>
<p>
Condizionatamente alle consuete ipotesi:
</p>
<ul class="org-ul">
<li>\(E[E_i] = 0 \quad \forall i = 1, \dots, N\);</li>
<li>\(V[E_i] = \sigma^2 \quad \forall i = 1, \dots, N\);</li>
<li>Le variabili \(E_i\) sono incorrelate tra loro;</li>
<li>Le variabili \(E_i\) sono normalmente distribuite.</li>
</ul>
<p>
le variabili \(T_0\) e \(T_1\) risultano essere distribuite come delle t di Student con \(n-2\) gradi di libert√†.
</p>

<p>
Considerate allora le realizzazioni:
</p>
<ul class="org-ul">
<li>\(s_{\text{RES}}^2\);</li>
<li>\(a_0\);</li>
<li>\(a_1\);</li>
<li>\(x_i \quad i = 1, \dots, n\);</li>
<li>\(\bar{x}\).</li>
</ul>
<p>
Si ottengono gli intervalli di confidenza per \(\alpha_0\) e \(\alpha_1\) che per un fissato livello di confidenza \(\alpha\) risultano essere:
</p>
<ul class="org-ul">
<li>\(\left[a_0 - t_{1-\frac{\alpha}{2}} \cdot \sqrt{s_{\text{RES}}^2 \cdot \left[\frac{1}{n} + \frac{x^{-2}}{s_x^2}\right]},
  a_0 + t_{1-\frac{\alpha}{2}} \cdot \sqrt{s_{\text{RES}}^2 \cdot \left[\frac{1}{n} + \frac{x^{-2}}{s_x^2}\right]}\right]\);</li>
<li>\(\left[a_1 - t_{1-\frac{\alpha}{2}} \cdot \sqrt{s_{\text{RES}}^2 \cdot \frac{1}{s_x^2}},
  a_0 + t_{1-\frac{\alpha}{2}} \cdot \sqrt{s_{\text{RES}}^2 \cdot \frac{1}{s_x^2}}\right]\).</li>
</ul>
<p>
Dove \(s_x^2 = \sum_{i=1}^n (x_i - \bar{x})^2\), mentre \(t_{1 - \frac{\alpha}{2}}\) √® il quantile di ordine \(1 - \frac{\alpha}{2}\) della t di Student con
\(n-2\) gradi di libert√†.
</p>

<p>
Per quanto riguarda le stime del parametro \(\sigma^2\) abbiamo gi√† detto che uno stimatore corretto √® la variabile \(S_{\text{RES}}^2\).
</p>

<p>
Anche di questa variabile √® nota la distribuzione quando valgono le ipotesi:
</p>
<ul class="org-ul">
<li>\(E[E_i] = 0 \quad \forall i = 1, \dots, N\);</li>
<li>\(V[E_i] = \sigma^2 \quad \forall i = 1, \dots, N\);</li>
<li>Le variabili \(E_i\) sono incorrelate tra loro;</li>
<li>Le variabili \(E_i\) sono normalmente distribuite.</li>
</ul>
<p>
In questo caso, infatti, il rapporto \(\frac{(n-2) \cdot S_{\text{RES}}^2}{\sigma^2}\) risulta essere distribuito come una Chi-Quadro con \(n-2\)
gradi di libert√†.
</p>

<p>
Mediante i soliti ragionamenti si deduce allora che un intervallo di confidenza per \(\sigma^2\) con un livello di fiducia \(\alpha\) √®
\[\left[\frac{(n-2) \cdot s_{\text{RES}}^2}{q_{1 - \frac{\alpha}{2}}}, \frac{(n-2) \cdot s_{\text{RES}}^2}{q_{\frac{\alpha}{2}}}\right]\]
dove \(q_{\frac{\alpha}{2}}\) e \(q_{1-\frac{\alpha}{2}}\) sono i quantili della Chi-Quadro con \(n-2\) gradi di libert√†.
</p>
</div>
</div>
<div id="outline-container-orge5c4ebd" class="outline-4">
<h4 id="orge5c4ebd"><span class="section-number-4">2.8.2</span> Attendibilit√† del modello lineare</h4>
<div class="outline-text-4" id="text-2-8-2">
<p>
Abbiamo gi√† detto che <i>dopo aver stimato i parametri di un modello lineare occorre verificare l'attendibilit√† del modello stesso</i>,
ovvero verificare l'ipotesi che le relazioni tra i due caratteri siano esprimibili tramite l'equazione
\(Y_i = \alpha_0 + \alpha_1 \cdot X_i + E_i\).
</p>

<p>
Un primo criterio adottabile per procedere in queste verifiche consiste nell'effettuare uno dei <i>test di</i> ipotesi, descritti nei
Capitoli 6 e 7, relativi alla <i>incorrelazione lineare tra due caratteri di una popolazione</i>.
</p>

<p>
Se con l'uso di questi test si <i>dovesse rifiutare l'ipotesi di incorrelazione</i>, allora ha senso provare ad <i>effettuare test
pi√π approfonditi sulla validit√† del modello lineare</i>, <i>altrimenti</i> si dovrebbe passare a <i>considerare qualche altro modello</i>.
</p>

<p>
√à preferibile utilizzate il test basato sulla statistica \(\hat{T}_n = R_n \cdot \sqrt{\frac{n-2}{1 - R_n^2}}\) descritto nel paragrafo 6.7 se si
posseggono dei dati accurati.
</p>

<p>
Useremo invece il test basato sulla statistica \(\tilde{T}_n = R_S \cdot \sqrt{\frac{n-2}{1 - R_S^2}}\) descritto nel paragrafo 7.4 se non si posseggono
dei dati accurati.
</p>

<p>
Un test pi√π specifico per la regressione lineare √® basato su un approccio di <i>analisi della varianza</i> del carattere dipendente \(Y\).
</p>

<p>
Dato un campione \(\{(X_1, Y_1, \dots, (X_n, Y_n))\}\) estratto da \((X, Y)\), si considerino gli stimatori \(A_0\) ed \(A_1\) definiti in
precedenza, e quindi gli stimatori \(\hat{Y}_i = A_0 + A_1 \cdot X_i\).
</p>

<p>
Si considerino poi le seguenti statistiche:
</p>
<ul class="org-ul">
<li><p>
<i>Devianza Totale</i>: \(D_{\text{TOT}} = \sum_{i=1}^n (Y_i - \bar{Y})^2\).
</p>

<p>
Si riferisce agli scostamenti tra le osservazioni \(Y_i\) e la loro media campionaria \(\bar{Y}\);
</p></li>
<li><p>
<i>Devianza Spiegata</i>: \(D_{\text{SP}} = \sum_{i=1}^n (\hat{Y}_i - \bar{Y})^2\).
</p>

<p>
Si riferisce agli scostamenti tra le stime \(\hat{Y}_i\) e la \(\bar{Y}\).
</p></li>
<li><p>
<i>Devianza dei Residui</i>: \(D_{\text{RES}} = \sum_{i=1}^n (Y_i - \hat{Y}_i)^2\).
</p>

<p>
Si riferisce agli scostamenti tra le osservazioni \(Y_i\) e le loro stime \(\hat{Y}_i\).
</p></li>
</ul>

<p>
Queste tre quantit√† sono gli indici degli scostamenti tra le osservazioni campionarie del carattere \(Y\), la media di queste
osservazioni e le loro stime tramite la regressione.
</p>

<p>
Si pu√≤ dimostrare che tra le 3 devianze introdotte sussiste la seguente relazione: \(D_{\text{TOT}} = D_{\text{SP}} + D_{\text{RES}}\).
</p>

<p>
Possiamo allora affermare che le variazioni tra le osservazioni \(Y_i\) e la loro media \(\bar{Y}\) sono da attribuire in parte alle
<i>"variazioni spiegate"</i> dalla retta di regressione, ed in parte al fatto che le osservazioni non si trovano esattamente su tale
retta (cio√® ai residui).
</p>

<p>
In altri termini, possiamo dire che se non fosse per i residui, allora la regressione spiegherebbe lo scostamento totale tra le
osservazioni e la loro media.
</p>

<p>
√à logico pensare che il modello √® adatto a descrivere variazioni del carattere \(Y\) se queste sono causate principalmente dalla
regressione, ovvero se il rapporto \(R^2 = \frac{D_{\text{SP}}}{D_{\text{TOT}}} = 1 - \frac{D_{\text{RES}}}{D_{\text{TOT}}}\) √® prossimo a 1.
</p>

<p>
In effetti si pu√≤ verificare che \(R^2\) sia il quadrato del coefficiente di correlazione lineare \(r_{XY}\) introdotto nei capitolo
precedenti, cio√® vale \(\sqrt{R^2} = |r_{XY}|\).
</p>

<p>
Mentre per√≤ il coefficiente di correlazione lineare ha senso solo se si considera una regressione lineare semplice, il coefficiente
\(R^2\) presenta il vantaggio di essere utilizzabile come misura di adattamento qualunque sia la forma della curva di regressione e
qualunque sia il numero di variabili esplicative considerate. Per tale ragione √® chiamato <i>coefficiente di correlazione
generalizzato</i>.
</p>

<p>
Similmente a quanto sopra, possiamo pensare che il modello lineare √® adatto a descrivere le variazioni del carattere \(Y\) se la
quantit√† \(D_{\text{RES}}\) risulta essere molto inferiore alla \(D_{\text{SP}}\), ovvero se il rapporto \(\frac{D_{\text{SP}}}{D_{\text{RES}}}\) √® molto
grande.
</p>

<p>
Un test sull'attendibilit√† del modello lineare molto utilizzato si basa proprio su questo rapporto, e specificamente sul fatto
che la <i>statistica</i> \(\tilde{F} = (n-2) \cdot \frac{D_{\text{SP}}}{D_{\text{RES}}} = \frac{D_{\text{SP}}}{S_{\text{RES}}^2}\), con
\(S_{\text{RES}}^2 = \frac{1}{n-2} \cdot \sum_{i=1}^n (Y_i - \hat{Y}_i)^2\) √® distribuita come una F con \((1, n-2)\) gradi di libert√†, quando siano
soddisfatte le ipotesi:
</p>
<ul class="org-ul">
<li>\(E[E_i] = 0 \quad \forall i = 1, \dots, N\);</li>
<li>\(V[E_i] = \sigma^2 \quad \forall i = 1, \dots, N\);</li>
<li>Le variabili \(E_i\) sono incorrelate tra loro;</li>
<li>Le variabili \(E_i\) sono normalmente distribuite.</li>
</ul>
<p>
E quando valga \(\alpha_1 = 0\), ovvero non esiste dipendenza tra i valori assunti dal carattere \(X\) e quelli assunti dal carattere \(Y\).
</p>

<p>
√à possibile pertanto effettuare un <i>test per l'ipotesi nulla</i> \(H_0 : \alpha_1 = 0\) (regressione non significativa) <i>rifiutando</i>
quando la realizzazione della statistica \(\tilde{F} = (n-2) \cdot \frac{D_{\text{SP}}}{D_{\text{RES}}} = \frac{D_{\text{SP}}}{S_{\text{RES}}^2}\)
assume valori grandi, ovvero <i>nel caso di un test di ampiezza \(\alpha\), quando</i> \(\tilde{f} > F_{1-\alpha}\), dove \(F_{1-\alpha}\) √® il
<i>quantile di ordine</i> \(1-\alpha\) <i>della \(F(1, n-2)\)</i>.
</p>

<p>
Ci si ricordi per√≤ che prima di effettuare questo test, occorre verificare la sussistenza delle ipotesi:
</p>
<ul class="org-ul">
<li>\(E[E_i] = 0 \quad \forall i = 1, \dots, N\);</li>
<li>\(V[E_i] = \sigma^2 \quad \forall i = 1, \dots, N\);</li>
<li>Le variabili \(E_i\) sono incorrelate tra loro;</li>
<li>Le variabili \(E_i\) sono normalmente distribuite.</li>
</ul>
<p>
Sui residui, con i metodi presentati nel prossimo paragrafo.
</p>

<p>
Ricordiamo inoltre che, in generale, il nostro obiettivo √® rifiutare l'ipotesi nulla, vale a dire l'inconsistenza del modello di
regressione lineare.
</p>

<p>
Un secondo test che si pu√≤ adottare per verificare l'attendibilit√† del modello lineare si basa sul fatto che <i>assumere l'esistenza
di una relazione lineare tra i due caratteri \(X\) ed \(Y\) corrisponde ad assume</i> \(\alpha \neq 0\).
</p>

<p>
Se fosse infatti \(\alpha_1 = 0\), allora <i>le variazioni delle \(Y\) non dipenderebbero da quelle delle \(X\)</i>. Si pu√≤ quindi effettuare un
<i>test avente come ipotesi nulla</i> la \(H_0 : \alpha_1 = 0\) e come <i>ipotesi alternativa</i> \(H_1 : \alpha_1 \neq 0\).
</p>

<p>
In tal caso si utilizza il fatto che quando siano soddisfatte le seguenti ipotesi sui residui:
</p>
<ul class="org-ul">
<li>\(E[E_i] = 0 \quad \forall i = 1, \dots, N\);</li>
<li>\(V[E_i] = \sigma^2 \quad \forall i = 1, \dots, N\);</li>
<li>Le variabili \(E_i\) sono incorrelate tra loro;</li>
<li>Le variabili \(E_i\) sono normalmente distribuite.</li>
</ul>
<p>
La variabile \(T_1\), definita come \(T_1 = \frac{A_1 - \alpha_1}{\sqrt{S_{\text{RES}}^2 \cdot \left[\frac{1}{\sum_{i=1}^n (X_i - \bar{X})^2}\right]}}\)
√® distribuita come una t di Student con \(n-2\) gradi di libert√†.
</p>

<p>
<i>Rifiuteremo l'ipotesi nulla</i> quando la sua realizzazione \(\tilde{t}\) assume valori troppo distanti dallo zero/ per poter pensare
che essa sia distribuita secondo una t di Student con \(n-2\) gradi di libert√†.
</p>

<p>
Ad esempio, per un <i>test di ampiezza \(\alpha\), rifiutiamo \(H_0\) quando</i> \(|\tilde{t}| > t_{1-\frac{\alpha}{2}}\), dove \(t_{1-\frac{\alpha}{2}}\) √® il quantile di
ordine \(1 - \frac{\alpha}{2}\) di una t di Student con \(n-2\) gradi di libert√†/.
</p>

<p>
Ricordiamo che anche con questo test la nostra speranza √® di rifiutare l'ipotesi nulla, ovvero la non dipendenza di \(Y\) da \(X\).
</p>

<p>
Relativamente ai due test di ipotesi appena presentati, occorre fare una breve considerazione. Dalla definizione delle
distribuzioni t di Student ed F si pu√≤ notare che se una variabile aleatoria \(Z\) ha distribuzione \(t_{n-2}\), allora il suo
quadrato \(Z^2\) ha distribuzione \(F(1, n-2)\).
</p>

<p>
In effetti, nel caso di regressione lineare semplice per le variabili \(\tilde{T}\) ed \(\tilde{F}\) sopra definite, vale la relazione:
</p>
<ul class="org-ul">
<li>\(\tilde{T} = \frac{A_1}{\sqrt{S_{\text{RES}}^2 \cdot \left[\frac{1}{\sum_{i=1}^n (X_i - \bar{X})^2}\right]}}\);</li>
<li>\(\tilde{T}^2 = \tilde{F}\);</li>
<li>\(\tilde{F} = (n-2) \cdot \frac{D_{\text{SP}}}{D_{\text{RES}}} = \frac{D_{\text{SP}}}{S_{\text{RES}}^2}\).</li>
</ul>
<p>
Che per brevit√† non dimostreremo.
</p>

<p>
Se ne deduce facilmente che i due test appena proposti sono equivalenti.
</p>

<p>
Li abbiamo comunque presentati separatamente perch√© tale equivalenza non sussiste pi√π nel caso di regressione lineare multipla
e nel caso di regressione non-lineare.
</p>
</div>
</div>
<div id="outline-container-orgb99c715" class="outline-4">
<h4 id="orgb99c715"><span class="section-number-4">2.8.3</span> Analisi dei residui</h4>
<div class="outline-text-4" id="text-2-8-3">
<p>
Nei paragrafi precedenti abbiamo definito i <i>residui</i> \(E_i = \hat{Y}_i - Y_i\) ed \(\hat{Y}_i = A_0 + A_1 \cdot X_i\) come differenze,
per ogni individuo, tra i valori assunti dal carattere \(Y\) e le sue stime secondo la regressione.
</p>

<p>
Abbiamo inoltre fatto diverse <i>ipotesi su tali residui</i>, che essi:
</p>
<ul class="org-ul">
<li>Abbiano media nulla;</li>
<li>Siano incorrelati;</li>
<li>Abbiano identica varianza;</li>
<li>Siano normalmente distribuiti.</li>
</ul>
<p>
In un'analisi di regressione √® opportuno pertanto <i>controllare la validit√† di tali ipotesi</i>.
</p>

<p>
Nei test si fa uso del livello di significativit√†, il quale implicitamente definisce la regione critica: se il valore della
statistica calcolato dai dati campionari cade nella regione critica, si rifiuta l'ipotesi.
</p>

<p>
Non si sa per√≤, se si modificasse la significativit√†, se l'ipotesi continuerebbe ad esser rifiutata o no, salvo ricalcolare la
regione: non si sa cio√® se il valore ottenuto sia significativamente o solo marginalmente interno alla regione critica predefinita.
</p>

<p>
Un modo alternativo e pi√π informativo √® quello di usare il \(p-\text{value}\).
</p>

<p>
Sia \(t^*\) il valore assunto dalla statistica sui dati campionari e si considerino le regioni critiche a seconda dell'ipotesi
alternativa:
</p>
<ul class="org-ul">
<li>Test bidirezionale: \(H_1' : \mu \neq \mu_0\);</li>
<li>Test unidirezionale con coda a sinistra: \(H_1'' : \mu < \mu_0\);</li>
<li>Test unidirezionale con coda a destra: \(H_1''' : \mu > \mu_0\)</li>
<li>\(C' = \left(-\infty, -t_{1-\frac{\alpha}{2}}^* \right) \cup \left(\mu_0 +t_{1-\frac{\alpha}{2}}^*, +\infty\right)\)
se \(H_1'\) √® l'ipotesi alternativa;</li>
<li>\(C'' = \left(-\infty, -t_{1-\alpha}^*\right)\) se \(H_1''\) √® l'ipotesi alternativa;</li>
<li>\(C''' = \left(t_{1-\alpha}^*, +\infty\right)\) se \(H_1'''\) √® l'ipotesi alternativa.</li>
</ul>
<p>
Il \(p-\text{value}\) √® definito come la <i>probabilit√† che la statistica valida sotto l'ipotesi nulla assuma valore nella regione critica
cos√¨ definita</i>.
</p>

<p>
Il \(p-\text{value}\) <i>misura</i> quindi la "<i>verosimiglianza</i>" (o l'"inverosimiglianza") <i>del valore campionario ottenuto, dalla distribuzione
della statistica sotto l'ipotesi nulla</i>.
</p>

<p>
Allora √® chiaro che, quanto pi√π piccolo √® il \(p-\text{value}\), tanto pi√π "inverosimile" √® che il risultato campionario della statistica
provenga dalla distribuzione della statistica valida sotto l'ipotesi nulla: quindi con tanta maggior sicurezza si rifiuta l'ipotesi
nulla in favore dell'ipotesi alternativa.
</p>

<p>
Invece, quanto pi√π grande √® il \(p-\text{value}\), tanto pi√π "verosimile" √® che si verifichi quel tal risultato campionario della
statistica, sotto l'ipotesi nulla: quindi con tanta maggior sicurezza si esclude che l'evidenza ottenuta contrasti con
l'ipotesi nulla.
</p>

<p>
Come esempio, consideriamo un <i>test t sulla media nell'ipotesi di popolazione normale</i>:
</p>
<ul class="org-ul">
<li>\(H_0 : \mu = 0\);</li>
<li>\(H_1' : \mu \neq 0\);</li>
<li>\(\alpha = 0.05\).</li>
</ul>
<p>
Un risultato del test t* che porta a \(p-\text{value} = 0.0001 \implies P(t < |t^*|) = 0.0001\) dice che c'√® una probabilit√† molto piccola che sotto l'ipotesi nulla
possa verificarsi una realizzazione della statistica di test con un valore assoluto maggiore di quello che si √® realizzato nel nostro
campione, per cui vi √® evidenza che l'ipotesi nulla √® falsa, e pertanto si accetta l'ipotesi alternativa.
</p>

<p>
Se invece \(H_1'' : \mu < \mu_0\), con ragionamenti analoghi si ha che (\(\alpha = 0.05\)):
</p>
<ul class="org-ul">
<li>\(p-\text{value} = 0.4 \implies P(t < |t^*|) = 0.4 \implies \text{non rifiuto } H_0\);</li>
<li>\(p-\text{value} = 0.0001 \implies P(t < |t^*|) = 0.0001 \implies \text{rifiuto } H_0\);</li>
</ul>
<p>
Analogamente, se invece \(H_1'' : \mu > \mu_0\), con ragionamenti analoghi si ha che (\(\alpha = 0.05\)):
</p>
<ul class="org-ul">
<li>\(p-\text{value} = 0.4 \implies P(t < |t^*|) = 0.4 \implies \text{non rifiuto } H_0\);</li>
<li>\(p-\text{value} = 0.0001 \implies P(t < |t^*|) = 0.0001 \implies \text{rifiuto } H_0\);</li>
</ul>
<p>
Relativamente all'<i>ipotesi di incorrelazione</i> tra i residui, il metodo pi√π utilizzato √® il <i>Test di Durbin-Watson</i>. In esso viene
considerata la statistica
\[D = \frac{\sum_{i=2}^n (E_i - E_{i-1})^2}{\sum_{i=1}^n E_i^2}\]
dove \(E_i\) √® l'\(i\)-esimo residuo.
</p>

<p>
Sotto l'ipotesi di incorrelazione, tale statistica ha una particolare distribuzione, le cui tavole si trovano in numerosi testi
introduttivi all'analisi di regressione.
</p>

<p>
√à possibile quindi determinare delle regioni critiche per \(D\) e rifiutare l'ipotesi di incorrelazione se la realizzazione di \(D\)
dovesse cadere in tali regioni.
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-09_15-11-12.png" alt="screenshot_2018-06-09_15-11-12.png" />
</p>
</div>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-09_15-11-28.png" alt="screenshot_2018-06-09_15-11-28.png" />
</p>
</div>

<p>
Mostriamo come sia possibile controllare l'<i>ipotesi di normalit√†</i>. In proposito si possono adottare diverse tecniche pi√π o meno
valide. A nostro giudizio la tecnica numerica pi√π valida √® quella che fa ricorso ai <i>test per la bont√† dell'adattamento</i>
denominati test:
</p>
<ul class="org-ul">
<li>Di <i>Kolmogorov-Smirnov</i>:
<ul class="org-ul">
<li>√à basato sulla differenza tra ripartizione empirica e ripartizione della normale: \(K_n = \text{sup}_x |F_e(x) - F_n(x)|\sqrt{n}\).</li>
<li>Si rifiuta l'ipotesi di normalit√† se \(K_n\) √® grande;</li>
<li>Richiede campioni di elevata numerosit√†.</li>
</ul></li>
<li>Del <i>Chi-Quadro</i>;</li>
<li>Di <i>Shapiro Wilk</i>:
<ul class="org-ul">
<li>Serve per campioni di bassa numerosit√†;</li>
<li>La statistica \(W\) misura la rettilineit√† del normal plot: \(W = \frac{\left[\sum_1^n w_i e_i'\right]^2}{\sum_i^n (e_i - \bar{e})^2}\), dove
i \(w_i\) sono quantit√† tabulate, \(e_i\) i valori campionari ed \(e_i'\) i valori ordinati;</li>
<li>Si rifiuta se \(W\) √® piccolo.</li>
</ul></li>
</ul>
<p>
In tutti i casi si controlla l'ipotesi che i <i>residui campionari</i> \(e_1, \dots, e_n\) ottenuti dalle osservazioni del campione
\(\{(X_1, Y_1), \dots, (X_n, Y_n)\}\) siano <i>distribuiti normalmente con media nulla e varianza</i> \(s_{\text{RES}}^2\), ricordando:
\(S_{\text{res}}^2 = \frac{1}{n-2} \cdot \sum_{i=1}^n (Y_i - \hat{Y}_i)^2\).
</p>

<p>
Un'alternativa √® il <i>Normal Quantile plot</i>. In ascissa la cumulata di una normale. In ordinata la cumulata dei dati. I punti
del grafico devono essere allineati se provengono da una distribuzione normale (o comunque cadere entro le curve in rosso,
regione di confidenza a \((1-\alpha)\)).
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-09_15-27-30.png" alt="screenshot_2018-06-09_15-27-30.png" />
</p>
</div>

<p>
Normal Quantile plot - Non-normalit√†:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-09_15-27-57.png" alt="screenshot_2018-06-09_15-27-57.png" />
</p>
</div>

<p>
Le maggiori difficolt√† si incontrano nella <i>verifica di omoschedasticit√†</i>, ovvero di identica varianza per ogni residuo. Test
veramente significativi per tale ipotesi possono essere realizzati se il numero di valori assumibili dal carattere \(X\)
√® limitato e se per ognuno di tali valori esistono numerose osservazioni. Questa situazione purtroppo si presenta raramente
nelle applicazioni e si √® costretti a ricorrere a metodi grafici.
</p>

<p>
Tra questi, comunque non sempre disprezzabili, segnaliamo quello basato sulla rappresentazione dei residui in funzione dei valori
assunti dalla variabile \(X\) o \(Y\). Per ogni elemento del campione si individui il corrispondente punto su un piano cartesiano
avente i valori del carattere \(X\) (o \(Y\)) su un asse, ed i valori del residuo sull'altro.
</p>

<p>
<i>Accettiamo l'ipotesi di omoschedasticit√†</i> se i punti cos√¨ individuati si presentano a forma di una nuvola, come riportato sotto:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-09_15-31-54.png" alt="screenshot_2018-06-09_15-31-54.png" />
</p>
</div>

<p>
Rifiutiamo invece l'ipotesi se i punti assumono un andamento pi√π regolare come mostrato sotto:
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-09_15-32-23.png" alt="screenshot_2018-06-09_15-32-23.png" />
</p>
</div>

<p>
In questo caso √® lecito pensare che la varianza del residuo aumenti all'aumentare del valore assunto dal carattere \(X\).
</p>

<p>
Un altro caso di varianza non costante (dipendente da \(y\)):
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-09_15-33-14.png" alt="screenshot_2018-06-09_15-33-14.png" />
</p>
</div>

<p>
Uno dei problemi che si presentano nella pratica √® la presenza di <i>osservazioni anomale</i> (dovute, ad esempio, a errori di misura).
Questi valori anomali, detti <i>outliers</i>, possono <i>provocare un peggioramento nella qualit√† della regressione</i>, in quanto i valori
dei <i>parametri stimati vengono distorti per tenere conto anche di questi valori errati</i>.
</p>

<p>
Per riconoscere i possibili outliers ed eliminarli dal calcolo, un modo √® quello di calcolare i <i>Residui Studentizzati</i>:
\[r_i = \frac{e_i}{\sqrt{\text{MSE} \left(1 - \frac{1}{n} + \frac{(x_i - \bar{x})^2}{\sum (x_i - \bar{x})^2}\right)}}\]
con \(e_i\) l'\(i\)-esimo residuo, \(\text{SSE}\) somma quadratica dei residui e \(\text{MSE}\) scarto quadratico medio dei residui
\(text{MSE} =\frac{\sum e_i^2}{n-2}\).
</p>

<p>
Si dimostra che essi sono distribuiti secondo una t di Student. Se il residuo studentizzato di un'osservazione supera un valore di
4-5, allora l'osservazione √® un candidato outlier.
</p>


<div class="figure">
<p><img src="Lezioni/screenshot_2018-06-09_15-40-04.png" alt="screenshot_2018-06-09_15-40-04.png" />
</p>
</div>

<p>
Non tutti gli outliers hanno per√≤ un ugual effetto di modifica dei parametri della regressione: per riconoscere quelli che la
influenzano effettivamente, si usa una misura detta <i>D-Cook</i>, che indica il cambio di pendenza se si omette un'osservazione.
</p>

<p>
Un sospetto outlier √® influente se \(D > 1\).
</p>

<p>
Concludiamo osservando che in questo paragrafo e nel paragrafo precedente abbiamo visto come controllare le ipotesi sui residui e
l'attendibilit√† del modello di regressione lineare.
</p>

<p>
Ma cosa possiamo fare se le ipotesi vengono rifiutate o se il modello risulta inadeguato?
</p>

<p>
Tra i diversi tentativi che possono essere fatti suggeriamo di passare a considerare un modello di regressione multipla o non
lineare, oppure di cercare di trasformare opportunamente le variabili del modello in modo da rendere lineari enventuali
relazioni non lineari cos√¨ come mostrato al termine del capitolo 1.
</p>
</div>
</div>
<div id="outline-container-org7c4e26a" class="outline-4">
<h4 id="org7c4e26a"><span class="section-number-4">2.8.4</span> Regressione lineare multipla</h4>
<div class="outline-text-4" id="text-2-8-4">
<p>
Vediamo ora come le stime ed i test descritti per la regressione lineare semplice si generalizzano al caso di <i>regressione
lineare multipla</i>. Torniamo quindi a considerare una popolazione \((m+1)\) dimensionale \((X_1, \dots, X_m, Y)\) ed un'<i>equazione di
regressione</i> del tipo \(Y_i = \alpha_0 + \alpha_i \cdot X_{1, i} + \dots + \alpha_m \cdot X_{m, i} + E_i\), dove l'indice \(i\) varia tra 1 ed \(N\), numero totale degli
individui della popolazione. Come vedremo, dal punto di vista teorico non vi sono grandi differenze rispetto al modello
di regressione semplice, eccetto per alcuni indici di correlazione e per il <i>problema di multicollinearit√†</i>.
</p>
</div>
<ol class="org-ol">
<li><a id="org54c2350"></a>Stima dei Parametri del Modello<br />
<div class="outline-text-5" id="text-2-8-4-1">
<p>
Come nel caso della regressione lineare semplice, la prima cosa che potremmo essere intenzionati a determinare √® una
<i>stima delle costanti e della varianza dei residui</i>. Occorre sottolineare che anche per la regressione lineare multipla,
la determinazione di tale <i>stima</i> √® <i>realizzabile solo condizionatamente alla validit√† delle ipotesi</i>:
</p>
<ul class="org-ul">
<li>\(E[E_i] = 0 \quad \forall i = 1, \dots, N\);</li>
<li>\(V[E_i] = \sigma^2 \quad \forall i = 1, \dots, N\);</li>
<li>Le variabili \(E_i\) sono incorrelate tra loro.</li>
</ul>
<p>
Supponiamo pertanto di poter affermare che tali ipotesi sono soddisfatte e supponiamo di poter disporre di un campione
\((X_{1,1}, \dots, X_{m,1}, Y_i), \dots, (X_{1,n}, \dots, X_{m,n}, Y_n)\) di numerosit√† \(n > m\)  estratto dalla popolazione \((X_1, \dots, X_m, Y)\).
Qui \(X_{k,i}\) denota il carattere \(k\)-mo dell'individuo \(i\)-mo con \(k = 1, \dots, m\) e \(i = 1, \dots, n\)
</p>

<p>
Si pu√≤ pervenire alla determinazione delle <i>stime delle costanti del modello</i> ragionando esattamente come nel caso semplice,
ovvero <i>rendendo minima la somma dei quadrati o dei residui</i>
\[\sum_{i=1}^n E_i^2 = \sum_{i=1}^n (Y_i - \hat{Y}_i)^2 = \sum_{i=1}^n (Y_i -(\alpha_0 + \alpha_1 \cdot X_{1,i} + \dots + \alpha_m \cdot X_{m,i}))^2\]
Si ottengono cos√¨ le stime delle costanti per la cui descrizione conviene introdurre una notazione matriciale. A tal fine sia:
</p>
\begin{equation*}
X =
\begin{bmatrix}
&1 &X_{1,1} &\dots &X_{m,1}\\
&\vdots &\vdots &\ddots &\vdots\\
&1 &X_{1,n} &\dots &X_{m,n}
\end{bmatrix}
\end{equation*}
<p>
la matrice contenente le \(m\) <i>variabili esplicative</i> degli \(n\) individui del campione (aggiunta della prima colonna contenente
solo l'unit√†).
</p>

<p>
Siano poi \(Y = (Y_1, \dots, Y_n)^T\) il vettore con i caratteri \(Y\) degli individui del campione e \(A = (A_0, \dots, A_m)^T\) il vettore colonna
contenente gli stimatori di \(\alpha_0, \dots, \alpha_m\).
</p>

<p>
Denotiamo infine con \(M^T\) la trasposta di una matrice o un vettore \(M\) e con \(M^{-1}\) la matrice inversa di una matrice \(M\)
<i>quadrata e non singolare</i>.
</p>

<p>
Il <i>modello regressivo</i> pu√≤ allora essere riscritto in forma vettoriale come \(Y = XA + E\).
</p>

<p>
Si dimostra che se sono valide le ipotesi:
</p>
<ul class="org-ul">
<li>\(E[E_i] = 0 \quad \forall i = 1, \dots, N\);</li>
<li>\(V[E_i] = \sigma^2 \quad \forall i = 1, \dots, N\);</li>
<li>Le variabili \(E_i\) sono incorrelate tra loro.</li>
</ul>
<p>
Relative ai residui, allora gli <i>stimatori corretti di varianza minima di</i> \(\alpha_0, \dots, \alpha_m\) <i>sono</i> dati da \(A = (X^T \cdot X)^{-1} \cdot X^T \cdot Y\).
</p>

<p>
Si dimostra poi che uno <i>stimatore corretto della varianza dei residui √®</i>
\(S_{\text{RES}}^2 = \frac{q}{n-m-1}\cdot \sum_{i=1}^n E_i^2 = \frac{1}{n-2} \cdot \sum_{i=1}^n (Y_i - \hat{Y}_i)^2\)  
</p>

<p>
In conclusione possiamo dire che se \((x_{1, 1}, \dots, x_{m, 1}, y_1), \dots, (x_{1, n}, \dots, x_{m, n}, y_n)\) √® una realizzazione del campione
\((X_{1, 1}, \dots, X_{m, 1}, Y_1), \dots, (X_{1, n}, \dots, X_{m, n}, Y_n)\), allora una stima del vettore dei coefficienti \((\alpha_0, \dots, \alpha_m)^T\) √® data dal vettore
\(a = (a_0, \dots, a_m)^T\) ottenuto come \(a = (x^T \cdot x)^{-1} \cdot x^T \cdot y\).
</p>

<p>
Una <i>stima della varianza</i> √® invece data da: \(s_{\text{RES}}^2 = \frac{1}{n-m-1} \cdot \sum_{i=1}^n e_i^2\), dove gli \(e_i\) sono le realizzazioni
dei residui \(E_i\), ovvero: \(e_i = y_i - \hat{y}_i = y_i - (a_0 + a_1 \cdot x_{1, i} + \dots, a_m \cdot x_{m, i})\)
</p>

<p>
Nel caso in cui risulti valida anche l'ipotesi di normalit√†, sar√† possibile computare anche gli intervalli di confidenza per le
stime dei parametri in modo del tutto analogo a quanto fatto nel caso della regressione lineare semplice.
</p>

<p>
Si denoti con \(C_{k, k}\) la \(k\)-ma componente della diagonale principale della matrice \((X^T \cdot X)^{-1}\).
</p>

<p>
Gli intervalli di confidenza per le costanti si ottengono tenendo conto del fatto che, quando sono soddisfatte le ipotesi sui
residui, allora le variabili \(T_k = \frac{A_k - \alpha_k}{\sqrt{S_{\text{RES}} \cdot C_{k, k}}}\) sono distribuite secondo delle t di Student con
\((n-m-1)\) gradi di libert√†.
</p>

<p>
I consueti ragionamenti portano a questo punto a determinare gli intervalli di confidenza per qualsiasi livello di fiducia.
</p>
</div>
</li>
<li><a id="orga94ae5d"></a>Attendibilit√† del Modello<br />
<div class="outline-text-5" id="text-2-8-4-2">
<p>
Abbiamo gi√† accennato al fatto che passando a considerare la regressione lineare multipla, alcune quantit√† utilizzabili per valutare
la bont√† dell'adattamento di un modello di regressione lineare semplice perdono di significato.
</p>

<p>
√à questo il caso, ad esempio, del <i>coefficiente di correlazione lineare</i> \(r_{XY}\).
</p>

<p>
Altre quantit√† continuano per√≤ ad essere significative. Tra di esse, in particolare ricordiamo il <i>coefficiente di correlazione
generalizzato</i> definito come \(R^2 = 1 - \frac{D_{\text{RES}}}{D_{\text{TOT}}}\).
</p>

<p>
Il modello di regressione \(Y_i = \alpha_0 + \alpha_1 \cdot X_{i,i} + \dots + \alpha_m \cdot X_{m,i} + E_i\), le cui costanti vengono stimate come mostrato in precedenza,
dovr√† essere considerato tanto pi√π attendibile quanto pi√π \(R^2\) si avvicina ad 1, ed essere considerato inattendibile quando esso
√® prossimo allo 0.
</p>

<p>
Un vero e proprio test si pu√≤ effettuare quando siano verificate tutte le ipotesi sui residui:
</p>
<ul class="org-ul">
<li>\(E[E_i] = 0 \quad \forall i = 1, \dots, N\);</li>
<li>\(V[E_i] = \sigma^2 \quad \forall i = 1, \dots, N\);</li>
<li>Le variabili \(E_i\) sono incorrelate tra loro;</li>
<li>Le variabili \(E_i\) sono normalmente distribuite.</li>
</ul>
<p>
In questo caso, si pu√≤ far ricorso alla statistica \(\tilde{F} = \frac{D_{\text{SP}}}{S_{\text{RES}}^2} = (n-m-1) \cdot \frac{D_{\text{SP}}}{D_{\text{RES}}}\),
che risulta essere distribuita secondo una F con \((m, n-m-1)\) gradi di libert√† quando non esiste dipendenza tra il carattere
risposta \(Y\) ed i caratteri esplicativi \(X_k\), ovvero quando \(\alpha_1 = \dots = \alpha_m = 0\).
</p>

<p>
Rifiuteremo allora l'ipotesi nulla \(H_0 : \alpha_1 = \dots = \alpha_m = 0\) quando la realizzazione \(\tilde{f}\) della statistica \(\tilde{F}\) assume valori
grandi.
</p>

<p>
In particolare, rifiuteremo l'ipotesi nulla (per un test di ampiezza \(\alpha\)), quando \(\tilde{f} > F_{1-\alpha}\) rappresenta il quantile di ordine
\((1-\alpha)\) della \(F(m, n-m-1)\). Per quanto riguarda le ipotesi sui residui, continuano a valere le considerazioni espresse
relativamente alla regressione lineare semplice.
</p>
</div>
</li>
<li><a id="org3ffb4d4"></a>Sull'importanza delle Singole Variabili Esplicative<br />
<div class="outline-text-5" id="text-2-8-4-3">
<p>
Non tutte le variabili \(X_k\) che compaiono nel modello di regressione lineare multipla \(Y_i = \alpha_0 + \alpha_1 \cdot X_{1,i} + \dots + \alpha_m \cdot X_{m,i} + E_i\)
possono essere realmente esplicative, nel senso che non necessariamente tutte contribuiscono a "spiegare" i valori assunti dal
carattere dipendente \(Y\).
</p>

<p>
Potrebbe infatti essere \(\alpha_k = 0\) per qualche \(k = 1, \dots, m\).
</p>

<p>
Pu√≤ essere utile venire a conoscenza di tale fatto, onde evitare in futuro di rilevare i valori assunti da \(X_k\) per determinare
delle stime di \(Y\).
</p>

<p>
Occorre allora poter effettuare dei test specifici per accertare l'eventuale indipendenza tra una singola variabile esplicativa
\(X_k\) e la variabile dipendente \(Y\).
</p>

<p>
Per questo si ricorre al fatto gi√† citato che le variabili \(T_k = \frac{A_k - \alpha_k}{\sqrt{S_{\text{RES}}^2 \cdot C_{k,k}}}\) hanno distribuzione
nota quando valgono le ipotesi:
</p>
<ul class="org-ul">
<li>\(E[E_i] = 0 \forall \quad i = 1, \dots, N\);</li>
<li>\(V[E_i] = \sigma^2 \quad \forall i = 1, \dots, N\);</li>
<li>Le variabili \(E_i\) sono incorrelate tra loro;</li>
<li>Le variabili \(E_i\) sono normalmente distribuite.</li>
</ul>

<p>
In particolare, se vale anche l'ipotesi nulla \(H_0 : \alpha_k = 0\), avremo che la statistica \(\tilde{T}_k = \frac{A_k}{\sqrt{S_{\text{RES}}^2 \cdot C_{k,k}}}\)
sar√† distribuita come una t di Student con \(n-m-1\) gradi di libert√†.
</p>

<p>
Rifiuteremo pertanto l'ipotesi nulla \(H_0 : \alpha_k = 0\) qualora la realizzazione \(\tilde{t}_k\) di \(\tilde{T}_k\) assuma valori troppo distanti
dallo 0 per poter pensare che essa abbia distribuzione t di Student con \(n-m-1\) gradi di libert√†.
</p>

<p>
Per esempio, per un test di ampiezza \(\alpha\), rifiutiamo \(H_0\) quando \(|\tilde{t}_k| > t_{1-\frac{\alpha}{2}}\), dove \(t_{1-\frac{\alpha}{2}}\) rappresenta il
quantile di ordine \(1-\frac{\alpha}{2}\) per una t di Student con \(n-m-1\) gradi di libert√†.
</p>
</div>
</li>
<li><a id="org1a0547d"></a>Il Problema della Multicollinearit√†<br />
<div class="outline-text-5" id="text-2-8-4-4">
<p>
Il problema della <i>multicollinearit√†</i> non esiste nella regressione lineare semplice. Notiamo che per determinare il vettore delle
stime \(a = (a_0, \dots, a_m)^T\) √® necessario calcolare la matrice inversa di \((x^T \cdot x)\) e per questo occorre che tale prodotto matriciale
sia non singolare, ovvero con determinante non nullo. Ci√≤ avviene se nessuna delle variabili \(X_k\) √® combinazione lineare delle altre.
</p>

<p>
Nella scelta delle variabili esplicative occorre quindi essere certi che non si verifichi tale fenomeno detto di multicollinearit√†.
</p>

<p>
In realt√† si presentano dei problemi non solo se una delle \(X_k\) √® combinazione lineare delle altre, ma anche se ci si trova di fronte
a forti dipendenze lineari tra le variabili esplicative.
</p>

<p>
In questi casi occorre quindi eliminare dal modello una o pi√π di esse.
</p>

<p>
Come valutare se esiste un problema di multicollinearit√†?
</p>

<p>
Diverse misure sono state proposte in letteratura a tale scopo, ma non le descriviamo qui.
</p>

<p>
Una cosa che comunque si pu√≤ fare senza troppe difficolt√† √® considerare la matrice di correlazione delle variabili
esplicative (ovvero la matrice le cui componenti sono i coefficienti di correlazione lineare di tutte le coppie di variabili
esplicative).
</p>

<p>
Una forte correlazione tra due variabili esplicative √® condizione sufficiente per affermare che esiste un fenomeno di
multicollinearit√†. Conviene in questo caso eliminare una delle due variabili dal modello.
</p>
</div>
</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-orgd9ee9de" class="outline-2">
<h2 id="orgd9ee9de"><span class="section-number-2">3</span> Laboratorio</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="outline-container-org6ab4fce" class="outline-3">
<h3 id="org6ab4fce"><span class="section-number-3">3.1</span> Libri</h3>
<div class="outline-text-3" id="text-3-1">
<p>
Help:
</p>
<div class="org-src-container">
<pre class="src src-R">help(solve)
</pre>
</div>
<div class="org-src-container">
<pre class="src src-R">?solve
</pre>
</div>
<div class="org-src-container">
<pre class="src src-R">help.start()
</pre>
</div>
<div class="org-src-container">
<pre class="src src-R">??solve
</pre>
</div>

<p>
Source:
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #558b2f;">source</span>(<span style="color: #689f38;">"commands.R"</span>)
</pre>
</div>

<p>
Basics:
</p>
<div class="org-src-container">
<pre class="src src-R">ls()

rm(x, y)

rm(list = ls())
</pre>
</div>

<p>
Vectors
</p>
<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(2, 5, 4)
y <span style="color: #558b2f;">&lt;-</span> c(x, 3)

y
</pre>
</div>

<pre class="example">
[1] 2 5 4 3

</pre>

<p>
Vector arithmetic
</p>
<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(1, 2, 3, 4)
y <span style="color: #558b2f;">&lt;-</span> 4

v <span style="color: #558b2f;">&lt;-</span> 2*x + y + 1

v
</pre>
</div>

<pre class="example">
[1]  7  9 11 13

</pre>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(1, 4, 6, 6)

max <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"max:"</span>, max(x))
min <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"min:"</span>, min(x))
length <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"length:"</span>, length(x))
mean <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"mean:"</span>, mean(x))
variance <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"variance:"</span>, var(x))
sum <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"sum:"</span>, sum(x))
product <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"product:"</span>, prod(x))

results <span style="color: #558b2f;">&lt;-</span> c(max, min, length, mean, variance, sum, product)
sorted_results <span style="color: #558b2f;">&lt;-</span> sort(results)

visual <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"Results:"</span>, results, <span style="color: #689f38;">"Sorted results:"</span>, sorted_results)
visual
</pre>
</div>

<pre class="example">
 [1] "Results:"         "max:"             "6"                "min:"            
 [5] "1"                "length:"          "4"                "mean:"           
 [9] "4.25"             "variance:"        "5.58333333333333" "sum:"            
[13] "17"               "product:"         "144"              "Sorted results:" 
[17] "1"                "144"              "17"               "4"               
[21] "4.25"             "5.58333333333333" "6"                "length:"         
[25] "max:"             "mean:"            "min:"             "product:"        
[29] "sum:"             "variance:"       

</pre>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(3, 6, -4, 5)
y <span style="color: #558b2f;">&lt;-</span> c(1, 4, 5, 0)

pmax <span style="color: #558b2f;">&lt;-</span> pmax(x, y)
pmin <span style="color: #558b2f;">&lt;-</span> pmin(x, y)

res <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"pmax"</span>, pmax, <span style="color: #689f38;">"pmin"</span>, pmin)
res
</pre>
</div>

<pre class="example">
[1] "pmax" "3"    "6"    "5"    "5"    "pmin" "1"    "4"    "-4"   "0"   

</pre>

<div class="org-src-container">
<pre class="src src-R">sqrt(-17+0i)
</pre>
</div>

<pre class="example">
[1] 0+4.123106i

</pre>

<p>
Generating regular sequences:
</p>
<div class="org-src-container">
<pre class="src src-R">seq(1, 5)
seq(from=1, to=5)
seq(to=5, from=1)
</pre>
</div>

<pre class="example">
[1] 1 2 3 4 5
[1] 1 2 3 4 5
[1] 1 2 3 4 5

</pre>

<div class="org-src-container">
<pre class="src src-R">seq(-5, 5, by=.9)
</pre>
</div>

<pre class="example">
[1] -5.0 -4.1 -3.2 -2.3 -1.4 -0.5  0.4  1.3  2.2  3.1  4.0  4.9

</pre>

<div class="org-src-container">
<pre class="src src-R">seq(length=10, from=-5, by=0.2)
</pre>
</div>

<pre class="example">
[1] -5.0 -4.8 -4.6 -4.4 -4.2 -4.0 -3.8 -3.6 -3.4 -3.2

</pre>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(0, 1)
rep(x, times=5)
</pre>
</div>

<pre class="example">
[1] 0 1 0 1 0 1 0 1 0 1

</pre>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(0, 1)
rep(x, each=3)
</pre>
</div>

<pre class="example">
[1] 0 0 0 1 1 1

</pre>

<p>
Logical vectors:
</p>
<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> 0:5
t <span style="color: #558b2f;">&lt;-</span> x &gt; 3
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(0, 1, <span style="color: #0097A7;">NA</span>)
ind <span style="color: #558b2f;">&lt;-</span> is.na(x)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">0/0

<span style="color: #0097A7;">Inf</span> - <span style="color: #0097A7;">Inf</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">NaN</span>
</pre>
</div>

<pre class="example">
[1] NaN
[1] NaN

</pre>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(0, <span style="color: #0097A7;">NA</span>, <span style="color: #0097A7;">NaN</span>)

is.nan(x)
</pre>
</div>

<pre class="example">
[1] FALSE FALSE  TRUE

</pre>

<p>
Character vectors:
</p>
<div class="org-src-container">
<pre class="src src-R">labs <span style="color: #558b2f;">&lt;-</span> paste(c(<span style="color: #689f38;">"X"</span>, <span style="color: #689f38;">"Y"</span>), 1:5, sep=<span style="color: #689f38;">""</span>)
</pre>
</div>

<p>
Index cectors; selecting and modifying subsets of a data  set
</p>
<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(0, 1, <span style="color: #0097A7;">NA</span>, 4)
y <span style="color: #558b2f;">&lt;-</span> x[!is.na(x)]
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(0, 1, 2, 3, 4, 5)
x[1:3]
</pre>
</div>

<pre class="example">
[1] 0 1 2

</pre>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(0, 1, 2, 3, 4, 5)
x[-(1:3)]
</pre>
</div>

<pre class="example">
[1] 3 4 5

</pre>

<div class="org-src-container">
<pre class="src src-R">c(<span style="color: #689f38;">"x"</span>, <span style="color: #689f38;">"y"</span>)[rep(c(1, 2, 2, 1), times=2)]
</pre>
</div>

<pre class="example">
[1] "x" "y" "y" "x" "x" "y" "y" "x"

</pre>

<div class="org-src-container">
<pre class="src src-R">fruit <span style="color: #558b2f;">&lt;-</span> c(5, 10, 1, 20)
names(fruit) <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"orange"</span>, <span style="color: #689f38;">"banana"</span>, <span style="color: #689f38;">"apple"</span>, <span style="color: #689f38;">"peach"</span>)
lunch <span style="color: #558b2f;">&lt;-</span> fruit[c(<span style="color: #689f38;">"apple"</span>, <span style="color: #689f38;">"orange"</span>)]
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #0097A7;">NA</span>, 1, <span style="color: #0097A7;">NA</span>, 2)
x[is.na(x)] <span style="color: #558b2f;">&lt;-</span> 0

x
</pre>
</div>

<pre class="example">
[1] 0 1 0 2

</pre>

<div class="org-src-container">
<pre class="src src-R">y <span style="color: #558b2f;">&lt;-</span> c(-1, -2, 0, 4, 6)
y[y &lt; 0] <span style="color: #558b2f;">&lt;-</span> -y[y &lt; 0]

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Same effect as</span>
y <span style="color: #558b2f;">&lt;-</span> abs(y)
</pre>
</div>

<p>
Intrinsic attributes: mode and length
</p>
<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(0, 1)

mode(x)
</pre>
</div>

<pre class="example">
[1] "numeric"

</pre>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> (3 + 5i)

attributes(x)
mode(x)
</pre>
</div>

<pre class="example">
NULL
[1] "complex"

</pre>

<div class="org-src-container">
<pre class="src src-R">z <span style="color: #558b2f;">&lt;-</span> 0:5

digits <span style="color: #558b2f;">&lt;-</span> as.character(z)

d <span style="color: #558b2f;">&lt;-</span> as.integer(digits)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">e <span style="color: #558b2f;">&lt;-</span> numeric()

e[3] <span style="color: #558b2f;">&lt;-</span> 4

e
</pre>
</div>

<pre class="example">
[1] NA NA  4

</pre>

<div class="org-src-container">
<pre class="src src-R">alpha <span style="color: #558b2f;">&lt;-</span> 0:9

alpha <span style="color: #558b2f;">&lt;-</span> alpha[2 * 1:5]
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">alpha <span style="color: #558b2f;">&lt;-</span> 0:9

alpha <span style="color: #558b2f;">&lt;-</span> alpha[2 * 1:5]

length(alpha) <span style="color: #558b2f;">&lt;-</span> 3

alpha
</pre>
</div>

<pre class="example">
[1] 1 3 5

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">Allows R to treat z as if it were a 10-by-10 matrix</span>
attr(z, <span style="color: #689f38;">"dim"</span>) <span style="color: #558b2f;">&lt;-</span> c(3, 3)
</pre>
</div>

<p>
The class of an object:
</p>
<ul class="org-ul">
<li>numeric;</li>
<li>logical;</li>
<li>character;</li>
<li>list;</li>
<li>matrix;</li>
<li>factor;</li>
<li>date.frame</li>
</ul>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">Temporarily remove the effects of class</span>
unclass(winter)
</pre>
</div>

<p>
Ordered and unordered factors:
</p>
<div class="org-src-container">
<pre class="src src-R">state <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"tas"</span>, <span style="color: #689f38;">"sa"</span>, <span style="color: #689f38;">"qld"</span>, <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"nt"</span>, <span style="color: #689f38;">"wa"</span>, <span style="color: #689f38;">"wa"</span>, <span style="color: #689f38;">"qld"</span>,
           <span style="color: #689f38;">"vic"</span>, <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"vic"</span>, <span style="color: #689f38;">"qld"</span>, <span style="color: #689f38;">"qld"</span>, <span style="color: #689f38;">"sa"</span>, <span style="color: #689f38;">"tas"</span>, <span style="color: #689f38;">"sa"</span>,
           <span style="color: #689f38;">"nt"</span>, <span style="color: #689f38;">"wa"</span>, <span style="color: #689f38;">"vic"</span>, <span style="color: #689f38;">"qld"</span>, <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"wa"</span>, <span style="color: #689f38;">"sa"</span>, <span style="color: #689f38;">"act"</span>,
           <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"vic"</span>, <span style="color: #689f38;">"vic"</span>, <span style="color: #689f38;">"act"</span>)

statef <span style="color: #558b2f;">&lt;-</span> factor(state)

levels(statef)
</pre>
</div>

<pre class="example">
[1] "act" "nsw" "nt"  "qld" "sa"  "tas" "vic" "wa" 

</pre>

<div class="org-src-container">
<pre class="src src-R">state <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"tas"</span>, <span style="color: #689f38;">"sa"</span>, <span style="color: #689f38;">"qld"</span>, <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"nt"</span>, <span style="color: #689f38;">"wa"</span>, <span style="color: #689f38;">"wa"</span>, <span style="color: #689f38;">"qld"</span>,
           <span style="color: #689f38;">"vic"</span>, <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"vic"</span>, <span style="color: #689f38;">"qld"</span>, <span style="color: #689f38;">"qld"</span>, <span style="color: #689f38;">"sa"</span>, <span style="color: #689f38;">"tas"</span>, <span style="color: #689f38;">"sa"</span>,
           <span style="color: #689f38;">"nt"</span>, <span style="color: #689f38;">"wa"</span>, <span style="color: #689f38;">"vic"</span>, <span style="color: #689f38;">"qld"</span>, <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"wa"</span>, <span style="color: #689f38;">"sa"</span>, <span style="color: #689f38;">"act"</span>,
           <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"vic"</span>, <span style="color: #689f38;">"vic"</span>, <span style="color: #689f38;">"act"</span>)

incomes <span style="color: #558b2f;">&lt;-</span> c(60, 49, 40, 61, 64, 60, 59, 54, 62, 69, 70, 42, 56,
             61, 61, 61, 58, 51, 48, 65, 49, 49, 41, 48, 52, 46,
             59, 46, 58, 43)

statef <span style="color: #558b2f;">&lt;-</span> factor(state)

incmeans <span style="color: #558b2f;">&lt;-</span> tapply(incomes, statef, mean)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">state <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"tas"</span>, <span style="color: #689f38;">"sa"</span>, <span style="color: #689f38;">"qld"</span>, <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"nt"</span>, <span style="color: #689f38;">"wa"</span>, <span style="color: #689f38;">"wa"</span>, <span style="color: #689f38;">"qld"</span>,
           <span style="color: #689f38;">"vic"</span>, <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"vic"</span>, <span style="color: #689f38;">"qld"</span>, <span style="color: #689f38;">"qld"</span>, <span style="color: #689f38;">"sa"</span>, <span style="color: #689f38;">"tas"</span>, <span style="color: #689f38;">"sa"</span>,
           <span style="color: #689f38;">"nt"</span>, <span style="color: #689f38;">"wa"</span>, <span style="color: #689f38;">"vic"</span>, <span style="color: #689f38;">"qld"</span>, <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"wa"</span>, <span style="color: #689f38;">"sa"</span>, <span style="color: #689f38;">"act"</span>,
           <span style="color: #689f38;">"nsw"</span>, <span style="color: #689f38;">"vic"</span>, <span style="color: #689f38;">"vic"</span>, <span style="color: #689f38;">"act"</span>)

incomes <span style="color: #558b2f;">&lt;-</span> c(60, 49, 40, 61, 64, 60, 59, 54, 62, 69, 70, 42, 56,
             61, 61, 61, 58, 51, 48, 65, 49, 49, 41, 48, 52, 46,
             59, 46, 58, 43)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">ordered() creates ordered factors</span>
statef <span style="color: #558b2f;">&lt;-</span> factor(state)

incmeans <span style="color: #558b2f;">&lt;-</span> tapply(incomes, statef, mean)

<span style="color: #0097A7;">stdError</span> <span style="color: #558b2f;">&lt;-</span> <span style="color: #00796b;">function</span>(x) sqrt(var(x)/length(x))

incster <span style="color: #558b2f;">&lt;-</span> tapply(incomes, statef, stdError)
</pre>
</div>

<p>
Arrays:
</p>
<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> array(1:20, dim=c(4, 5)) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">Generate a 4 by 5 array</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> array(1:20, dim=c(4, 5)) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">Generate a 4 by 5 array</span>

i <span style="color: #558b2f;">&lt;-</span> array(c(1:3, 3:1), dim=c(3, 2)) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">i is a 3 by 2 index array</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> array(1:20, dim=c(4, 5)) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">Generate a 4 by 5 array</span>

i <span style="color: #558b2f;">&lt;-</span> array(c(1:3, 3:1), dim=c(3, 2)) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">i is a 3 by 2 index array</span>

x[i] <span style="color: #607d8b;"># </span><span style="color: #607d8b;">Extract those elements</span>
</pre>
</div>

<pre class="example">
[1] 9 6 3

</pre>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> array(1:20, dim=c(4, 5)) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">Generate a 4 by 5 array</span>

i <span style="color: #558b2f;">&lt;-</span> array(c(1:3, 3:1), dim=c(3, 2)) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">i is a 3 by 2 index array</span>

x[i] <span style="color: #607d8b;"># </span><span style="color: #607d8b;">Extract those elements</span>

x[i] <span style="color: #558b2f;">&lt;-</span> 0 <span style="color: #607d8b;">#</span><span style="color: #607d8b;">Replace those elements by zeros</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">Xb <span style="color: #558b2f;">&lt;-</span> matrix(0, n, b) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">blocks</span>
Xv <span style="color: #558b2f;">&lt;-</span> matrix(0, n, v) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">varieties</span>
ib <span style="color: #558b2f;">&lt;-</span> cbind(1:n, blocks)
iv <span style="color: #558b2f;">&lt;-</span> cbind(1:n, varieties)
Xb[ib] <span style="color: #558b2f;">&lt;-</span> 1
Xv[iv] <span style="color: #558b2f;">&lt;-</span> 1
X <span style="color: #558b2f;">&lt;-</span> cbind(Xb, Xv)

N <span style="color: #558b2f;">&lt;-</span> table(blocks, varieties)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> matrix(1:10, ncol=5)
dimnames(x) <span style="color: #558b2f;">&lt;-</span> list(c(<span style="color: #689f38;">"nome1"</span>, <span style="color: #689f38;">"nome2"</span>), <span style="color: #0097A7;">NULL</span>) <span style="color: #607d8b;">#</span><span style="color: #607d8b;">nomina solo le righe</span>
x
</pre>
</div>

<pre class="example">
      [,1] [,2] [,3] [,4] [,5]
nome1    1    3    5    7    9
nome2    2    4    6    8   10

</pre>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> matrix(1:10, ncol=5)
dimnames(x) <span style="color: #558b2f;">&lt;-</span> list(c(<span style="color: #689f38;">"nome2"</span>, <span style="color: #689f38;">"nome2"</span>), <span style="color: #0097A7;">NULL</span>) <span style="color: #607d8b;">#</span><span style="color: #607d8b;">nomina solo le righe</span>
dimnames(x)[[2]] <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"g"</span>, <span style="color: #689f38;">"h"</span>, <span style="color: #689f38;">"j"</span>, <span style="color: #689f38;">"j"</span>, <span style="color: #689f38;">"k"</span>) <span style="color: #607d8b;">#</span><span style="color: #607d8b;">nomina le colonne</span>
x
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">Utilizzabili anche le funzioni rownames() e colnames()</span>
</pre>
</div>

<pre class="example">
      g h j j  k
nome2 1 3 5 7  9
nome2 2 4 6 8 10

</pre>

<div class="org-src-container">
<pre class="src src-R">h <span style="color: #558b2f;">&lt;-</span> 0:23

Z <span style="color: #558b2f;">&lt;-</span> array(h, dim=c(3, 4, 2))

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">Equivalent if h has 24 elements and not less</span>
Z <span style="color: #558b2f;">&lt;-</span> h ; dim(Z) <span style="color: #558b2f;">&lt;-</span> c(3, 4, 2)
Z
</pre>
</div>

<pre class="example">
, , 1

     [,1] [,2] [,3] [,4]
[1,]    0    3    6    9
[2,]    1    4    7   10
[3,]    2    5    8   11

, , 2

     [,1] [,2] [,3] [,4]
[1,]   12   15   18   21
[2,]   13   16   19   22
[3,]   14   17   20   23

</pre>

<div class="org-src-container">
<pre class="src src-R">h <span style="color: #558b2f;">&lt;-</span> 0:11

Z <span style="color: #558b2f;">&lt;-</span> array(h, dim=c(3, 4, 2))
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">h <span style="color: #558b2f;">&lt;-</span> 0:5

Z <span style="color: #558b2f;">&lt;-</span> array(h, dim=c(3, 2, 2))

Z[1:6]
</pre>
</div>

<pre class="example">
[1] 0 1 2 3 4 5

</pre>

<div class="org-src-container">
<pre class="src src-R">h <span style="color: #558b2f;">&lt;-</span> 0:5

Z <span style="color: #558b2f;">&lt;-</span> array(h, dim=c(3, 2, 2))

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Equivalent to Z</span>
Z[]
</pre>
</div>

<pre class="example">
, , 1

     [,1] [,2]
[1,]    0    3
[2,]    1    4
[3,]    2    5

, , 2

     [,1] [,2]
[1,]    0    3
[2,]    1    4
[3,]    2    5

</pre>

<p>
The outer product of two arrays:
</p>
<div class="org-src-container">
<pre class="src src-R">a <span style="color: #558b2f;">&lt;-</span> array(1:5)
b <span style="color: #558b2f;">&lt;-</span> array (6: 10)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Equivalent: ab &lt;- outer(a, b, "*")</span>
ab <span style="color: #558b2f;">&lt;-</span> a <span style="color: #558b2f;">%o%</span> b
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> 0:5
y <span style="color: #558b2f;">&lt;-</span> 2:4

<span style="color: #0097A7;">f</span> <span style="color: #558b2f;">&lt;-</span> <span style="color: #00796b;">function</span>(x, y) cos(y)/(1 + x^2)
z <span style="color: #558b2f;">&lt;-</span> outer(x, y, f)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Determinant of 2 by 2 matrices</span>

d <span style="color: #558b2f;">&lt;-</span> outer(0:9, 0:9)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Determinant of 2 by 2 matrices</span>

d <span style="color: #558b2f;">&lt;-</span> outer(0:9, 0:9)
fr <span style="color: #558b2f;">&lt;-</span> table(outer(d, d, <span style="color: #689f38;">"-"</span>))
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Determinant of 2 by 2 matrices</span>

d <span style="color: #558b2f;">&lt;-</span> outer(0:9, 0:9)
fr <span style="color: #558b2f;">&lt;-</span> table(outer(d, d, <span style="color: #689f38;">"-"</span>))
plot(fr, xlab=<span style="color: #689f38;">"Determinant"</span>, ylab=<span style="color: #689f38;">"Frequency"</span>)
</pre>
</div>


<div class="figure">
<p><img src="graph.png" alt="graph.png" />
</p>
</div>

<p>
Generalized transpose of an array:
</p>
<div class="org-src-container">
<pre class="src src-R">A <span style="color: #558b2f;">&lt;-</span> array(c(0:3, 5:6), dim=c(3, 2))

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">Transpose (also t(A)):</span>
B <span style="color: #558b2f;">&lt;-</span> aperm(A, c(2, 1))
</pre>
</div>

<p>
Matrix facilities:
</p>
<div class="org-src-container">
<pre class="src src-R">A <span style="color: #558b2f;">&lt;-</span> array(0:9, c(5, 2))

row <span style="color: #558b2f;">&lt;-</span> nrow(A)
col <span style="color: #558b2f;">&lt;-</span> ncol(A)

c(row, col)
</pre>
</div>

<pre class="example">
[1] 5 2

</pre>

<p>
Matrix multiplication:
</p>
<div class="org-src-container">
<pre class="src src-R">A <span style="color: #558b2f;">&lt;-</span> array(0:5, c(2, 3))
B <span style="color: #558b2f;">&lt;-</span> array(1:6, c(2, 3))

A * B
</pre>
</div>

<pre class="example">
     [,1] [,2] [,3]
[1,]    0    6   20
[2,]    2   12   30

</pre>

<div class="org-src-container">
<pre class="src src-R">A <span style="color: #558b2f;">&lt;-</span> array(0:5, c(2, 3))
B <span style="color: #558b2f;">&lt;-</span> array(1:6, c(3, 2))

A <span style="color: #558b2f;">%*%</span> B
</pre>
</div>

<pre class="example">
     [,1] [,2]
[1,]   16   34
[2,]   22   49

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">The same, but more efficient, of: t(X) %*% y</span>
crossprod(X, y)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> 0:4
y <span style="color: #558b2f;">&lt;-</span> 5:9
A <span style="color: #558b2f;">&lt;-</span> array(0:24, c(5, 5))

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">Quadratic form</span>
x <span style="color: #558b2f;">%*%</span> A <span style="color: #558b2f;">%*%</span> x
</pre>
</div>

<pre class="example">
     [,1]
[1,] 1800

</pre>

<div class="org-src-container">
<pre class="src src-R">v <span style="color: #558b2f;">&lt;-</span> 0:5

diag(v)
</pre>
</div>

<pre class="example">
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    0    0    0    0    0    0
[2,]    0    1    0    0    0    0
[3,]    0    0    2    0    0    0
[4,]    0    0    0    3    0    0
[5,]    0    0    0    0    4    0
[6,]    0    0    0    0    0    5

</pre>

<div class="org-src-container">
<pre class="src src-R">k <span style="color: #558b2f;">&lt;-</span> 4

diag(k)
</pre>
</div>

<pre class="example">
     [,1] [,2] [,3] [,4]
[1,]    1    0    0    0
[2,]    0    1    0    0
[3,]    0    0    1    0
[4,]    0    0    0    1

</pre>

<div class="org-src-container">
<pre class="src src-R">M <span style="color: #558b2f;">&lt;-</span> array(0:8, c(3, 3))

diag(M)
</pre>
</div>

<pre class="example">
[1] 0 4 8

</pre>

<p>
Linear equations and inversion:
</p>
<div class="org-src-container">
<pre class="src src-R">A <span style="color: #558b2f;">&lt;-</span> array(0:3, c(2, 2))
b <span style="color: #558b2f;">&lt;-</span> 0:1

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">b = A x</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">x = A^{-1} b</span>
x <span style="color: #558b2f;">&lt;-</span> solve(A, b)
</pre>
</div>

<p>
Eigenvalues and eigenvectors
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Assign to ev the list of this 2 components: values and vectors</span>
Sm <span style="color: #558b2f;">&lt;-</span> array(c(1, 2, 2, 1), c(2, 2))

ev <span style="color: #558b2f;">&lt;-</span> eigen(Sm)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">For only the eigenvalues</span>
evals <span style="color: #558b2f;">&lt;-</span> eigen(Sm)$values

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">If the eigenvectors are not needed</span>
evals <span style="color: #558b2f;">&lt;-</span> eigen(Sm, only.values = <span style="color: #0097A7;">TRUE</span>)$values
</pre>
</div>

<p>
Least squares fitting and the QR decomposition
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">A list squares fit where y is the vector of observations and X is the desing matrix</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">A grand mean term is automatically included and need not be included explicitly as a column of X</span>
ans <span style="color: #558b2f;">&lt;-</span> lsfit(X, y)
</pre>
</div>

<p>
Forming partitioned matrices, <code>cbind()</code> and <code>rbind()</code>
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">The arguments to cbind() must be either vectors of any length,</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">or matrices with the same colums size, that is the same number of rows</span>
X <span style="color: #558b2f;">&lt;-</span> cbind(arg_1, arg_2, ...)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">rbind &#8594; row bind</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">X1 <span style="color: #558b2f;">&lt;-</span> 0:4
X2 <span style="color: #558b2f;">&lt;-</span> 5:9

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">The 1 is shorter than the vectors, so it is cyclically extended to match the matrix column size</span>
X <span style="color: #558b2f;">&lt;-</span> cbind(1, X1, X2)
</pre>
</div>

<p>
The concatenation function, <code>c()</code>, with arrays
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">To coerce the array vec batk to a simple vector object</span>
vec <span style="color: #558b2f;">&lt;-</span> as.vector(X)
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Equivalent to</span>
vec <span style="color: #558b2f;">&lt;-</span> c(X)
</pre>
</div>

<p>
Lists and data frames:
</p>
<div class="org-src-container">
<pre class="src src-R">Lst <span style="color: #558b2f;">&lt;-</span> list(name=<span style="color: #689f38;">"Fred"</span>, wife=<span style="color: #689f38;">"Mary"</span>, no.children=3, child.ages=c(4, 7, 9))

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Lst[[1]] is the first component, etc.</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Lst$name or Lst[["name"]] is also the first component</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Lst[1] is the sublist consisting of the first entry only. The correct operator is '[[...]]'</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">length(Lst) is the lenght of the list</span>
</pre>
</div>

<p>
Constructing and modifying lists
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">To extend a list by specifying additional components</span>
Lst[5] <span style="color: #558b2f;">&lt;-</span> list(matrix=Mat)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Concatenating lists</span>
list.ABC <span style="color: #558b2f;">&lt;-</span> c(list.A, list.B, list.C)
</pre>
</div>

<p>
Data frames
</p>
<div class="org-src-container">
<pre class="src src-R">accountants <span style="color: #558b2f;">&lt;-</span> data.frame(home=statef, loot=incomes, shot=incomef)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">List to data frame: use the function as.data.frame()</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">To eliminate a component</span>
accountants$home <span style="color: #558b2f;">&lt;-</span> <span style="color: #0097A7;">NULL</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">crea un dataframe con una variabile 'quantitativa' ed una</span>
<span style="color: #607d8b; font-weight: bold;">#</span><span style="color: #607d8b; font-weight: bold;">'</span><span style="color: #607d8b;">qualitativa'</span>
X <span style="color: #558b2f;">&lt;-</span> data.frame(a=1:4, sesso=c(<span style="color: #689f38;">"M"</span>, <span style="color: #689f38;">"F"</span>, <span style="color: #689f38;">"F"</span>, <span style="color: #689f38;">"M"</span>))
X$eta <span style="color: #558b2f;">&lt;-</span> c(2.5, 3, 5, 6.2) <span style="color: #607d8b;">#</span><span style="color: #607d8b;">aggiungi una variabile di nome eta</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">X <span style="color: #558b2f;">&lt;-</span> data.frame(a=1:4, sesso=c(<span style="color: #689f38;">"M"</span>, <span style="color: #689f38;">"F"</span>, <span style="color: #689f38;">"F"</span>, <span style="color: #689f38;">"M"</span>))
X$eta <span style="color: #558b2f;">&lt;-</span> c(2.5, 3, 5, 6.2) <span style="color: #607d8b;">#</span><span style="color: #607d8b;">aggiungi una variabile di nome eta</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">seleziona i valori di "a" se eta &lt;=5 E eta &gt;3</span>
X$a[X$eta &lt;=5 &amp; X$eta&gt;3]
</pre>
</div>

<pre class="example">
[1] 3

</pre>

<div class="org-src-container">
<pre class="src src-R">X <span style="color: #558b2f;">&lt;-</span> data.frame(a=1:4, sesso=c(<span style="color: #689f38;">"M"</span>, <span style="color: #689f38;">"F"</span>, <span style="color: #689f38;">"F"</span>, <span style="color: #689f38;">"M"</span>))
X$eta <span style="color: #558b2f;">&lt;-</span> c(2.5, 3, 5, 6.2) <span style="color: #607d8b;">#</span><span style="color: #607d8b;">aggiungi una variabile di nome eta</span>

subset(X, subset=(eta&lt;3 | eta&gt;5), select=c(a, sesso))
</pre>
</div>

<pre class="example">
  a sesso
1 1     M
4 4     M

</pre>

<div class="org-src-container">
<pre class="src src-R">X <span style="color: #558b2f;">&lt;-</span> data.frame(a=1:4, sesso=c(<span style="color: #689f38;">"M"</span>, <span style="color: #689f38;">"F"</span>, <span style="color: #689f38;">"F"</span>, <span style="color: #689f38;">"M"</span>))
X$eta <span style="color: #558b2f;">&lt;-</span> c(2.5, 3, 5, 6.2) <span style="color: #607d8b;">#</span><span style="color: #607d8b;">aggiungi una variabile di nome eta</span>

subset(X, subset=(eta&lt;3|eta&gt;5), select=-eta)
</pre>
</div>

<pre class="example">
  a sesso
1 1     M
4 4     M

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">lentils is a data frame: lentils$u, lentils$v and lentils$w</span>
<span style="color: #558b2f;">attach</span>(lentils)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Do not modify lentils$u</span>
u <span style="color: #558b2f;">&lt;-</span> v + w

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">Modify lentils$u</span>
lentils$u <span style="color: #558b2f;">&lt;-</span> v + w

<span style="color: #558b2f;">detach</span>(lentils)
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">or detach("lentils")</span>
</pre>
</div>

<p>
Reading data from files
</p>
<div class="org-src-container">
<pre class="src src-R">HousePrice <span style="color: #558b2f;">&lt;-</span> read.table(<span style="color: #689f38;">"houses.data"</span>, header=<span style="color: #0097A7;">TRUE</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">prova <span style="color: #558b2f;">&lt;-</span> read.table(<span style="color: #689f38;">"mio.txt"</span>, row.names=1)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">X <span style="color: #558b2f;">&lt;-</span> read.table(file=<span style="color: #689f38;">"c:/documenti/dati.txt"</span>,
                header=<span style="color: #0097A7;">TRUE</span>,
                sep=<span style="color: #689f38;">"\t"</span>
                na.strings=<span style="color: #689f38;">"NA"</span>,
                dec=<span style="color: #689f38;">"."</span>)
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">nrows &#8594; numero massimo di righe da leggere</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">skip &#8594; numero di righe iniziali da saltare prima dell'importazione</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">X$eta[1] <span style="color: #558b2f;">&lt;-</span> X$sesso[4] <span style="color: #558b2f;">&lt;-</span> <span style="color: #0097A7;">NA</span>
X2 <span style="color: #558b2f;">&lt;-</span> X[!is.na(X$sesso)&amp;!is.na(X$eta),]
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Si pu&#242; semplicemente usare na.omit(X)</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Crea una variabile categoriale e nomina le etichette:</span>
x <span style="color: #558b2f;">&lt;-</span> factor(c(1, 1, 2, 3, 1), labels=c(<span style="color: #689f38;">"gruppo1"</span>, <span style="color: #689f38;">"gruppo2"</span>, <span style="color: #689f38;">"gruppo3"</span>))
x
</pre>
</div>

<pre class="example">
[1] gruppo1 gruppo1 gruppo2 gruppo3 gruppo1
Levels: gruppo1 gruppo2 gruppo3

</pre>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> factor(c(1, 1, 2, 3, 1), labels=c(<span style="color: #689f38;">"gruppo1"</span>, <span style="color: #689f38;">"gruppo2"</span>, <span style="color: #689f38;">"gruppo3"</span>))

factor(x, levels=c(<span style="color: #689f38;">"gruppo1"</span>, <span style="color: #689f38;">"gruppo3"</span>)) <span style="color: #607d8b;">#</span><span style="color: #607d8b;">escludi la categoria 3</span>
</pre>
</div>

<pre class="example">
[1] gruppo1 gruppo1 &lt;NA&gt;    gruppo3 gruppo1
Levels: gruppo1 gruppo3

</pre>

<div class="org-src-container">
<pre class="src src-R">eta <span style="color: #558b2f;">&lt;-</span> c(2, 4, .3, 5, .2, 6, 8, 9, .8, 4, 10, 9.5)
eta.cat <span style="color: #558b2f;">&lt;-</span> cut(eta, breaks=c(0, 3, 5, 10),
               labels=c(<span style="color: #689f38;">"basso"</span>, <span style="color: #689f38;">"medio"</span>, <span style="color: #689f38;">"alto"</span>))
eta.cat
</pre>
</div>

<div class="org-src-container">
<pre class="src src-org">basso
medio
basso
medio
basso
alto
alto
alto
basso
medio
alto
alto
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">inp <span style="color: #558b2f;">&lt;-</span> scan(<span style="color: #689f38;">"input.dat"</span>, list(<span style="color: #689f38;">""</span>, 0, 0))

label <span style="color: #558b2f;">&lt;-</span> inp[[1]]; x <span style="color: #558b2f;">&lt;-</span> inp[[2]]; y <span style="color: #558b2f;">&lt;-</span> inp[[3]]
</pre>
</div>

<p>
Similarly:
</p>
<div class="org-src-container">
<pre class="src src-R">inp <span style="color: #558b2f;">&lt;-</span> scan(<span style="color: #689f38;">"input.dat"</span>, list(id=<span style="color: #689f38;">""</span>, x=0, y=0))

lable &#171;- inp$id; x <span style="color: #558b2f;">&lt;-</span> inp$x; y <span style="color: #558b2f;">&lt;-</span> inpt$y
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">The second arguemnt is a single value and not a list</span>
X <span style="color: #558b2f;">&lt;-</span> matrix(scan(<span style="color: #689f38;">"light.dat"</span>, 0), ncol=5, byrow=<span style="color: #0097A7;">TRUE</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">List of datasets</span>
data()
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">To access data from a particular package</span>
data(package=<span style="color: #689f38;">"rpart"</span>)
data(Puromycin, package=<span style="color: #689f38;">"datasets"</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">xnew <span style="color: #558b2f;">&lt;-</span> edit(xold)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">fix(xold) is equivalent to</span>
xold <span style="color: #558b2f;">&lt;-</span> edit(xold)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">To enter new data via the spreadsheet interface</span>
xnew <span style="color: #558b2f;">&lt;-</span> edit(data.frame())
</pre>
</div>
</div>
</div>

<div id="outline-container-orgeb7324d" class="outline-3">
<h3 id="orgeb7324d"><span class="section-number-3">3.2</span> Slides</h3>
<div class="outline-text-3" id="text-3-2">
</div>
<div id="outline-container-org5e1ec72" class="outline-4">
<h4 id="org5e1ec72"><span class="section-number-4">3.2.1</span> Statistica Descrittiva</h4>
<div class="outline-text-4" id="text-3-2-1">
<p>
Esempio 1.1
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Caricare il file "esempio1.1.csv"</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">f &lt;- file.choose()</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">ese11 &lt;- scan(f, sep=";")</span>
ese11 <span style="color: #558b2f;">&lt;-</span> scan(<span style="color: #689f38;">"./Files/esempio1.1.csv"</span>, sep=<span style="color: #689f38;">";"</span>)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Frequenze assolute</span>
table(ese11)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Frequenze relative</span>
prop.table(table(ese11))

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Frequenze cumulate assolute</span>
cumsum(table(ese11))

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Frequenze cumulate relative</span>
cumsum(prop.table(table(ese11)))

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Dati quantitativi - barplot</span>
barplot(table(ese11), xlab=<span style="color: #689f38;">"numero stanze"</span>, ylab=<span style="color: #689f38;">"frequenza"</span>,
        main=<span style="color: #689f38;">""</span>)
</pre>
</div>


<div class="figure">
<p><img src="barplot.png" alt="barplot.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Caricare il file "esempio1.1.csv"</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">f &lt;- file.choose()</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">ese11 &lt;- scan(f, sep=";")</span>
ese11 <span style="color: #558b2f;">&lt;-</span> scan(<span style="color: #689f38;">"./Files/esempio1.1.csv"</span>,
sep=<span style="color: #689f38;">";"</span>)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Frequenze assolute</span>
table(ese11)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Frequenze relative</span>
prop.table(table(ese11))

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Frequenze cumulate assolute</span>
cumsum(table(ese11))

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Frequenze cumulate relative</span>
cumsum(prop.table(table(ese11)))

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Dati quantitativi - stripchart o dot plot</span>
stripchart(ese11, method=<span style="color: #689f38;">"stack"</span>, xlab=<span style="color: #689f38;">"stanze"</span>) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">stack</span>
</pre>
</div>


<div class="figure">
<p><img src="stripchart.png" alt="stripchart.png" />
</p>
</div>

<p>
Esempio 1.2
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Caricare il file "esempio1.2.csv"</span>
ese12 <span style="color: #558b2f;">&lt;-</span> scan(<span style="color: #689f38;">"./Files/esempio1.2.csv"</span>,
sep=<span style="color: #689f38;">";"</span>, dec=<span style="color: #689f38;">","</span>)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">minimo e massimo</span>
min(ese12)
max(ese12)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Dati quantitativi - hist</span>
interval <span style="color: #558b2f;">&lt;-</span> c(0.4, 1.5, 2.3, 3, 4, 5.5)
hist(ese12, breaks=interval)
</pre>
</div>


<div class="figure">
<p><img src="hist1.png" alt="hist1.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-R">
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Caricare il file "esempio1.2.csv"</span>
ese12 <span style="color: #558b2f;">&lt;-</span> scan(<span style="color: #689f38;">"./Files/esempio1.2.csv"</span>,
sep=<span style="color: #689f38;">";"</span>, dec=<span style="color: #689f38;">","</span>)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">minimo e massimo</span>
min(ese12)
max(ese12)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Dati quantitativi - hist</span>
interval <span style="color: #558b2f;">&lt;-</span> c(0.4, 1.5, 2.3, 3, 4, 5.5)
hist(ese12)
</pre>
</div>


<div class="figure">
<p><img src="hist2.png" alt="hist2.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-R">
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Caricare il file "esempio1.2.csv"</span>
ese12 <span style="color: #558b2f;">&lt;-</span> scan(<span style="color: #689f38;">"./Files/esempio1.2.csv"</span>,
sep=<span style="color: #689f38;">";"</span>, dec=<span style="color: #689f38;">","</span>)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">minimo e massimo</span>
min(ese12)
max(ese12)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Dati quantitativi - plot</span>
plot(ese12, xlab=<span style="color: #689f38;">"appartamenti"</span>, ylab=<span style="color: #689f38;">"costo"</span>)
</pre>
</div>


<div class="figure">
<p><img src="plot.png" alt="plot.png" />
</p>
</div>

<p>
Esercizio 1:
</p>
<ul class="org-ul">
<li>Si √® interessati a studiare la variabile <code>years</code> relativa all'et√† di un certo numero di giocatori di calcio.</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">giocatori <span style="color: #558b2f;">&lt;-</span> read.table(<span style="color: #689f38;">"./Files/giocatori.txt"</span>,
            sep=<span style="color: #689f38;">";"</span>, header=<span style="color: #0097A7;">TRUE</span>)

<span style="color: #558b2f;">attach</span>(giocatori)

table(years)
</pre>
</div>

<pre class="example">
years
 18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37 
 17  36 107 170 192 209 203 173 198 209 197 209 149 159 139 115 128  96  85  56 
 38  39  40  41  42  43  44  46 
 40  30  15   9   5   2   3   1

</pre>

<div class="org-src-container">
<pre class="src src-R">prop.table(table(years))
</pre>
</div>

<pre class="example">
years
          18           19           20           21           22           23 
0.0057588076 0.0121951220 0.0362466125 0.0575880759 0.0650406504 0.0707994580 
          24           25           26           27           28           29 
0.0687669377 0.0586043360 0.0670731707 0.0707994580 0.0667344173 0.0707994580 
          30           31           32           33           34           35 
0.0504742547 0.0538617886 0.0470867209 0.0389566396 0.0433604336 0.0325203252 
          36           37           38           39           40           41 
0.0287940379 0.0189701897 0.0135501355 0.0101626016 0.0050813008 0.0030487805 
          42           43           44           46 
0.0016937669 0.0006775068 0.0010162602 0.0003387534
</pre>

<div class="org-src-container">
<pre class="src src-R">cumsum(table(years))
</pre>
</div>

<pre class="example">
  18   19   20   21   22   23   24   25   26   27   28   29   30   31   32   33 
  17   53  160  330  522  731  934 1107 1305 1514 1711 1920 2069 2228 2367 2482 
  34   35   36   37   38   39   40   41   42   43   44   46 
2610 2706 2791 2847 2887 2917 2932 2941 2946 2948 2951 2952

</pre>

<div class="org-src-container">
<pre class="src src-R">cumsum(prop.table(table(year)))
</pre>
</div>

<div class="org-src-container">
<pre class="src src-org">org<span style="color: #8b4513;">_babel</span>_R<span style="color: #8b4513;">_eoe</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R">min <span style="color: #558b2f;">&lt;-</span> min(years)
max <span style="color: #558b2f;">&lt;-</span> max(years)

c(min, max)
</pre>
</div>

<pre class="example">
Error in table(year) : oggetto "year" non trovato
[1] 18 46

</pre>

<div class="org-src-container">
<pre class="src src-R">hist(years, main=<span style="color: #689f38;">"Istogramma et&#224;"</span>)
</pre>
</div>


<div class="figure">
<p><img src="istogramma.png" alt="istogramma.png" />
</p>
</div>

<p>
Esempio 1.8:
</p>
<div class="org-src-container">
<pre class="src src-R">ese11 <span style="color: #558b2f;">&lt;-</span> scan(<span style="color: #689f38;">"./Files/esempio1.1.csv"</span>,
sep=<span style="color: #689f38;">";"</span>)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Ordinamento crescente</span>
cresc <span style="color: #558b2f;">&lt;-</span> sort(ese11)
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Ordinamento descrescente</span>
decr <span style="color: #558b2f;">&lt;-</span> sort(ese11, dec=T)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Media</span>
media <span style="color: #558b2f;">&lt;-</span> mean(ese11)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Mediana</span>
mediana <span style="color: #558b2f;">&lt;-</span> median(ese11)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Moda</span>
m <span style="color: #558b2f;">&lt;-</span> table(ese11)
moda <span style="color: #558b2f;">&lt;-</span> m[m==max(m)]

list(cresc, decr, media, mediana, moda)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-org">2       8       4.3125  4       24
2       8       4.3125  4       24
2       8       4.3125  4       24
2       7       4.3125  4       24
2       7       4.3125  4       24
2       7       4.3125  4       24
2       7       4.3125  4       24
2       7       4.3125  4       24
2       6       4.3125  4       24
2       6       4.3125  4       24
2       6       4.3125  4       24
3       6       4.3125  4       24
3       6       4.3125  4       24
3       6       4.3125  4       24
3       6       4.3125  4       24
3       6       4.3125  4       24
3       6       4.3125  4       24
3       5       4.3125  4       24
3       5       4.3125  4       24
3       5       4.3125  4       24
3       5       4.3125  4       24
3       5       4.3125  4       24
3       5       4.3125  4       24
3       5       4.3125  4       24
4       5       4.3125  4       24
4       5       4.3125  4       24
4       5       4.3125  4       24
4       5       4.3125  4       24
4       5       4.3125  4       24
4       5       4.3125  4       24
4       5       4.3125  4       24
4       5       4.3125  4       24
4       4       4.3125  4       24
4       4       4.3125  4       24
4       4       4.3125  4       24
4       4       4.3125  4       24
4       4       4.3125  4       24
4       4       4.3125  4       24
4       4       4.3125  4       24
4       4       4.3125  4       24
4       4       4.3125  4       24
4       4       4.3125  4       24
4       4       4.3125  4       24
4       4       4.3125  4       24
4       4       4.3125  4       24
4       4       4.3125  4       24
4       4       4.3125  4       24
4       4       4.3125  4       24
5       4       4.3125  4       24
5       4       4.3125  4       24
5       4       4.3125  4       24
5       4       4.3125  4       24
5       4       4.3125  4       24
5       4       4.3125  4       24
5       4       4.3125  4       24
5       4       4.3125  4       24
5       3       4.3125  4       24
5       3       4.3125  4       24
5       3       4.3125  4       24
5       3       4.3125  4       24
5       3       4.3125  4       24
5       3       4.3125  4       24
5       3       4.3125  4       24
6       3       4.3125  4       24
6       3       4.3125  4       24
6       3       4.3125  4       24
6       3       4.3125  4       24
6       3       4.3125  4       24
6       3       4.3125  4       24
6       2       4.3125  4       24
6       2       4.3125  4       24
6       2       4.3125  4       24
7       2       4.3125  4       24
7       2       4.3125  4       24
7       2       4.3125  4       24
7       2       4.3125  4       24
7       2       4.3125  4       24
8       2       4.3125  4       24
8       2       4.3125  4       24
8       2       4.3125  4       24
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Caricare il file "esempio1.2.csv"</span>
ese12 <span style="color: #558b2f;">&lt;-</span> scan(<span style="color: #689f38;">"./Files/esempio1.2.csv"</span>,
sep=<span style="color: #689f38;">";"</span>, dec=<span style="color: #689f38;">","</span>)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Varianza campionaria</span>
var <span style="color: #558b2f;">&lt;-</span> var(ese12)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Deviazione standard</span>
sd <span style="color: #558b2f;">&lt;-</span> sd(ese12)
sqrt(var(ese12))

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Quantili</span>
quant <span style="color: #558b2f;">&lt;-</span> quantile(ese12, c(0.25, 0.5, 0.75))

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Range interquantile</span>
iqr <span style="color: #558b2f;">&lt;-</span> IQR(ese12)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Range</span>
range(ese12)

list(var, sd, quant, iqr, range)
</pre>
</div>

<pre class="example">
Read 80 items
[1] 1.2132
[1] 0.44 5.42
[[1]]
[1] 1.471853

[[2]]
[1] 1.2132

[[3]]
  25%   50%   75% 
1.895 2.355 3.675 

[[4]]
[1] 1.78

[[5]]
function (..., na.rm = FALSE)  .Primitive("range")
</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">install.packages("e1071")</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">library("e1071")</span>
<span style="color: #558b2f;">require</span>(<span style="color: #689f38;">"e1071"</span>)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Asimmetria</span>
skewness <span style="color: #558b2f;">&lt;-</span> skewness(ese12)
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2 * sqrt(6/length(ese12))</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Curtosi</span>
kurtosis <span style="color: #558b2f;">&lt;-</span> kurtosis(ese12)
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">4 * sqrt(6/length(ese12))</span>

list(skewness, kurtosis)
</pre>
</div>

<pre class="example">
Carico il pacchetto richiesto: e1071
[[1]]
[1] 0.3226639

[[2]]
[1] -0.8020067

</pre>


<div class="figure">
<p><img src="Laboratorio/screenshot_2018-03-20_19-50-29.png" alt="screenshot_2018-03-20_19-50-29.png" />
</p>
</div>


<div class="figure">
<p><img src="Laboratorio/screenshot_2018-03-20_19-51-03.png" alt="screenshot_2018-03-20_19-51-03.png" />
</p>
</div>

<p>
Esercizio 2:
</p>
<ul class="org-ul">
<li>Si √® interessati a studiare la variabile years relativa all'et√† di un certo numero di giocatori di calcio</li>
</ul>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #558b2f;">require</span>(<span style="color: #689f38;">"e1071"</span>)

giocatori <span style="color: #558b2f;">&lt;-</span> read.table(<span style="color: #689f38;">"./Files/giocatori.txt"</span>,
            sep=<span style="color: #689f38;">";"</span>, header=<span style="color: #0097A7;">TRUE</span>)

<span style="color: #558b2f;">attach</span>(giocatori)

media <span style="color: #558b2f;">&lt;-</span> mean(years)

mediana <span style="color: #558b2f;">&lt;-</span> median(years)

max <span style="color: #558b2f;">&lt;-</span> max(years)

m <span style="color: #558b2f;">&lt;-</span> table(years)
moda <span style="color: #558b2f;">&lt;-</span> m[m==max(m)]

iqr <span style="color: #558b2f;">&lt;-</span> IQR(years)

varianza <span style="color: #558b2f;">&lt;-</span> var(years)

devst <span style="color: #558b2f;">&lt;-</span> sd(years)

skewness <span style="color: #558b2f;">&lt;-</span> skewness(years)

kurtosis <span style="color: #558b2f;">&lt;-</span> kurtosis(years)

list(media, mediana, max, moda, iqr, varianza, devst, skewness, kurtosis)
</pre>
</div>

<pre class="example">
[[1]]
[1] 27.74898

[[2]]
[1] 27

[[3]]
[1] 46

[[4]]
years
 23  27  29 
209 209 209 

[[5]]
[1] 7

[[6]]
[1] 26.43409

[[7]]
[1] 5.141409

[[8]]
[1] 0.3825924

[[9]]
[1] -0.5454063

</pre>

<p>
Esempio 1.12
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Caricare il file "esempio 1.12.csv"</span>
ese112 <span style="color: #558b2f;">&lt;-</span> read.csv(<span style="color: #689f38;">"./Files/esempio1.12.csv"</span>,
                   sep=<span style="color: #689f38;">";"</span>, header=<span style="color: #0097A7;">TRUE</span>)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Frequenze assolute</span>
tc <span style="color: #558b2f;">&lt;-</span> table(ese112)
tc
</pre>
</div>

<pre class="example">
      Occupanti
Stanze 2 3 4 5 7
     2 3 1 0 0 0
     3 5 2 2 0 0
     4 1 5 4 2 0
     5 1 3 2 0 1
     6 0 0 2 0 1

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Tabella di contingenza con distribuzioni assolute marginali</span>
tcc <span style="color: #558b2f;">&lt;-</span> cbind(tc, margin.table(tc, 1)) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">marginale stanze</span>
tcc
</pre>
</div>

<pre class="example">
  2 3 4 5 7   
2 3 1 0 0 0  4
3 5 2 2 0 0  9
4 1 5 4 2 0 12
5 1 3 2 0 1  7
6 0 0 2 0 1  3

</pre>

<div class="org-src-container">
<pre class="src src-R">rbind(tcc, margin.table(tcc, 2)) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">marginale occupanti</span>
</pre>
</div>

<pre class="example">
   2  3  4 5 7   
2  3  1  0 0 0  4
3  5  2  2 0 0  9
4  1  5  4 2 0 12
5  1  3  2 0 1  7
6  0  0  2 0 1  3
  10 11 10 2 2 35

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Frequenze relative</span>
tcr <span style="color: #558b2f;">&lt;-</span> prop.table(table(ese112))
tcr
</pre>
</div>

<pre class="example">
      Occupanti
Stanze          2          3          4          5          7
     2 0.08571429 0.02857143 0.00000000 0.00000000 0.00000000
     3 0.14285714 0.05714286 0.05714286 0.00000000 0.00000000
     4 0.02857143 0.14285714 0.11428571 0.05714286 0.00000000
     5 0.02857143 0.08571429 0.05714286 0.00000000 0.02857143
     6 0.00000000 0.00000000 0.05714286 0.00000000 0.02857143

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Tabella di contingenza con distribuzioni relative marginali</span>
tccr <span style="color: #558b2f;">&lt;-</span> cbind(tcr, margin.table(tcr, 1)) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">marginale stanze</span>
rbind(tccr, margin.table(tccr, 2)) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">marginale occupanti</span>
</pre>
</div>

<pre class="example">
           2          3          4          5          7           
2 0.08571429 0.02857143 0.00000000 0.00000000 0.00000000 0.11428571
3 0.14285714 0.05714286 0.05714286 0.00000000 0.00000000 0.25714286
4 0.02857143 0.14285714 0.11428571 0.05714286 0.00000000 0.34285714
5 0.02857143 0.08571429 0.05714286 0.00000000 0.02857143 0.20000000
6 0.00000000 0.00000000 0.05714286 0.00000000 0.02857143 0.08571429
  0.28571429 0.31428571 0.28571429 0.05714286 0.05714286 1.00000000

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">install.packages("labstatR")</span>
<span style="color: #558b2f;">require</span>(<span style="color: #689f38;">"labstatR"</span>)
bubbleplot(tc)
</pre>
</div>


<div class="figure">
<p><img src="bubbleplot.png" alt="bubbleplot.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-R">plot(ese112$Occupanti, ese112$Stanze, xlab=<span style="color: #689f38;">"Occupanti"</span>, ylab=<span style="color: #689f38;">"Stanze"</span>, main=<span style="color: #689f38;">"Scatterplot"</span>)
</pre>
</div>


<div class="figure">
<p><img src="scatterplot.png" alt="scatterplot.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-R">barplot(table(ese112), legend=T, col=c(<span style="color: #689f38;">"lightblue"</span>, <span style="color: #689f38;">"mistyrose"</span>, <span style="color: #689f38;">"lightcyan"</span>,
                                       <span style="color: #689f38;">"lavender"</span>, <span style="color: #689f38;">"cornsilk"</span>), xlab=<span style="color: #689f38;">"Occupanti"</span>,
        ylab=<span style="color: #689f38;">"Frequenze"</span>, args.legend=list(x=<span style="color: #689f38;">"topright"</span>, title=<span style="color: #689f38;">"Stanze"</span>))
</pre>
</div>


<div class="figure">
<p><img src="barplot.png" alt="barplot.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Covarianza</span>
cov(ese112$Stanze, ese112$Occupanti)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Correlazione</span>
cor(ese112$Stanze, ese112$Occupanti)
</pre>
</div>

<pre class="example">
Loading required package: labstatR
labstatR 1.0.9
Insieme di funzioni di supporto al volume
‚ÄòLaboratorio di Statistica con R‚Äô
Iacus-Masarotto, MacGraw-Hill Italia, 2006.
Si veda ‚Äòlibrary(help="labstatR")‚Äô per i comandi disponibili.
Nota: 'mean.a', 'mean.g' e 'hist.pf' sono state sostituite rispettivamente da 'meana', 'meang' e 'histpf'
null device 
          1
null device 
          1
null device 
          1
[1] 0.805042
[1] 0.5548666
</pre>

<p>
Esercizio 3:
</p>
<div class="org-src-container">
<pre class="src src-R">giocatori <span style="color: #558b2f;">&lt;-</span> read.table(<span style="color: #689f38;">"./Files/giocatori.txt"</span>,
            sep=<span style="color: #689f38;">";"</span>, header=<span style="color: #0097A7;">TRUE</span>)

<span style="color: #558b2f;">attach</span>(giocatori)

tc <span style="color: #558b2f;">&lt;-</span> table(role, years)
tc

tcc <span style="color: #558b2f;">&lt;-</span> cbind(tc, margin.table(tc, 1))
tcc

rbind(tcc, margin.table(tcc, 2))
</pre>
</div>

<pre class="example">
The following objects are masked from giocatori (pos = 3):

    birth_date, name, player_id, role, year_date, years
            years
role          18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33
  defence      3   6  34  47  47  58  51  50  75  69  59  65  60  52  47  40
  goalkeeper   2   6  15  22  29  23  20  18  18  21  13  15  11  15  16  16
  midfield    10  19  44  77  98  95 112  93  93 103 110 109  71  80  63  53
  striker      1   4   8  19  18  30  18  12  12  16  15  20   7  12  13   6
  unknown      1   1   6   5   0   3   2   0   0   0   0   0   0   0   0   0
            years
role          34  35  36  37  38  39  40  41  42  43  44  46
  defence     46  41  33  24  16   9   2   1   0   0   0   0
  goalkeeper  14   8  13  10   5   7   5   7   2   2   3   1
  midfield    55  40  33  19  17  12   7   0   3   0   0   0
  striker     13   7   6   2   2   2   1   1   0   0   0   0
  unknown      0   0   0   1   0   0   0   0   0   0   0   0
           18 19 20 21 22 23  24 25 26  27  28  29 30 31 32 33 34 35 36 37 38
defence     3  6 34 47 47 58  51 50 75  69  59  65 60 52 47 40 46 41 33 24 16
goalkeeper  2  6 15 22 29 23  20 18 18  21  13  15 11 15 16 16 14  8 13 10  5
midfield   10 19 44 77 98 95 112 93 93 103 110 109 71 80 63 53 55 40 33 19 17
striker     1  4  8 19 18 30  18 12 12  16  15  20  7 12 13  6 13  7  6  2  2
unknown     1  1  6  5  0  3   2  0  0   0   0   0  0  0  0  0  0  0  0  1  0
           39 40 41 42 43 44 46     
defence     9  2  1  0  0  0  0  935
goalkeeper  7  5  7  2  2  3  1  337
midfield   12  7  0  3  0  0  0 1416
striker     2  1  1  0  0  0  0  245
unknown     0  0  0  0  0  0  0   19
           18 19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34 35
defence     3  6  34  47  47  58  51  50  75  69  59  65  60  52  47  40  46 41
goalkeeper  2  6  15  22  29  23  20  18  18  21  13  15  11  15  16  16  14  8
midfield   10 19  44  77  98  95 112  93  93 103 110 109  71  80  63  53  55 40
striker     1  4   8  19  18  30  18  12  12  16  15  20   7  12  13   6  13  7
unknown     1  1   6   5   0   3   2   0   0   0   0   0   0   0   0   0   0  0
           17 36 107 170 192 209 203 173 198 209 197 209 149 159 139 115 128 96
           36 37 38 39 40 41 42 43 44 46     
defence    33 24 16  9  2  1  0  0  0  0  935
goalkeeper 13 10  5  7  5  7  2  2  3  1  337
midfield   33 19 17 12  7  0  3  0  0  0 1416
striker     6  2  2  2  1  1  0  0  0  0  245
unknown     0  1  0  0  0  0  0  0  0  0   19
           85 56 40 30 15  9  5  2  3  1 2952
</pre>

<div class="org-src-container">
<pre class="src src-R">barplot(tc, legend=T, col=c(<span style="color: #689f38;">"lightblue"</span>, <span style="color: #689f38;">"mistyrose"</span>, <span style="color: #689f38;">"lightcyan"</span>,
                                       <span style="color: #689f38;">"lavender"</span>, <span style="color: #689f38;">"cornsilk"</span>), xlab=<span style="color: #689f38;">"Et&#224;"</span>,
        ylab=<span style="color: #689f38;">"Frequenze"</span>, args.legend=list(x=<span style="color: #689f38;">"topright"</span>, title=<span style="color: #689f38;">"Ruoli"</span>))
</pre>
</div>


<div class="figure">
<p><img src="barplotgiocatori.png" alt="barplotgiocatori.png" />
</p>
</div>

<p>
Esempio 1.16
</p>
<div class="org-src-container">
<pre class="src src-R">ese116 <span style="color: #558b2f;">&lt;-</span> read.csv(<span style="color: #689f38;">"./Files/esempio1.16.csv"</span>, sep=<span style="color: #689f38;">";"</span>, header=<span style="color: #0097A7;">TRUE</span>)
ese116
</pre>
</div>

<pre class="example">
   CaricoPrimaLesione.x. CaricoRottura.y.
1                   2550             4650
2                   2900             4650
3                   3000             4700
4                   3000             4750
5                   3000             4775
6                   3000             4775
7                   3250             4800
8                   3250             4950
9                   3250             5050
10                  3600             5100
11                  4225             5100
12                  4650             5150
13                  4750             5175
14                  5175             5250
15                  5300             5300
</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Scarto quadratico medio x</span>
sqrt(mean((ese116$CaricoPrimaLesione.x. - mean(ese116$CaricoPrimaLesione.x.))^2))

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Scarto quadratico medio y</span>
sqrt(mean((ese116$CaricoRottura.y. - mean(ese116$CaricoRottura.y.))^2))

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Covarianza</span>
mean((ese116$CaricoPrimaLesione.x. - mean(ese116$CaricoPrimaLesione.x.)) *
     (ese116$CaricoRottura.y - mean(ese116$CaricoRottura.y)))

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Correlazione</span>
cov(ese116$CaricoPrimaLesione.x., ese116$CaricoRottura.y.)/
    (sd(ese116$CaricoPrimaLesione.x.) * sd(ese116$CaricoRottura.y.))
</pre>
</div>

<pre class="example">
[1] 876.8219
[1] 219.6968
[1] 177133.3
[1] 0.9195286

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Retta di regressione</span>
rr <span style="color: #558b2f;">&lt;-</span> lm(ese116$CaricoRottura.y.~ ese116$CaricoPrimaLesione.x.)
rr
</pre>
</div>

<pre class="example">

Call:
lm(formula = ese116$CaricoRottura.y. ~ ese116$CaricoPrimaLesione.x.)

Coefficients:
                 (Intercept)  ese116$CaricoPrimaLesione.x.  
                   4101.7456                        0.2304

</pre>

<div class="org-src-container">
<pre class="src src-R">plot(ese116$CaricoPrimaLesione.x., ese116$CaricoRottura.y., xlab=<span style="color: #689f38;">"Carico prima lesione"</span>, ylab=<span style="color: #689f38;">"Carico rottura"</span>)
abline(rr, col=<span style="color: #689f38;">"red"</span>, lwd=2)
</pre>
</div>


<div class="figure">
<p><img src="regressionelineare.png" alt="regressionelineare.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Retta di regressione (non lineare)</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">rrnl &lt;- lm(ese116$CaricoRottura.y.~1 + ese116$CaricoPrimaLesione.x. +</span>
<span style="color: #607d8b;">#           </span><span style="color: #607d8b;">l(ese116$CaricoPrimaLesione.x.^2))</span>
rrnl <span style="color: #558b2f;">&lt;-</span> lm(ese116$CaricoRottura.y~ poly(ese116$CaricoPrimaLesione.x., 2, raw=T))
rrnl
</pre>
</div>

<pre class="example">
null device 
          1

Call:
lm(formula = ese116$CaricoRottura.y ~ poly(ese116$CaricoPrimaLesione.x., 
    2, raw = T))

Coefficients:
                                    (Intercept)  
                                      2.893e+03  
poly(ese116$CaricoPrimaLesione.x., 2, raw = T)1  
                                      8.743e-01  
poly(ese116$CaricoPrimaLesione.x., 2, raw = T)2  
                                     -8.108e-05
</pre>

<div class="org-src-container">
<pre class="src src-R">plot(ese116$CaricoPrimaLesione.x., ese116$CaricoRottura.y., xlab=<span style="color: #689f38;">"Carico prima lesione"</span>, ylab=<span style="color: #689f38;">"Carico rottura"</span>)
lines(ese116$CaricoPrimaLesione.x., predict(rrnl), col=<span style="color: #689f38;">"green"</span>, lwd=2)
</pre>
</div>


<div class="figure">
<p><img src="regressionenonlineare.png" alt="regressionenonlineare.png" />
</p>
</div>

<p>
Esercizio 4:
</p>
<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(4, 8, 9, 12, 7)
y <span style="color: #558b2f;">&lt;-</span> c(17, 24, 25, 28, 26)

rr <span style="color: #558b2f;">&lt;-</span> lm(y~ x)
rr
</pre>
</div>

<pre class="example">

Call:
lm(formula = y ~ x)

Coefficients:
(Intercept)            x  
     13.882        1.265

</pre>

<div class="org-src-container">
<pre class="src src-R">plot(x, y, xlab=<span style="color: #689f38;">"x"</span>, ylab=<span style="color: #689f38;">"y"</span>)
abline(rr, col=<span style="color: #689f38;">"red"</span>, lwd=2)
</pre>
</div>


<div class="figure">
<p><img src="esregressionelineare.png" alt="esregressionelineare.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-org629deed" class="outline-4">
<h4 id="org629deed"><span class="section-number-4">3.2.2</span> Calcolo delle Probabilit√†</h4>
<div class="outline-text-4" id="text-3-2-2">
<p>
Lo spazio campione in R √® di solito rappresentato da un data frame:
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Per scaricare un pacchetto archiviato</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">require(devtools)</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">devtools::install_url('https://cran.r-project.org/src/contrib/Archive/prob/prob_1.0-0.tar.gz')</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Caricare il package prob</span>
<span style="color: #558b2f;">library</span>(prob)
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Creare spazio campione</span>
tosscoin
cards
rolldie
urnsamples

t <span style="color: #558b2f;">&lt;-</span> tosscoin(2)
t
</pre>
</div>

<pre class="example">
Carico il pacchetto richiesto: combinat

Attaching package: ‚Äòcombinat‚Äô

The following object is masked from ‚Äòpackage:utils‚Äô:

    combn

Carico il pacchetto richiesto: fAsianOptions
Carico il pacchetto richiesto: timeDate
Carico il pacchetto richiesto: timeSeries
Carico il pacchetto richiesto: fBasics
Carico il pacchetto richiesto: fOptions

Attaching package: ‚Äòprob‚Äô

The following objects are masked from ‚Äòpackage:base‚Äô:

    intersect, setdiff, union
function (times, makespace = FALSE) 
{
    temp &lt;- list()
    for (i in 1:times) {
        temp[[i]] &lt;- c("H", "T")
    }
    res &lt;- expand.grid(temp, KEEP.OUT.ATTRS = FALSE)
    names(res) &lt;- c(paste(rep("toss", times), 1:times, sep = ""))
    if (makespace) 
        res$probs &lt;- rep(1, 2^times)/2^times
    return(res)
}
&lt;bytecode: 0x555964114e90&gt;
&lt;environment: namespace:prob&gt;
function (jokers = FALSE, makespace = FALSE) 
{
    x &lt;- c(2:10, "J", "Q", "K", "A")
    y &lt;- c("Club", "Diamond", "Heart", "Spade")
    res &lt;- expand.grid(rank = x, suit = y)
    if (jokers) {
        levels(res$rank) &lt;- c(levels(res$rank), "Joker")
        res &lt;- rbind(res, data.frame(rank = c("Joker", "Joker"), 
            suit = c(NA, NA)))
    }
    if (makespace) {
        res$probs &lt;- rep(1, dim(res)[1])/dim(res)[1]
    }
    return(res)
}
&lt;bytecode: 0x555964121868&gt;
&lt;environment: namespace:prob&gt;
function (times, nsides = 6, makespace = FALSE) 
{
    temp = list()
    for (i in 1:times) {
        temp[[i]] &lt;- 1:nsides
    }
    res &lt;- expand.grid(temp, KEEP.OUT.ATTRS = FALSE)
    names(res) &lt;- c(paste(rep("X", times), 1:times, sep = ""))
    if (makespace) 
        res$probs &lt;- rep(1, nsides^times)/nsides^times
    return(res)
}
&lt;bytecode: 0x555964138170&gt;
&lt;environment: namespace:prob&gt;
function (x, ...) 
UseMethod("urnsamples")
&lt;bytecode: 0x555964089ce0&gt;
&lt;environment: namespace:prob&gt;
  toss1 toss2
1     H     H
2     T     H
3     H     T
4     T     T
</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Spazio campione del lancio di un dado bilanciato a 6 facce</span>
r <span style="color: #558b2f;">&lt;-</span> rolldie(1)
r
</pre>
</div>

<pre class="example">
  X1
1  1
2  2
3  3
4  4
5  5
6  6

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Spazio campione (primi 6 elementi) di un mazzo composto da 52 carte</span>
c <span style="color: #558b2f;">&lt;-</span> cards()
head(c)
</pre>
</div>

<pre class="example">
  rank suit
1    2 Club
2    3 Club
3    4 Club
4    5 Club
5    6 Club
6    7 Club

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Spazio campione di un'urna di 3 palline numerate da 1 a 3 con estrazione 2 palline</span>
u <span style="color: #558b2f;">&lt;-</span> urnsamples(1:3, size=2, replace=<span style="color: #0097A7;">TRUE</span>, ordered=<span style="color: #0097A7;">TRUE</span>)
u
</pre>
</div>

<pre class="example">
  X1 X2
1  1  1
2  2  1
3  3  1
4  1  2
5  2  2
6  3  2
7  1  3
8  2  3
9  3  3
</pre>

<div class="org-src-container">
<pre class="src src-R">urnsamples(1:3, size=2, replace=<span style="color: #0097A7;">FALSE</span>, ordered=<span style="color: #0097A7;">TRUE</span>)
</pre>
</div>

<pre class="example">
  X1 X2
1  1  2
2  2  1
3  1  3
4  3  1
5  2  3
6  3  2

</pre>

<div class="org-src-container">
<pre class="src src-R">urnsamples(1:3, size=2, replace=<span style="color: #0097A7;">FALSE</span>, ordered=<span style="color: #0097A7;">FALSE</span>)
</pre>
</div>

<pre class="example">
  X1 X2
1  1  2
2  1  3
3  2  3

</pre>

<div class="org-src-container">
<pre class="src src-R">urnsamples(1:3, size=2, replace=<span style="color: #0097A7;">TRUE</span>, ordered=<span style="color: #0097A7;">FALSE</span>)
</pre>
</div>

<pre class="example">
  X1 X2
1  1  1
2  1  2
3  1  3
4  2  2
5  2  3
6  3  3

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Accedere ad alcuni elementi</span>
u[c(2, 4),]
</pre>
</div>

<pre class="example">
  X1 X2
2  2  1
4  1  2

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Accedere a sottoinsiemi con funzione subset</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Estrarre solo le carte di seme Spade</span>
x <span style="color: #558b2f;">&lt;-</span> subset(c, suit==<span style="color: #689f38;">"Spade"</span>)
x
</pre>
</div>

<pre class="example">
   rank  suit
40    2 Spade
41    3 Spade
42    4 Spade
43    5 Spade
44    6 Spade
45    7 Spade
46    8 Spade
47    9 Spade
48   10 Spade
49    J Spade
50    Q Spade
51    K Spade
52    A Spade
</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">%in%</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Estrarre solo le carte 5 e 6</span>
subset(c, rank <span style="color: #558b2f;">%in%</span> 5:6)
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">subset(c, rank==6 | rank==5)</span>
</pre>
</div>

<pre class="example">
   rank    suit
4     5    Club
5     6    Club
17    5 Diamond
18    6 Diamond
30    5   Heart
31    6   Heart
43    5   Spade
44    6   Spade

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">isin()</span>
x1 <span style="color: #558b2f;">&lt;-</span> 1:10
y1 <span style="color: #558b2f;">&lt;-</span> 8:12
r1 <span style="color: #558b2f;">&lt;-</span> isin(x1, y1)

x2 <span style="color: #558b2f;">&lt;-</span> 1:10
y2=c(3, 3, 7)
r2 <span style="color: #558b2f;">&lt;-</span> isin(x2, y2)

x3 <span style="color: #558b2f;">&lt;-</span> 1:10
y3=c(3, 3, 7)
r3 <span style="color: #558b2f;">&lt;-</span> all(y3 <span style="color: #558b2f;">%in%</span> x3)

c(r1, r2, r3)
</pre>
</div>

<pre class="example">
[1] FALSE FALSE  TRUE

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Espressioni matematiche</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Somma delle facce dei 3 dadi maggiore di 14</span>
subset(rolldie(3), X1+X2+X3&gt;14)
</pre>
</div>

<pre class="example">
    X1 X2 X3
108  6  6  3
138  6  5  4
143  5  6  4
144  6  6  4
168  6  4  5
173  5  5  5
174  6  5  5
178  4  6  5
179  5  6  5
180  6  6  5
198  6  3  6
203  5  4  6
204  6  4  6
208  4  5  6
209  5  5  6
210  6  5  6
213  3  6  6
214  4  6  6
215  5  6  6
216  6  6  6
</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Somma delle due facce sia numero pari (%% modulo)</span>
subset(rolldie(2), ((X1+X2)<span style="color: #558b2f;">%%</span>2)==0)
</pre>
</div>

<pre class="example">
   X1 X2
1   1  1
3   3  1
5   5  1
8   2  2
10  4  2
12  6  2
13  1  3
15  3  3
17  5  3
20  2  4
22  4  4
24  6  4
25  1  5
27  3  5
29  5  5
32  2  6
34  4  6
36  6  6
</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Faccia del primo dado maggiore di quella del secondo</span>
subset(rolldie(2), (X1&gt;X2))
</pre>
</div>

<pre class="example">
   X1 X2
2   2  1
3   3  1
4   4  1
5   5  1
6   6  1
9   3  2
10  4  2
11  5  2
12  6  2
16  4  3
17  5  3
18  6  3
23  5  4
24  6  4
30  6  5
</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Insiemistica</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Unione di due subset A, B</span>
A <span style="color: #558b2f;">&lt;-</span> 0:3
B <span style="color: #558b2f;">&lt;-</span> 3:5
union(A, B)
</pre>
</div>

<pre class="example">
[1] 0 1 2 3 4 5

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Intersezione tra A, B</span>
intersect(A, B)
</pre>
</div>

<pre class="example">
[1] 3

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Differenza tra A, B</span>
setdiff(A, B)
</pre>
</div>

<pre class="example">
[1] 0 1 2

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">isrep(oggetto, valore, ripetizione)</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">verifica se in N compare 3 volte il valore red</span>
isrep(N, vals=<span style="color: #689f38;">"red"</span>, nrep=3)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Spazio di probabilit&#224;</span>
tosscoin(2, makespace=<span style="color: #0097A7;">TRUE</span>)
</pre>
</div>

<pre class="example">
  toss1 toss2 probs
1     H     H  0.25
2     T     H  0.25
3     H     T  0.25
4     T     T  0.25

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Hanno l'argomento makespace</span>
cards()
rolldie()
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Spazio di probabilit&#224;</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">probspace(spazio campione, probabilit&#224;)</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">analogo a rolldie(1, makespace=TRUE)</span>
outcome=rolldie(1)
p=rep(1/6, times=6)
probspace(outcome, probs=p)
</pre>
</div>

<pre class="example">
  X1     probs
1  1 0.1666667
2  2 0.1666667
3  3 0.1666667
4  4 0.1666667
5  5 0.1666667
6  6 0.1666667

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Moneta sbilanciata</span>
probspace(tosscoin(1), probs=c(0.3, 0.7))
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">iidspace(c("H", "T"), ntrials=1, probs=c(0.3, 0.7))</span>
</pre>
</div>

<pre class="example">
  toss1 probs
1     H   0.3
2     T   0.7

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Calcolare la probabilit&#224; di un evento</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Prob(spazio di probabilit&#224;, evento)</span>
S <span style="color: #558b2f;">&lt;-</span> cards(makespace=<span style="color: #0097A7;">TRUE</span>)
A <span style="color: #558b2f;">&lt;-</span> subset(S, suit==<span style="color: #689f38;">"Heart"</span>)
Prob(A)
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Prob(S, suit=="Heart")</span>
</pre>
</div>

<pre class="example">
[1] 0.25

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Permutazioni</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">factorial(n)</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Combinazioni semplici</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">choose(n, k)</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Numero di combinazioni di 8 elementi presi a gruppi di 2</span>
choose(8, 2)
</pre>
</div>

<pre class="example">
[1] 28

</pre>

<p>
Esercizio 1:
</p>
<ul class="org-ul">
<li>Supponiamo che 10 carte numerate da 1 a 10 vengano introdotte in un cappello e che una carta venga estratta a caso.
Vogliamo determinare:
<ul class="org-ul">
<li>Qual'√® la probabilit√† che la carta estratta sia 10?</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">carte <span style="color: #558b2f;">&lt;-</span> urnsamples(1:10, size=1)
prob <span style="color: #558b2f;">&lt;-</span> rep(1/10, times=10)
S <span style="color: #558b2f;">&lt;-</span> probspace(carte, probs=prob)
Prob(S, out==10)
</pre>
</div>

<pre class="example">
[1] 0.1

</pre>

<p>
Esercizio 3:
</p>
<ul class="org-ul">
<li>Si supponga che un'urna contenga 7 palline bianche e 5 nere. Supponiamo di estrarre 2 palline senza reimmissione.
Assumendo che ogni pallina possa essere estratta con egual probabilit√†,
<ul class="org-ul">
<li>Qual'√® la probabilit√† che entrambe le palline estratte siano bianche?</li>
</ul></li>
</ul>

<div class="org-src-container">
<pre class="src src-R">L=rep(c(<span style="color: #689f38;">"white"</span>, <span style="color: #689f38;">"black"</span>), times=c(7, 5))
urn <span style="color: #558b2f;">&lt;-</span> urnsamples(L, size=2, replace=<span style="color: #0097A7;">FALSE</span>, ordered=<span style="color: #0097A7;">FALSE</span>)
space_urn <span style="color: #558b2f;">&lt;-</span> probspace(urn)
Prob(space_urn, isrep(space_urn, <span style="color: #689f38;">"white"</span>, 2))
</pre>
</div>

<pre class="example">
[1] 0.3181818

</pre>

<p>
Esercizio 10:
</p>
<ul class="org-ul">
<li>Un'urna contiene 3 biglie bianche e 2 biglie nere:
<ol class="org-ol">
<li>Calcolare la probabilit√† che estraendo in successione (senza reimbussolamento) 3 biglie almeno una sia nera;</li>
<li>Ripetere il punto precedente supponendo il reimbussolamento.</li>
</ol></li>
</ul>

<p>
1:
</p>
<div class="org-src-container">
<pre class="src src-R">urn <span style="color: #558b2f;">&lt;-</span> urnsamples(c(<span style="color: #689f38;">"B"</span>, <span style="color: #689f38;">"B"</span>, <span style="color: #689f38;">"B"</span>, <span style="color: #689f38;">"N"</span>, <span style="color: #689f38;">"N"</span>), size=3, ordered=<span style="color: #0097A7;">TRUE</span>)
space_urn <span style="color: #558b2f;">&lt;-</span> probspace(urn)
Prob(space_urn, X1==<span style="color: #689f38;">"N"</span> | X2==<span style="color: #689f38;">"N"</span> | X3==<span style="color: #689f38;">"N"</span>)
</pre>
</div>

<pre class="example">
[1] 0.9

</pre>

<p>
2:
</p>
<div class="org-src-container">
<pre class="src src-R">urn <span style="color: #558b2f;">&lt;-</span> urnsamples(c(<span style="color: #689f38;">"B"</span>, <span style="color: #689f38;">"B"</span>, <span style="color: #689f38;">"B"</span>, <span style="color: #689f38;">"N"</span>, <span style="color: #689f38;">"N"</span>), size=3, ordered=<span style="color: #0097A7;">TRUE</span>, replace=<span style="color: #0097A7;">TRUE</span>)
space_urn <span style="color: #558b2f;">&lt;-</span> probspace(urn)
Prob(space_urn, X1==<span style="color: #689f38;">"N"</span> | X2==<span style="color: #689f38;">"N"</span> | X3==<span style="color: #689f38;">"N"</span>)
</pre>
</div>

<pre class="example">
[1] 0.784

</pre>

<p>
Esercizio 19:
</p>
<ul class="org-ul">
<li>Da un mazzo regolare di 52 carte vengono estratte contemporaneamente 3 carte.
<ul class="org-ul">
<li>Qual'√® la probabilit√† che le 3 carte estratte siano tutte di picche?</li>
</ul></li>
</ul>

<div class="org-src-container">
<pre class="src src-R">carte <span style="color: #558b2f;">&lt;-</span> urnsamples(cards(), 3, replace=<span style="color: #0097A7;">FALSE</span>, ordered=<span style="color: #0097A7;">FALSE</span>)
carte_space <span style="color: #558b2f;">&lt;-</span> probspace(carte)
Prob(carte_space, all(suit==<span style="color: #689f38;">"Club"</span>))
</pre>
</div>

<pre class="example">
[1] 0.01294118

</pre>

<p>
Esercizio 4:
</p>
<ul class="org-ul">
<li>Supponiamo che tre amici ad una festa gettino il proprio cappello sulla stessa sedia. Questi cappelli vengono
mescolati tra loro e, successivamente, i tre amici scelgono un cappello a caso.
<ul class="org-ul">
<li>Qual'√® la probabilit√† che nessuno di loro venga in possesso del proprio cappello?</li>
</ul></li>
</ul>

<div class="org-src-container">
<pre class="src src-R">cappelli <span style="color: #558b2f;">&lt;-</span> urnsamples(c(<span style="color: #689f38;">"Cappello 1"</span>, <span style="color: #689f38;">"Cappello 2"</span>, <span style="color: #689f38;">"Cappello 3"</span>), 3, replace=<span style="color: #0097A7;">FALSE</span>, ordered=<span style="color: #0097A7;">TRUE</span>)
cappelli_space <span style="color: #558b2f;">&lt;-</span> probspace(cappelli)
Prob(cappelli_space, X1!=<span style="color: #689f38;">"Cappello 1"</span> &amp; X2!=<span style="color: #689f38;">"Cappello 2"</span> &amp; X3!=<span style="color: #689f38;">"Cappello 3"</span>)
</pre>
</div>

<pre class="example">
[1] 0.3333333

</pre>

<p>
Esercizio 5:
</p>
<ul class="org-ul">
<li>Viene estratta una pallina da un'urna che contiene 4 palline numerate da 1 a 4. Siano \(E = \{1, 2\}, F = \{1, 3\}, G = \{1, 4\}\).
Calcolare:
<ol class="org-ol">
<li>\(P(E)\);</li>
<li>\(P(E \cap G)\);</li>
<li>\(P(F \cap G)\);</li>
<li>\(P(E \cap F \cap G)\).</li>
</ol></li>
</ul>

<p>
1:
</p>
<div class="org-src-container">
<pre class="src src-R">urna <span style="color: #558b2f;">&lt;-</span> urnsamples(1:4, 1)
urna_space <span style="color: #558b2f;">&lt;-</span> probspace(urna)
E <span style="color: #558b2f;">&lt;-</span> c(1, 2)
F <span style="color: #558b2f;">&lt;-</span> c(1, 3)
G <span style="color: #558b2f;">&lt;-</span> c(1, 4)
Prob(urna_space, out <span style="color: #558b2f;">%in%</span> E)
</pre>
</div>

<pre class="example">
[1] 0.5

</pre>

<p>
2:
</p>
<div class="org-src-container">
<pre class="src src-R">Prob(urna_space, out <span style="color: #558b2f;">%in%</span> intersect(E, G))
</pre>
</div>

<pre class="example">
[1] 0.25

</pre>

<p>
3:
</p>
<div class="org-src-container">
<pre class="src src-R">Prob(urna_space, out <span style="color: #558b2f;">%in%</span> intersect(F, G))
</pre>
</div>

<pre class="example">
[1] 0.25

</pre>

<p>
4:
</p>
<div class="org-src-container">
<pre class="src src-R">Prob(urna_space, out <span style="color: #558b2f;">%in%</span> intersect(E, F, G))
</pre>
</div>

<pre class="example">
[1] 0.25

</pre>

<p>
Esercizio 10:
</p>
<ul class="org-ul">
<li>Un'urna contiene 3 biglie bianche e 2 biglie nere.
<ol class="org-ol">
<li>Calcolare la probabilit√† che estraendo in successione (senza reimbussolamento) 3 biglie almeno una sia nera;</li>
<li>Ripetere il punto precedente supponendo il reimbussolamento.</li>
</ol></li>
</ul>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Un'urna contiene 'b' (ex: b=3) biglie bianche e n (ex:n=2) biglie nere. </span>


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">a) Calcolare la probabilit&#224; che estraendo in successione </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">(senza reimbussolamento) 3 biglie almeno una sia 'k' (ex: nera).</span>




<span style="color: #607d8b;"># </span><span style="color: #607d8b;">b) Ripetere il punto precedente supponendo il reimbussolamento.</span>



<span style="color: #607d8b;">#</span><span style="color: #607d8b;">---------------------------------------------------------</span>


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">importo la libreria prob</span>
<span style="color: #558b2f;">library</span>(prob)



<span style="color: #607d8b;"># </span><span style="color: #607d8b;">PARAMETRI </span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">b = num palline bianche nell'urna</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">n = num palline nere nell'urna</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">x = num di palline che estraiamo (ve volessimo aumentare il numero </span>
<span style="color: #607d8b;">#    </span><span style="color: #607d8b;">di palline estratte dovremmo modificare questo valore)</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">k = colore di cui vogliamo calcolare la probabilit&#224; di estrarre almeno una pallina</span>

b <span style="color: #558b2f;">&lt;-</span> 3
n <span style="color: #558b2f;">&lt;-</span> 2

x <span style="color: #558b2f;">&lt;-</span> 3
k <span style="color: #558b2f;">&lt;-</span> <span style="color: #689f38;">'n'</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">DATI</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">inizializzazione dell'array relativo all'urna</span>
y <span style="color: #558b2f;">&lt;-</span> <span style="color: #0097A7;">NULL</span>


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Cicli che inseriscono elementi nell'urna</span>

<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1 : b){
  y <span style="color: #558b2f;">&lt;-</span> append(y, <span style="color: #689f38;">"b"</span>);
}

<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1 : n){
  y <span style="color: #558b2f;">&lt;-</span> append(y, <span style="color: #689f38;">"n"</span>);
}




<span style="color: #607d8b;">#</span><span style="color: #607d8b;">------------------------------------------</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">PROCEDIMENTO:</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">a) Calcolatre la probabilit&#224; che estarendo in succesione (senza reimbussolamento)</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">x biglie almeno una sia k</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">CREAZIONE DELLO SPAZIO DELLE PROBABILIT&#224;</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">a-1) Creazione dello "Spazio degli eventi relativo all'urna"</span>

urn1 = urnsamples(y, x, replace = <span style="color: #0097A7;">FALSE</span>, ordered=<span style="color: #0097A7;">TRUE</span>)

numel = nrow(urn1)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">a-2) Generiamo un array indicante, in ogni posizione "i", la probabilit&#224; di </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">verificarsi dell'i-esimo evento dello "Spazio degli eventi" sopra definito.</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">numel = numero degli elementi nell'urna</span>

p <span style="color: #558b2f;">&lt;-</span> rep(1/numel, times=numel)


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">creazione dello spazio di probabilit&#224;</span>

space_urn1 = probspace(urn1, p)



<span style="color: #607d8b;">#</span><span style="color: #607d8b;">SOLUZIONE: Probabilit&#224; che entrambe le palline estratte siano del tipo "k" </span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">---&gt; se volessimo estrarre un numero di palline maggiore di 3 dovremmo aggiungere</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">nuove condizioni Xi == k come secondo argomento della funzione Prob.</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">ad esempio se volessimo estrarre 4 palline la funzione prob diventerebbe:</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">out &lt;- Prob(space_urn1, X1==k | X2 == k | X3 == k | X4==k)</span>

out <span style="color: #558b2f;">&lt;-</span> Prob(space_urn1, X1==k | X2 == k | X3 == k)








<span style="color: #607d8b;"># </span><span style="color: #607d8b;">b) Ripetere il punto precedente supponendo il reimbussolamento</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">CREAZIONE DELLO SPAZIO DELLE PROBABILIT&#224;</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">b-1) Creazione dello "Spazio degli eventi relativo all'urna"</span>

urn2 = urnsamples(y, x, replace = <span style="color: #0097A7;">TRUE</span>, ordered=<span style="color: #0097A7;">TRUE</span>)

numel2 = nrow(urn2)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">a-2) Generiamo un array indicante, in ogni posizione "i", la probabilit&#224; di </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">verificarsi dell'i-esimo evento dello "Spazio degli eventi" sopra definito.</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">numel = numero degli elementi nell'urna</span>

p2 <span style="color: #558b2f;">&lt;-</span> rep(1/numel2, times=numel2)


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">creazione dello spazio di probabilit&#224;</span>

space_urn2 = probspace(urn2, p2)



<span style="color: #607d8b;">#</span><span style="color: #607d8b;">SOLUZIONE: Probabilit&#224; che entrambe le palline estratte siano del tipo "k" </span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">---&gt; se volessimo estrarre un numero di palline maggiore di 3 dovremmo aggiungere</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">nuove condizioni Xi == k come secondo argomento della funzione Prob.</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">ad esempio se volessimo estrarre 4 palline la funzione prob diventerebbe:</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">out2 &lt;- Prob(space_urn2, X1==k | X2 == k | X3 == k | X4== k)</span>

out2 <span style="color: #558b2f;">&lt;-</span> Prob(space_urn2, X1==k | X2 == k | X3 == k)
</pre>
</div>
<p>
Esercizio 11:
</p>
<ul class="org-ul">
<li>Una squadra di calcio chiera ad ogni partita 1 portiere, 5 difensori e 5 attaccanti. La sociat√† "Aleas" sceglie
in modo casuale ciascun gruppo di giocatori tra 2 portieri, 8 difensori e 12 attaccanti disponibili.
<ol class="org-ol">
<li>Quante sono le formazioni possibili?</li>
<li>Se Roberto e Ronaldo sono due attaccanti, quante sono le formazioni in cui giocano entrambi?</li>
<li>Se Franco √® un difensore, quante sono le formazioni in cui gioca con l'attaccante Roberto?</li>
</ol></li>
</ul>

<p>
1:
</p>
<div class="org-src-container">
<pre class="src src-R">p <span style="color: #558b2f;">&lt;-</span> 2
d <span style="color: #558b2f;">&lt;-</span> 8
a <span style="color: #558b2f;">&lt;-</span> 12

cp <span style="color: #558b2f;">&lt;-</span> choose(p, 1)
cd <span style="color: #558b2f;">&lt;-</span> choose(d, 5)
da <span style="color: #558b2f;">&lt;-</span> choose(a, 5)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Numero di formazioni possibili</span>
cp*cd*da
</pre>
</div>

<pre class="example">
[1] 88704

</pre>

<p>
2:
</p>
<div class="org-src-container">
<pre class="src src-R">ca <span style="color: #558b2f;">&lt;-</span> choose(a-2, 3)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Numero di formazioni in cui giocano 2 attaccanti scelti</span>
cp*cd*ca 
</pre>
</div>

<pre class="example">
[1] 13440

</pre>

<p>
3:
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Ridondante: sono uguali</span>
ca <span style="color: #558b2f;">&lt;-</span> choose(a-1, 4)
cd <span style="color: #558b2f;">&lt;-</span> choose(d-1, 4)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Numero di formazioni in cui giocano 1 attaccante e un difensore scelto</span>
cp*cd*ca
</pre>
</div>

<pre class="example">
[1] 23100

</pre>

<p>
Esercizio 17:
</p>
<ul class="org-ul">
<li>Si supponga di estrarre contemporaneamente 13 carte da un mazzo di 52. Si calcoli la probabilit√† che le carte
estratte contengano:
<ol class="org-ol">
<li>Il 3 di cuori;</li>
<li>Una sola carta di quadri;</li>
<li>3 carte di picche e 5 carte di quadri;</li>
<li>Solo 3 figure.</li>
</ol></li>
</ul>

<p>
1:
</p>
<div class="org-src-container">
<pre class="src src-R">combTot <span style="color: #558b2f;">&lt;-</span> choose(52, 13)
comb3Cuori <span style="color: #558b2f;">&lt;-</span> choose(51, 12)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Probabilit&#224; di estrarre il 3 di cuori</span>
comb3Cuori/combTot
</pre>
</div>

<pre class="example">
[1] 0.25

</pre>

<p>
2:
</p>
<div class="org-src-container">
<pre class="src src-R">comb1CartaQuadri <span style="color: #558b2f;">&lt;-</span> 13*choose(39, 12)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Probabilit&#224; di estrarre solo una carta di quadri</span>
comb1CartaQuadri/combTot
</pre>
</div>

<pre class="example">
[1] 0.08006186

</pre>

<p>
3:
</p>
<div class="org-src-container">
<pre class="src src-R">comb3Picche5Quadri <span style="color: #558b2f;">&lt;-</span> choose(13, 3)*choose(13, 5)*choose(26, 5)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Probabilit&#224; di estrarre 3 carte di picche e 5 di quadri</span>
comb3Picche5Quadri/combTot
</pre>
</div>

<pre class="example">
[1] 0.038129

</pre>

<p>
4:
</p>
<div class="org-src-container">
<pre class="src src-R">comb3Figure <span style="color: #558b2f;">&lt;-</span> choose(12, 3)*choose(40, 10)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Probabilit&#224; di estrarre solo 3 figure</span>
comb3Figure/combTot
</pre>
</div>

<pre class="example">
[1] 0.2936714

</pre>
<p>
Esercizio 29:
</p>
<ul class="org-ul">
<li>Un mazzo di carte napoletane costituito da 40 carte suddivise in 4 classi (detti "semi") ciascuna contenente 10 carte
numerate. Supponiamo di estrarre "a caso" 8 carte da un tale mazzo.
<ol class="org-ol">
<li>Calcolare la probabilit√† di estrarre i 4 "sette";</li>
<li>Calcolare la probabilit√† di estrarre al pi√π 2 "sei";</li>
<li>Calcolare la probabilit√† di estrarre "4 sette" e al pi√π 2 "sei".</li>
</ol></li>
</ul>

<p>
1:
</p>
<div class="org-src-container">
<pre class="src src-R">combTot <span style="color: #558b2f;">&lt;-</span> choose(40, 8)
comb4Sette <span style="color: #558b2f;">&lt;-</span> choose(36, 4)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Probabilit&#224; di estrarre i 4 "sette"</span>
prob4Sette <span style="color: #558b2f;">&lt;-</span> comb4Sette/combTot
prob4Sette
</pre>
</div>

<pre class="example">
[1] 0.0007659481

</pre>

<p>
2:
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">combMax2Sei &lt;- choose(36, 8) + 4*choose(36, 7) + choose(4, 2)*choose(36, 6)</span>
combMin3Sei <span style="color: #558b2f;">&lt;-</span> choose(4, 3)*choose(36, 5) + choose(36, 4)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Probabilit&#224; di estrarre al pi&#249; 2 "sei"</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">combMax2Sei/combTot</span>
probMax2Sei <span style="color: #558b2f;">&lt;-</span> 1 - combMin3Sei/combTot
probMax2Sei
</pre>
</div>

<pre class="example">
[1] 0.9796258

</pre>

<p>
3:
</p>
<div class="org-src-container">
<pre class="src src-R">probTot4Carte <span style="color: #558b2f;">&lt;-</span> choose(36, 4)
combMin3Sei4Carte <span style="color: #558b2f;">&lt;-</span> choose(4, 3)*choose(36, 1) + 1
probMax2Sei4Carte <span style="color: #558b2f;">&lt;-</span> 1 - combMin3Sei4Carte/probTot4Carte

prob4SetteMax2Sei <span style="color: #558b2f;">&lt;-</span> prob4Sette*probMax2Sei4Carte
prob4SetteMax2Sei
</pre>
</div>

<pre class="example">
[1] 0.0007640627

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Esercizio 29</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Un mazzo di carte napoletane costituito da 40 carte suddivise in 4 classi (detti "semi") </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">ciascuna contenente 10 carte numerate. Supponiamo di estrarre "a caso" n carte da un tale mazzo.</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">a) Calcolare la probabilit&#224; di estrarre n7 (ex: n7=4) "sette".</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">b) Calcolare la probabilit&#224; di estrarre al pi&#249; n6 (ex: n6=2) "sei".</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">c) Calcolare la probabilit&#224; di estrarre "n7 sette" e al pi&#249; n6 "sei".</span>


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">---------------------------------------------------------</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">importo la libreria prob</span>
<span style="color: #558b2f;">library</span>(prob)


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">PARAMETRI </span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">n =  numero di carte estratte dal mazzo</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">n7 = numero di sette nel punto a) e c)</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">n6 = numero di sei nel punto b) e c)</span>


n <span style="color: #558b2f;">&lt;-</span> 8

n7 <span style="color: #558b2f;">&lt;-</span> 4

n6 <span style="color: #558b2f;">&lt;-</span> 2

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">-----------------------------</span>


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">SOLUZIONE</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">a) probabilit&#224; di estrarre n7 sette</span>


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">possibili combinazioni di n elementi estratti dal mazzo di 40 carte</span>

CasiPoss <span style="color: #558b2f;">&lt;-</span> choose(40,8)


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">numero di passibili combinazioni in cui n7 sono carte di "sette"</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">mentre (n - n7) carte non sono "sette"</span>

CasiFavA <span style="color: #558b2f;">&lt;-</span> choose(4, n7)*choose(40-4, n-n7) 

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">soluzione:</span>

out1 <span style="color: #558b2f;">&lt;-</span> CasiFavA/CasiPoss 


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">-------------------------------</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">b) Calcolare la probabilit&#224; di estrarre al pi&#249; n6 "sei"</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">p conterr&#224; la probabilit&#224; di estrarre "i" n6</span>

p <span style="color: #558b2f;">&lt;-</span> <span style="color: #0097A7;">NULL</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">per ogni i -&gt; p[i] = probabilit&#224; di estrarre 'i' carte di "sei"</span>
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 0:n6){
  p[i+1] = (choose(4,i)*choose(40-4, n-i) ) / CasiPoss
}

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">sommo le probabilit&#224; sopra generate</span>
out2 <span style="color: #558b2f;">&lt;-</span> sum(p)


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">-------------------------------</span>


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">c) Calcolare la probabilit&#224; di estrarre n7 "sette" e n6 "sei"</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">dobbiamo calcolare le probabilit&#224; congiunte:</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">per ogni i -&gt; pA[i] = probabilit&#224; di estrarre 'i' carte di "sei" e n7 carte di "sette"</span>
pA <span style="color: #558b2f;">&lt;-</span> <span style="color: #0097A7;">NULL</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">pA contiene, per ogni 'i', la probabilit&#224; di esatrarre n7 </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">carte di "sette" ed i carte di "sei"</span>

<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 0:n6){
  pA[i+1] = (choose(4,n7)*choose(4,i)*choose(40-4-4, n-i-n7) ) / CasiPoss
}

out3 <span style="color: #558b2f;">&lt;-</span> sum(pA)
</pre>
</div>
<p>
Esercizio 30:
</p>
<ul class="org-ul">
<li>Consideriamo un mazzo di 40 carte suddivise in 4 classi (detti "semi") ciascuna contenente 10 carte numerate
da 1 a 10. Ogni mano servita √® formata da 5 carte estratte dal mazzo.
<ol class="org-ol">
<li>Calcolare la probabilit√† di ricevere una mano che contiene i numeri 6, 7, 8, 9, 10;</li>
<li>Calcolare la probabilit√† di ricevere una mano che contiene 5 numeri distinti.</li>
</ol></li>
</ul>

<div class="org-src-container">
<pre class="src src-R">combTot <span style="color: #558b2f;">&lt;-</span> choose(40, 5)
comb5Numeri <span style="color: #558b2f;">&lt;-</span> 4^5

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
prob5Numeri <span style="color: #558b2f;">&lt;-</span> comb5Numeri/combTot
prob5Numeri

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
prob5NumeriDistinti <span style="color: #558b2f;">&lt;-</span> prob5Numeri*choose(10, 5)
prob5NumeriDistinti
</pre>
</div>

<pre class="example">
[1] 0.001556212
[1] 0.3921654

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Esercizio 29</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Consideriamo un mazzo di 40 carte suddivise in 4 classi (detti "semi") </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">ciascuna contenente 10 carte numerate da 1 a 10. Ogni mano servita &#232; </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">formata da n (ex: n=5) carte estratte dal mazzo.</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">a) Calcolare la probabilit&#224; di avere una mano formata dai numeri da </span>
<span style="color: #607d8b;">#    </span><span style="color: #607d8b;">1 a n (ex: con n=5 -&gt; mano="1","2", "3", "4", "5")</span>


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">b) Calcolare la probabilit&#224; di ricevere una mano che contiene n carte con numero</span>
<span style="color: #607d8b;">#    </span><span style="color: #607d8b;">diverso</span>


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">---------------------------------------------------------</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">importo la libreria prob</span>
<span style="color: #558b2f;">library</span>(prob)


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">PARAMETRI </span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">n = numero di carte con cui &#232; formata una mano</span>


n <span style="color: #558b2f;">&lt;-</span> 5

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">-----------------------------</span>


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">SOLUZIONE</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">a) Calcolare la probabilit&#224; di avere una mano formata dai numeri da </span>
<span style="color: #607d8b;">#    </span><span style="color: #607d8b;">1 a n (ex: con n=5 -&gt; mano="1","2", "3", "4", "5")</span>

out1 <span style="color: #558b2f;">&lt;-</span> 1;


<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> n : 1){
  
  <span style="color: #607d8b;"># </span><span style="color: #607d8b;">probabilit&#224; di estrarre una carta di tipo diverso sapendo che </span>
  <span style="color: #607d8b;"># </span><span style="color: #607d8b;">sono gi&#224; state estratte 'i' carte tra loro di tipo diverso </span>
  
  temp <span style="color: #558b2f;">&lt;-</span> (4*i/(40-(5-i)))
  
  <span style="color: #607d8b;"># </span><span style="color: #607d8b;">calcolo del risultato finale del punto a) in forma ricorsiva</span>
  
  out1 <span style="color: #558b2f;">&lt;-</span> out1 * temp

}


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">-------------------------------</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">b) Calcolare la probabilit&#224; di ricevere una mano che contiene n carte con numero</span>
<span style="color: #607d8b;">#    </span><span style="color: #607d8b;">diverso</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">numero di possibili combinazioni di 10 carte con numeri diversi per una mano di n elementi</span>
temp2 <span style="color: #558b2f;">&lt;-</span> choose(10,n)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">soluzione</span>
out2 <span style="color: #558b2f;">&lt;-</span> temp2*out1
</pre>
</div>

<p>
Esercizio 34:
</p>
<ul class="org-ul">
<li>Scegliamo 3 carte a caso fra un mazzo di 52 carte da gioco.
<ol class="org-ol">
<li>Qual'√® la probabilit√† che 2 siano assi e una sia un 10?</li>
<li>Qual'√® la probabilit√† che almeno 2 siano figure?</li>
<li>Qual'√® la probabilit√† che almeno 2 siano figure e nessuna sia un asso?</li>
</ol></li>
</ul>

<div class="org-src-container">
<pre class="src src-R">combTot <span style="color: #558b2f;">&lt;-</span> choose(52, 3)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
comb2Assi1Dieci <span style="color: #558b2f;">&lt;-</span> choose(4, 2)*4
prob2Assi1Dieci <span style="color: #558b2f;">&lt;-</span> comb2Assi1Dieci/combTot
prob2Assi1Dieci

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
combMin2Figure <span style="color: #558b2f;">&lt;-</span> choose(12, 2)*40 + choose(12, 3)
probMin2Figure <span style="color: #558b2f;">&lt;-</span> combMin2Figure/combTot
probMin2Figure

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>

comb2Figure1Asso <span style="color: #558b2f;">&lt;-</span> choose(12, 2)*4
probMin2Figure1Asso <span style="color: #558b2f;">&lt;-</span>probMin2Figure - comb2Figure1Asso/combTot
probMin2Figure1Asso
</pre>
</div>

<pre class="example">
[1] 0.001085973
[1] 0.1294118
[1] 0.1174661

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Esercizio 34</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Scegliamo tre carte a caso fra un mazzo di 52 carte da gioco </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">(divise in quattro semi con ciascuno tre figure: fante, donna, re).</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">1) Qual'&#232; la probabilit&#224; che nA siano assi e n10 siano dieci?</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">2) Qual'&#232; la probabilit&#224; che almeno nF1 siano figure?</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">3) Qual'&#232; la probabilit&#224; che almeno nF2 siano figure e nessuno sia asso</span>



<span style="color: #607d8b;">#</span><span style="color: #607d8b;">---------------------------------------------------------</span>


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">importo la libreria prob</span>
<span style="color: #558b2f;">library</span>(prob)



<span style="color: #607d8b;"># </span><span style="color: #607d8b;">PARAMETRI </span>


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">nA = numero di assi che si desidera estrarre nel primo punto</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">n10 = numero di 10 che si desidera estrarre nel primo punto</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">totEstr = numero totale di carte che si vuole estrarre</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">nF1 = numero minimo di figure che si vogliono estrarre nel punto 2</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">nF2 = numero minimo di figure che si vogliono estrarre nel punto 3</span>

nA <span style="color: #558b2f;">&lt;-</span> 2
n10 <span style="color: #558b2f;">&lt;-</span> 1
totEstr <span style="color: #558b2f;">&lt;-</span> 3


nF1 <span style="color: #558b2f;">&lt;-</span> 2

nF2 <span style="color: #558b2f;">&lt;-</span> 2

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">------------------------------------------</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">SOLUZIONE</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">1) Qual'&#232; la probabilit&#224; che nA siano assi e n10 siano dieci?</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">combinazioni possibili di estrazione di nA assi</span>
temp1 <span style="color: #558b2f;">&lt;-</span> choose(4,nA)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">combinazioni possibili di estrazione di n10 dieci</span>
temp2 <span style="color: #558b2f;">&lt;-</span> choose(4,n10)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">casi possibili</span>

den <span style="color: #558b2f;">&lt;-</span> choose(52,totEstr)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">soluzione:</span>

out <span style="color: #558b2f;">&lt;-</span> (temp1*temp2)/den


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">------------------------------</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">2) Qual'&#232; la probabilit&#224; che almeno nF1 siano figure?</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">numero di possibili combinazioni di estrazioni di almeno nF1 figure</span>
num2 <span style="color: #558b2f;">&lt;-</span> 0

<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> totEstr : nF1){
  num2 <span style="color: #558b2f;">&lt;-</span> num2 + choose(12,i)*choose(40, totEstr-i)
}

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">casi possibili</span>
den <span style="color: #558b2f;">&lt;-</span> choose(52,totEstr)


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">soluzione:</span>

out2 <span style="color: #558b2f;">&lt;-</span> num2/den

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">------------------------------</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">3) Qual'&#232; la probabilit&#224; che almeno nF2 siano figure e nessuno sia asso</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">numero di possibili combinazioni di estrazioni di almeno nF2 figure</span>
num3 <span style="color: #558b2f;">&lt;-</span> 0

<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> totEstr : nF2){
  num3 <span style="color: #558b2f;">&lt;-</span> num3 + choose(12,i)*choose(36, totEstr-i)
}

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">casi possibili</span>
den <span style="color: #558b2f;">&lt;-</span> choose(52,totEstr)


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">soluzione:</span>

out3 <span style="color: #558b2f;">&lt;-</span> num3/den
</pre>
</div>

<p>
Probabilit√† condizionata:
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Prob(spazio di probabilit&#224;, evento, osservazione)</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Calcolare la probabilit&#224; che lanciando 2 dadi esca la stess faccia</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">dato che la loro somma &#232; maggiore o uguale a 8</span>
S=rolldie(2, makespace=<span style="color: #0097A7;">TRUE</span>)
Prob(S, X1==X2, given=(X1+X2&gt;=8))
</pre>
</div>

<pre class="example">
[1] 0.2

</pre>

<p>
Esercizio 1:
</p>
<ul class="org-ul">
<li>Supponiamo che 10 carte numerate da 1 a 10 vengano introdotte in un cappello e che una carta venga estratta a caso.
<ul class="org-ul">
<li>Sapendo che la carta estratta √® maggiore di 4, qual'√® la probabilit√† che sia 10?</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">carte <span style="color: #558b2f;">&lt;-</span> urnsamples(1:10, size=1)
prob <span style="color: #558b2f;">&lt;-</span> rep(1/10, times=10)
S <span style="color: #558b2f;">&lt;-</span> probspace(carte, probs=prob)
Prob(S, out==10, given=out&gt;4)
</pre>
</div>

<pre class="example">
[1] 0.1666667

</pre>

<p>
Esercizio 2:
</p>
<ul class="org-ul">
<li>In una famiglia vi sono 2 figli. Qual'√® la probabilit√† che entrambi siano maschi dato che almeno uno di loro √® maschio?</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">figli <span style="color: #558b2f;">&lt;-</span> urnsamples(c(<span style="color: #689f38;">"M"</span>, <span style="color: #689f38;">"F"</span>), size=2, replace=T, ordered=T)
urn_figli <span style="color: #558b2f;">&lt;-</span> probspace(figli)
Prob(urn_figli, X1==<span style="color: #689f38;">"M"</span> &amp; X2==<span style="color: #689f38;">"M"</span>, given=(X1==<span style="color: #689f38;">"M"</span> | X2==<span style="color: #689f38;">"M"</span>))
</pre>
</div>

<pre class="example">
[1] 0.3333333

</pre>

<p>
Formula del prodotto:
</p>
<ul class="org-ul">
<li>Esempio 2.10:
<ul class="org-ul">
<li>Consideriamo un'urna contenente 2 palline Blu, 1 Rossa e 1 Verde e supponiamo di effettuare 3 estrazioni, lasciando fuori
dall'urna le palline gi√† estratte. Si vuole calcolare la probabilit√† che:
<ol class="org-ol">
<li>La prima volta venga estratta una pallina blu;</li>
<li>La seconda volta venga estratta la pallina rossa;</li>
<li>La terza volta venga estratta la pallina verde.</li>
</ol></li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">urn <span style="color: #558b2f;">&lt;-</span> urnsamples(c(<span style="color: #689f38;">"R"</span>, <span style="color: #689f38;">"B"</span>, <span style="color: #689f38;">"B"</span>, <span style="color: #689f38;">"V"</span>), 3, ordered=T)
urn_sample <span style="color: #558b2f;">&lt;-</span> probspace(urn)
Prob(urn_sample, X1==<span style="color: #689f38;">"B"</span> &amp; X2==<span style="color: #689f38;">"R"</span> &amp; X3==<span style="color: #689f38;">"V"</span>)
</pre>
</div>

<pre class="example">
[1] 0.08333333

</pre>

<p>
Formula delle probabilit√† totali:
</p>
<ul class="org-ul">
<li>Esempio 2.10.1:
<ul class="org-ul">
<li>Una compagnia di assicurazioni ritiene che i guidatori appartengano a due categorie. Facili agli incidenti e non facili.
Le statistiche dicono che un guidatore f.a.i. ha probabilit√† 0.4 di fare un incidente nell'anno mentre uno non
f.a.i. ha probabilit√† 0.2. Supponiamo che il 30% dei guidatori sia f.a.i., qual'√® la probabilit√† che un nuovo
guidatore abbia un incidente nell'anno?</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">prior <span style="color: #558b2f;">&lt;-</span> c(0.3, 0.7)
inc <span style="color: #558b2f;">&lt;-</span> c(0.4, 0.2)
sum(prior*inc)
</pre>
</div>

<pre class="example">
[1] 0.26

</pre>

<p>
Formula di Bates:
</p>
<ul class="org-ul">
<li>Esempio 2.11:
<ul class="org-ul">
<li>Supponiamo di aver effettuato un'indagine sugli individui in et√† lavorativa abitanti in un quartiere di una data
citt√† italiana, e di aver riscontrato che il 40% di tali individui ha la licenza elementare o media, il 50% ha un
titolo di scuola superiore mentre il restante 10% √® laureato. Una seconda indagine ha permesso di rilevare i tassi
di disoccupazione tra i tre gruppi di individui che risultano essere rispettivamente: 15%, 5% e 10%.
<ul class="org-ul">
<li>Supponiamo che l'individuo estratto √® disoccupato, qual'√® la probabilit√† che esso sia laureato?</li>
</ul></li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">Occ <span style="color: #558b2f;">&lt;-</span> c(0.4, 0.5, 0.1)
Dis <span style="color: #558b2f;">&lt;-</span> c(0.15, 0.05, 0.1)
num <span style="color: #558b2f;">&lt;-</span> Occ*Dis
Ptot <span style="color: #558b2f;">&lt;-</span> sum(num)
num/Ptot
</pre>
</div>

<pre class="example">
[1] 0.6315789 0.2631579 0.1052632

</pre>

<p>
Esercizio 1:
</p>
<ul class="org-ul">
<li>Supponiamo che 10 carte numerate da 1 a 10 vengano introdotte in un cappello e che una carta venga estratta a caso.
Vogliamo determinare:
<ol class="org-ol">
<li>Qual'√® la probabilit√† che la carta estratta sia 10?</li>
<li>Sapendo che la carta estratta √® maggiore di 4, qual'√® la probabilit√† che sia un 10?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">carte <span style="color: #558b2f;">&lt;-</span> urnsamples(1:10, 1)
carte_space <span style="color: #558b2f;">&lt;-</span> probspace(carte)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
Prob(carte_space, out==10)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
Prob(carte_space, out==10, given=out&gt;4)
</pre>
</div>

<pre class="example">
[1] 0.1
[1] 0.1666667

</pre>

<p>
Esercizio 2:
</p>
<ul class="org-ul">
<li>In una famiglia vi sono 2 figli. Qual'√® la probabilit√† che entrambi siano maschi dato che almeno uno di loro √® maschio?</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Esercizio 2: In una famiglia vi sono 2 figli. </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Qual &#232; la probabilit&#224; che entrambi siano 'k' (ad esempio 'maschi') </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">dato che almeno uno di loro &#232; 'k'? </span>


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">---------------------------------------------------------</span>


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">importo la libreria prob</span>
<span style="color: #558b2f;">library</span>(prob)



<span style="color: #607d8b;"># </span><span style="color: #607d8b;">PARAMETRI INPUT</span>
n <span style="color: #558b2f;">&lt;-</span> 2

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">numero di figli</span>
k <span style="color: #558b2f;">&lt;-</span> <span style="color: #689f38;">'m'</span> <span style="color: #607d8b;"># </span><span style="color: #607d8b;">pu&#242; essere 'm' o 'f'</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">DATI</span>


figli <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">'m'</span>, <span style="color: #689f38;">'f'</span>)




<span style="color: #607d8b;">#</span><span style="color: #607d8b;">------------------------------------------</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">PROCEDIMENTO:</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">CREAZIONE DELLO SPAZIO DELLE PROBABILIT&#224;</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">1) creazione dello spazio di probabilit&#224; relativo alle possibili </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">combinazioni di figli all'interno della famiglia</span>


space=iidspace(figli, n, probs = <span style="color: #0097A7;">NULL</span>)




<span style="color: #607d8b;">#</span><span style="color: #607d8b;">SOLUZIONE: Probabilit&#224; che entrambi i figli siano 'k' dato che almeno uno &#232; 'k'</span>

out <span style="color: #558b2f;">&lt;-</span> Prob(space, X1==X2, (X1==k| X2==k))


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">OSSERVAZIONE: se volessimo adattare il problema ad numero 'n' di figli</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">dovremmo modificare:</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">1) il parametro n della parte iniziale </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">2) l'istruzione per calcolare la soluzione. Esattamente dovremmo </span>
<span style="color: #607d8b;">#   </span><span style="color: #607d8b;">estendere le due condizioni a "n" Xi.</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Facciamo un esempio: se al posto di 2 volessi eseguire il problema con 3 figli</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">la soluzione dovrebbe essere calcolata facendo:</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">out &lt;- Prob(space, (X1==X2 &amp; X2==X3), (X1==k| X2==k | X3==k))</span>
</pre>
</div>

<p>
Esercizio 3:
</p>
<ul class="org-ul">
<li>Si supponga che un'urna contenga 7 palline bianche e 5 nere. Supponiamo di estrarre 2 palline senza reimmissione.
Assumendo che ogni pallina possa essere estratta con egual probabilit√†,
<ul class="org-ul">
<li>Qual'√® la probabilit√† che entrambe le palline estratte siano bianche?</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">palline <span style="color: #558b2f;">&lt;-</span> <span style="color: #0097A7;">NULL</span>
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1:7) {
  palline <span style="color: #558b2f;">&lt;-</span> append(palline, <span style="color: #689f38;">"B"</span>)
}
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1:5) {
  palline <span style="color: #558b2f;">&lt;-</span> append(palline, <span style="color: #689f38;">"N"</span>)
}
urna <span style="color: #558b2f;">&lt;-</span> urnsamples(palline, 2, replace=<span style="color: #0097A7;">FALSE</span>, ordered=<span style="color: #0097A7;">FALSE</span>)
urna_space <span style="color: #558b2f;">&lt;-</span> probspace(urna)

Prob(urna_space, X1==<span style="color: #689f38;">"B"</span> &amp; X2==<span style="color: #689f38;">"B"</span>)
</pre>
</div>

<pre class="example">
[1] 0.3181818

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Esercizio 3: Si supponga che un'urna contenga 7  palline  bianche  e  5  nere.  </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Supponiamo  di  estrarre  due  palline  senza reimmissione. </span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Assumendo che ogni pallina possa essere estratta con egual probabilit&#224;, </span>


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">       Qual &#232; la probabilit&#224; che entrambe le palline estratte siano del tipo "k" (ex: siano bianche)?</span>


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">---------------------------------------------------------</span>


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">importo la libreria prob</span>
<span style="color: #558b2f;">library</span>(prob)



<span style="color: #607d8b;"># </span><span style="color: #607d8b;">PARAMETRI </span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">b = num palline bianche nell'urna</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">n = num palline nere nell'urna</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">k = colore di cui vogliamo calcolare la probabilit&#224; di estrarre palline</span>

b <span style="color: #558b2f;">&lt;-</span> 7
n <span style="color: #558b2f;">&lt;-</span> 5

k <span style="color: #558b2f;">&lt;-</span> <span style="color: #689f38;">"b"</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">DATI</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">inizializzazione dell'array relativo all'urna</span>
y <span style="color: #558b2f;">&lt;-</span> <span style="color: #0097A7;">NULL</span>


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Cicli che inseriscono elementi nell'urna</span>

<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1 : b){
  y <span style="color: #558b2f;">&lt;-</span> append(y, <span style="color: #689f38;">"b"</span>);
}

<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1 : n){
  y <span style="color: #558b2f;">&lt;-</span> append(y, <span style="color: #689f38;">"n"</span>);
}


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">calcolo numero elementi nell'urna</span>
numel = nsamp(b+n, 2, replace=<span style="color: #0097A7;">FALSE</span>)


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">------------------------------------------</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">PROCEDIMENTO:</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">CREAZIONE DELLO SPAZIO DELLE PROBABILIT&#224;</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">1) Creazione dello "Spazio degli eventi relativo all'urna"</span>

urn = urnsamples(y, 2, replace = <span style="color: #0097A7;">FALSE</span>, ordered=<span style="color: #0097A7;">FALSE</span>)


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">2) Generiamo un array indicante, in ogni posizione "i", la probabilit&#224; di </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">verificarsi dell'i-esimo evento dello "Spazio degli eventi" sopra definito.</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">numel = numero degli elementi nell'urna</span>

p <span style="color: #558b2f;">&lt;-</span> rep(1/numel, times=numel)



<span style="color: #607d8b;"># </span><span style="color: #607d8b;">creazione dello spazio di probabilit&#224;</span>

space_urn = probspace(urn, p)



<span style="color: #607d8b;">#</span><span style="color: #607d8b;">SOLUZIONE: Probabilit&#224; che entrambe le palline estratte siano del tipo "k" </span>

out = Prob(space_urn, X1==X2 &amp; X1==k)
</pre>
</div>
<p>
Esercizio 6:
</p>
<ul class="org-ul">
<li>Si considerino 2 urne. La prima contiene 2 palline bianche e 7 nere, mentre la seconda contiene 5 palline bianche
e 6 nere. Lanciamo una moneta e se otteniamo testa estraiamo una palline dalla prima urna, altrimenti
estraiamo una pallina della seconda urna.
<ul class="org-ul">
<li>Qual'√® la probabilit√† che il lancio della moneta sia stato testa dato che la pallina estratta √® bianca?</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">urna1 <span style="color: #558b2f;">&lt;-</span> <span style="color: #0097A7;">NULL</span>
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1:2) {
  urna1 <span style="color: #558b2f;">&lt;-</span> append(urna1, <span style="color: #689f38;">"b"</span>)
}
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1:7) {
  urna1 <span style="color: #558b2f;">&lt;-</span> append(urna1, <span style="color: #689f38;">"n"</span>)
}
urna2 <span style="color: #558b2f;">&lt;-</span> <span style="color: #0097A7;">NULL</span>
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1:5) {
  urna2 <span style="color: #558b2f;">&lt;-</span> append(urna2, <span style="color: #689f38;">"b"</span>)
}
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1:6) {
  urna2 <span style="color: #558b2f;">&lt;-</span> append(urna2, <span style="color: #689f38;">"n"</span>)
}

urna_space1 <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(urna1, 1))
urna_space2 <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(urna2, 1))
pBH <span style="color: #558b2f;">&lt;-</span> Prob(urna_space1, out==<span style="color: #689f38;">"b"</span>)
pBT <span style="color: #558b2f;">&lt;-</span> Prob(urna_space2, out==<span style="color: #689f38;">"b"</span>)

moneta <span style="color: #558b2f;">&lt;-</span> c(0.5, 0.5)
pBHT <span style="color: #558b2f;">&lt;-</span> c(pBH, pBT)
pB <span style="color: #558b2f;">&lt;-</span> moneta*pBHT
pTot <span style="color: #558b2f;">&lt;-</span> sum(moneta*pBHT)

pHeadGivenBianca <span style="color: #558b2f;">&lt;-</span> pB/pTot
pHeadGivenBianca[1]
</pre>
</div>

<pre class="example">
[1] 0.3283582

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Esercizio 6: </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Si considerino due urne. La prima contiene b1 (ex: b1=2) palline bianche e n1 (ex:n1=7) nere, </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">mentre la seconda contiene b2 (ex: b2=5) palline bianche e (ex: n2=6) nere. </span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Lanciamo una moneta e se otteniamo testa estraiamo una pallina dalla prima urna, </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">altrimenti estraiamo una pallina della seconda urna. </span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Qual &#232; la probabilit&#224; che il lancio della moneta sia stato l (ex: l=testa) dato che </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">la pallina estratta &#232; k (ex: k=bianca)?</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">---------------------------------------------------------</span>


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">importo la libreria prob</span>
<span style="color: #558b2f;">library</span>(prob)



<span style="color: #607d8b;"># </span><span style="color: #607d8b;">PARAMETRI </span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">b1 = numero palline bianche nella prima urna</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">n1 = numero palline nere nella prima urna</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">b2 = numero palline bianche nella seconda urna</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">n2 = numero palline nere nella seconda urna</span>



b1 <span style="color: #558b2f;">&lt;-</span> 2
n1 <span style="color: #558b2f;">&lt;-</span> 7

b2 <span style="color: #558b2f;">&lt;-</span> 5
n2 <span style="color: #558b2f;">&lt;-</span> 6


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">"probabilit&#224; che il lancio sia stato l ..."</span>

l <span style="color: #558b2f;">&lt;-</span> <span style="color: #689f38;">'T'</span> <span style="color: #607d8b;">#</span><span style="color: #607d8b;">l pu&#242; assumere valore T (testa) o H (croce)</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">"...sapendo che la palllina estratta &#232; k"</span>

k <span style="color: #558b2f;">&lt;-</span> <span style="color: #689f38;">'b'</span> <span style="color: #607d8b;">#</span><span style="color: #607d8b;">pu&#242; assumere valore 'b' (bianco) o 'n' (nero)</span>


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">calcolo del risultato inverso della moneta rispetto a quello scelto</span>
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">nell'esercizio. (verr&#224; usato per lo svolgimento)</span>

<span style="color: #00796b;">if</span> (l ==<span style="color: #689f38;">'T'</span>)
  notl <span style="color: #558b2f;">&lt;-</span> <span style="color: #689f38;">'H'</span>
<span style="color: #00796b;">else</span>
  notl <span style="color: #558b2f;">&lt;-</span> <span style="color: #689f38;">'T'</span>



<span style="color: #607d8b;">#</span><span style="color: #607d8b;">DATI</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">definizione della prima urna</span>


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">inizializzazione dell'array relativo alla prima urna</span>
urn1 <span style="color: #558b2f;">&lt;-</span> <span style="color: #0097A7;">NULL</span>


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Cicli che inseriscono elementi nell'urna</span>

<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1 : b1){
  urn1 <span style="color: #558b2f;">&lt;-</span> append(urn1, <span style="color: #689f38;">"b"</span>);
}

<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1 : n1){
  urn1 <span style="color: #558b2f;">&lt;-</span> append(urn1, <span style="color: #689f38;">"n"</span>);
}




<span style="color: #607d8b;"># </span><span style="color: #607d8b;">definizione della seconda urna</span>


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">inizializzazione dell'array relativo alla seconda urna</span>
urn2 <span style="color: #558b2f;">&lt;-</span> <span style="color: #0097A7;">NULL</span>


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Cicli che inseriscono elementi nell'urna</span>

<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1 : b2){
  urn2 <span style="color: #558b2f;">&lt;-</span> append(urn2, <span style="color: #689f38;">"b"</span>);
}

<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1 : n2){
  urn2 <span style="color: #558b2f;">&lt;-</span> append(urn2, <span style="color: #689f38;">"n"</span>);
}

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">numel1 contiene il numero di elementi della prima urna</span>
numel1 = length(urn1)


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">numel2 contiene il numero di elementi della seconda urna</span>
numel2 = length(urn2)



<span style="color: #607d8b;">#</span><span style="color: #607d8b;">------------------------------------------</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">PROCEDIMENTO:</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">CREAZIONE DELLO SPAZIO DELLE PROBABILIT&#224;</span>

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">1) Generiamo un array indicante, in ogni posizione "i", la probabilit&#224; di </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">verificarsi dell'i-esimo evento dello "Spazio degli eventi" (urn1) sopra definito.</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">numel1 = numero degli elementi nella prima urna</span>

p1 <span style="color: #558b2f;">&lt;-</span> rep(1/numel1, times=numel1)


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">2) creazione dello spazio di probabilit&#224; relativo alla prima urna</span>

space_urn1 = probspace(urn1, p1)


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">3) Generiamo un array indicante, in ogni posizione "i", la probabilit&#224; di </span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">verificarsi dell'i-esimo evento dello "Spazio degli eventi" (urn2) sopra definito.</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">numel2 = numero degli elementi nella prima urna</span>

p2 <span style="color: #558b2f;">&lt;-</span> rep(1/numel2, times=numel2)


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">4) creazione dello spazio di probabilit&#224; relativo alla prima urna</span>

space_urn2 = probspace(urn2, p2)


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">5) creazione dello spazio di probabilit&#224; relativo al lancio della moneta</span>

coin = tosscoin(1, makespace=<span style="color: #0097A7;">TRUE</span>)





<span style="color: #607d8b;">#</span><span style="color: #607d8b;">SOLUZIONE: </span>


<span style="color: #607d8b;"># </span><span style="color: #607d8b;">(faremo uso della formula di Bayes)</span>



<span style="color: #607d8b;"># </span><span style="color: #607d8b;">probabilit&#224; al numeratore </span>


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">probabilit&#224; che la pallina sia k (ex: bianca) se esce l (ex: testa)</span>

PBT <span style="color: #558b2f;">&lt;-</span> Prob(space_urn1, x == k)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">probabilit&#224; che esca t</span>

PT <span style="color: #558b2f;">&lt;-</span> Prob(coin,toss1 == l)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">probabilit&#224; numeratore</span>

num <span style="color: #558b2f;">&lt;-</span> PBT * PT





<span style="color: #607d8b;"># </span><span style="color: #607d8b;">probabilit&#224; al denominatore</span>


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">probabilit&#224; che la pallina sia k (ex: bianca) se esce notl (ex: se l = T -&gt; notl = H)</span>

PBC <span style="color: #558b2f;">&lt;-</span> Prob(space_urn2, x == k)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">probabilit&#224; che esca croce</span>

PC <span style="color: #558b2f;">&lt;-</span> Prob(coin,toss1==notl)


<span style="color: #607d8b;">#</span><span style="color: #607d8b;">probabilit&#224; denominatore</span>

den <span style="color: #558b2f;">&lt;-</span> PBT * PT + PBC * PC






<span style="color: #607d8b;"># </span><span style="color: #607d8b;">applicazione della formula di Bayes</span>

out = num / den
</pre>
</div>
<p>
Esercizio 7:
</p>
<ul class="org-ul">
<li>Uno studente risponde ad un quiz multivalore conoscendo la risposta o selezionando a caso. Si indichi con "p" la probabilit√†
che lo studente conosca la risposta (ha studiato). Supponiamo che uno studente che non conosca la risposta indovini con
probabilit√† \(1/m\), dove "m" √® il numero di risposte possibili.
<ul class="org-ul">
<li>Qual'√® la probabilit√† che lo studente conoscesse la risposta dato che ha risposto correttamente?</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Numero di risposte possibili</span>
m <span style="color: #558b2f;">&lt;-</span> 4
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Probabilit&#224; che conosca la risposta</span>
p <span style="color: #558b2f;">&lt;-</span> 0.8

conoscenza <span style="color: #558b2f;">&lt;-</span> c(p, 1-p)
corretto <span style="color: #558b2f;">&lt;-</span> c(1, 1/m)

comb <span style="color: #558b2f;">&lt;-</span> conoscenza*corretto
pTot <span style="color: #558b2f;">&lt;-</span> sum(comb)

comb[1]/pTot
</pre>
</div>

<pre class="example">
[1] 0.9411765

</pre>

<p>
Esercizio 8:
</p>
<ul class="org-ul">
<li>Un test di laboratorio √® efficace al 95% nel rilevare una certa malattia quando questa √® presente. Il test fornisce
comunque "falsi positivi" (dice che una persona sana √® malata) per l'1% delle persone sane esaminate. Nel caso in cui
lo 0.5% della popolazione sia affetto dalla suddetta malattia,
<ul class="org-ul">
<li>Qual'√® il problema che una persona sia effettivamente malata dato che il test d√† risultato positivo?</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">posti <span style="color: #558b2f;">&lt;-</span> c(0.95, 0.01)
salute <span style="color: #558b2f;">&lt;-</span> c(0.005, 0.995)

casi <span style="color: #558b2f;">&lt;-</span> posti*salute
num <span style="color: #558b2f;">&lt;-</span> casi[1]
denom <span style="color: #558b2f;">&lt;-</span> sum(casi)

num/denom
</pre>
</div>

<pre class="example">
[1] 0.3231293

</pre>

<p>
Esercizio 9:
</p>
<ul class="org-ul">
<li>Si sa che una data lettera ha eguale probabilit√† di essere contenuta in uno di tre folders. Si indichi con \(\alpha_i\) la probabilit√† che la lettera
venga trovata tramite una ricerca sommaria nel folder \(i\). Pertanto con probabilit√† \((1 - \alpha_i)\) la lettera non viene trovata anche se si trova
nel folder \(i\). Supponiamo di cercare nel folder \(1\) senza trovare la lettera.
<ul class="org-ul">
<li>Qual'√® la probabilit√† che la lettera sia nel folder <code>1</code>?</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">n <span style="color: #558b2f;">&lt;-</span> 3
probFolders <span style="color: #558b2f;">&lt;-</span> rep(1/n, 3)
probRicercaSucc <span style="color: #558b2f;">&lt;-</span> c(0.8, 0.9, 0.85)
probRicercaFall <span style="color: #558b2f;">&lt;-</span> 1-probRicercaSucc
probRicercaPrimo <span style="color: #558b2f;">&lt;-</span> c(probRicercaFall[1], 1, 1)
prob <span style="color: #558b2f;">&lt;-</span> probFolders*probRicercaPrimo

num <span style="color: #558b2f;">&lt;-</span> prob[1]
denom <span style="color: #558b2f;">&lt;-</span> sum(prob)

num/denom
</pre>
</div>

<pre class="example">
[1] 0.09090909

</pre>

<p>
Esercizio 12:
</p>
<ul class="org-ul">
<li>Date 2 urne indistinguibili esternamente. La prima contiene 3 palline rosse, 1 bianca e 2 verdi, mentre la seconda contiene 1 pallina rossa,
3 bianche e 2 verdi. Presa un'urna a caso, si estraggono 2 palline senza reimbussolamento da tale urna. Calcolare la probabilit√† che:
<ol class="org-ol">
<li>Vengano estratte 2 palline rosse;</li>
<li>Venga estratta almeno una pallina rossa;</li>
<li>L'urna dalla quale stiamo estraendo sia la prima quando la prima pallina estratta √® rossa;</li>
<li>La seconda pallina estratta dall'urna sia rossa quando la prima √® rossa.</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">urna1 <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"b"</span>, <span style="color: #689f38;">"v"</span>, <span style="color: #689f38;">"v"</span>)
urna2 <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"b"</span>, <span style="color: #689f38;">"b"</span>, <span style="color: #689f38;">"b"</span>, <span style="color: #689f38;">"v"</span>, <span style="color: #689f38;">"v"</span>)
numero_estrazioni <span style="color: #558b2f;">&lt;-</span> 2
prob <span style="color: #558b2f;">&lt;-</span> <span style="color: #0097A7;">NULL</span>
<span style="color: #00796b;">for</span>(i <span style="color: #00796b;">in</span> 1:numero_estrazioni) {
  prob <span style="color: #558b2f;">&lt;-</span> append(prob, 1/numero_estrazioni)
}

urna1_space <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(urna1, numero_estrazioni, ordered=T))
urna2_space <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(urna2, numero_estrazioni, ordered=T))

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
prob1 <span style="color: #558b2f;">&lt;-</span> Prob(urna1_space, X1==<span style="color: #689f38;">"r"</span> &amp; X2==<span style="color: #689f38;">"r"</span>)
prob2 <span style="color: #558b2f;">&lt;-</span> Prob(urna2_space, X1==<span style="color: #689f38;">"r"</span> &amp; X2==<span style="color: #689f38;">"r"</span>)
prob12 <span style="color: #558b2f;">&lt;-</span> c(prob1, prob2)
prob_2_palline_rosse <span style="color: #558b2f;">&lt;-</span> sum(prob12*prob)
prob_2_palline_rosse

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
prob1_0r <span style="color: #558b2f;">&lt;-</span> Prob(urna1_space, X1!=<span style="color: #689f38;">"r"</span> &amp; X2!=<span style="color: #689f38;">"r"</span>)
prob2_0r <span style="color: #558b2f;">&lt;-</span> Prob(urna2_space, X1!=<span style="color: #689f38;">"r"</span> &amp; X2!=<span style="color: #689f38;">"r"</span>)
prob12_0r <span style="color: #558b2f;">&lt;-</span> c(prob1_0r, prob2_0r)
1-sum(prob12_0r*prob)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
prob1_prima_r <span style="color: #558b2f;">&lt;-</span> Prob(urna1_space, X1==<span style="color: #689f38;">"r"</span>)
prob2_prima_r <span style="color: #558b2f;">&lt;-</span> Prob(urna2_space, X1==<span style="color: #689f38;">"r"</span>)
prob12_prima_r <span style="color: #558b2f;">&lt;-</span> c(prob1_prima_r, prob2_prima_r)
prob_tot_prima_r <span style="color: #558b2f;">&lt;-</span> prob12_prima_r*prob
num <span style="color: #558b2f;">&lt;-</span> prob_tot_prima_r[1]
denom <span style="color: #558b2f;">&lt;-</span> sum(prob_tot_prima_r)
num/denom

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">4</span>
num <span style="color: #558b2f;">&lt;-</span> prob_2_palline_rosse
denom <span style="color: #558b2f;">&lt;-</span> sum(prob_tot_prima_r)
num/denom
</pre>
</div>

<pre class="example">
[1] 0.1
[1] 0.5666667
[1] 0.75
[1] 0.3

</pre>

<p>
Esercizio 13:
</p>
<ul class="org-ul">
<li>2 urne indistinguibili esternamente. La prima contiene 2 palline rosse, 2 bianche e 4 verdi, mentre la seconda contiene 2 palline rosse,
4 bianche e 2 verdi. Selezioniamo un'urna a caso ed estraiamo da essa 2 palline senza reimbussolamento. Calcolare pa probabilit√† che:
<ol class="org-ol">
<li>Vengano estratte 2 palline verdi;</li>
<li>L'urna dalla quale stiamo estraendo sia la prima sapendo che la prima pallina estratta √® verde;</li>
<li>Vengano estratte 2 palline di colore diverso.</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">urna1 <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"b"</span>, <span style="color: #689f38;">"b"</span>, <span style="color: #689f38;">"v"</span>, <span style="color: #689f38;">"v"</span>, <span style="color: #689f38;">"v"</span>, <span style="color: #689f38;">"v"</span>)
urna2 <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"b"</span>, <span style="color: #689f38;">"b"</span>, <span style="color: #689f38;">"b"</span>, <span style="color: #689f38;">"b"</span>, <span style="color: #689f38;">"v"</span>, <span style="color: #689f38;">"v"</span>)
prob <span style="color: #558b2f;">&lt;-</span> c(0.5, 0.5)
urna1_space <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(urna1, 2, ordered=T))
urna2_space <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(urna2, 2, ordered=T))

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
urna1_2_verdi <span style="color: #558b2f;">&lt;-</span> Prob(urna1_space, X1==X2 &amp; X2==<span style="color: #689f38;">"v"</span>)
urna2_2_verdi <span style="color: #558b2f;">&lt;-</span> Prob(urna2_space, X1==X2 &amp; X2==<span style="color: #689f38;">"v"</span>)
urne_2_verdi <span style="color: #558b2f;">&lt;-</span> c(urna1_2_verdi, urna2_2_verdi)
urne_2_verdi_tot <span style="color: #558b2f;">&lt;-</span> sum(urne_2_verdi*prob)
urne_2_verdi_tot

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
urna1_prima_verde <span style="color: #558b2f;">&lt;-</span> Prob(urna1_space, X1==<span style="color: #689f38;">"v"</span>)
urna2_prima_verde <span style="color: #558b2f;">&lt;-</span> Prob(urna2_space, X1==<span style="color: #689f38;">"v"</span>)
urne_prima_verde <span style="color: #558b2f;">&lt;-</span> c(urna1_prima_verde, urna2_prima_verde)
prob_urne_prima_verde <span style="color: #558b2f;">&lt;-</span> urne_prima_verde*prob
num <span style="color: #558b2f;">&lt;-</span> prob_urne_prima_verde[1]
denom <span style="color: #558b2f;">&lt;-</span> sum(prob_urne_prima_verde)
num/denom

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
urna1_colore_diverso <span style="color: #558b2f;">&lt;-</span> Prob(urna1_space, X1!=X2)
urna2_colore_diverso <span style="color: #558b2f;">&lt;-</span> Prob(urna2_space, X1!=X2)
urne_colore_diverso <span style="color: #558b2f;">&lt;-</span> c(urna1_colore_diverso, urna2_colore_diverso)
sum(urne_colore_diverso*prob)
</pre>
</div>

<pre class="example">
[1] 0.125
[1] 0.6666667
[1] 0.7142857

</pre>

<p>
Esercizio 14:
</p>
<ul class="org-ul">
<li>Si effettuano 3 tiri verso un medesimo bersaglio. La probabilit√† di colpirlo al primo, al secondo e al terzo colpo sono rispettivamente
uguali a \(p1 = 0.4, p2=0.5, p3=0.7\). Calcolare la probabilit√†:
<ol class="org-ol">
<li>Di colpire il bersaglio una sola volta in 3 tiri;</li>
<li>Di colpire il bersaglio al pi√π una volta in 3 tiri;</li>
<li>Di colpire il bersaglio almeno una volta in 3 tiri;</li>
<li>Che il centro sia avvenuto al terzo colpo sapendo che il bersaglio viene colpito una sola volta.</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">prob_bersaglio <span style="color: #558b2f;">&lt;-</span> c(0.4, 0.5, 0.7)
prob_mancato <span style="color: #558b2f;">&lt;-</span> 1 - prob_bersaglio

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
prob_matrix <span style="color: #558b2f;">&lt;-</span> array(rep(prob_mancato, 3), c(3, 3))
diag(prob_matrix) <span style="color: #558b2f;">&lt;-</span> prob_bersaglio
prob_1_bersaglio <span style="color: #558b2f;">&lt;-</span> 0
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1:3) {
  prod <span style="color: #558b2f;">&lt;-</span> 1
  <span style="color: #00796b;">for</span> (j <span style="color: #00796b;">in</span> 1:3) {
  prod <span style="color: #558b2f;">&lt;-</span> prod*prod(prob_matrix[j, i])
  }
  prob_1_bersaglio <span style="color: #558b2f;">&lt;-</span> prob_1_bersaglio + prod
}
prob_1_bersaglio

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
prob_0_volte <span style="color: #558b2f;">&lt;-</span> prob_mancato[1]*prob_mancato[2]*prob_mancato[3]
prob_al_massimo_1_volta <span style="color: #558b2f;">&lt;-</span> prob_0_volte + prob_1_bersaglio
prob_al_massimo_1_volta

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
prob_almeno_1_volta <span style="color: #558b2f;">&lt;-</span> 1 - prob_0_volte
prob_almeno_1_volta

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">4</span>
prob_matrix_neg <span style="color: #558b2f;">&lt;-</span> 1 - prob_matrix
num <span style="color: #558b2f;">&lt;-</span> 1
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1:3) {
  num <span style="color: #558b2f;">&lt;-</span> num*prob_matrix_neg[i,1]
}
num/prob_1_bersaglio
</pre>
</div>

<pre class="example">
[1] 0.36
[1] 0.45
[1] 0.91
[1] 0.5833333

</pre>

<p>
Esercizio 15:
</p>
<ul class="org-ul">
<li>Un dado equilibrato viene lanciato 3 volte. Calcolare la probabilit√† che:
<ol class="org-ol">
<li>Il punteggio del primo lancio non sia divisibile per 3;</li>
<li>Il punteggio somma dei primi 2 lanci non sia divisibile per 3;</li>
<li>N√© il punteggio del primo lancio, n√© il punteggio somma dei primi due lanci siano visibili per 3.</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">die <span style="color: #558b2f;">&lt;-</span> probspace(rolldie(3))

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
primo <span style="color: #558b2f;">&lt;-</span> Prob(die, X1<span style="color: #558b2f;">%%</span>3!=0)
primo

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
secondo <span style="color: #558b2f;">&lt;-</span> Prob(die, (X1+X2)<span style="color: #558b2f;">%%</span>3!= 0)
secondo

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
primo*secondo
</pre>
</div>

<pre class="example">
[1] 0.6666667
[1] 0.6666667
[1] 0.4444444

</pre>

<p>
Esercizio 16:
</p>
<ul class="org-ul">
<li>Abbiamo dei componenti elettronici che provengono da 3 diversi centri di produzione, \(C1\), \(C2\) e \(C3\), la cui probabilit√†
di funzionamento √®, rispettivamente \(\frac{1}{10}, \frac{2}{10}\) e \(\frac{3}{10}\). Sappiamo inoltre che il 30% dei
componenti provengono da \(C1\), altri 20% da \(C2\) ed i restanti 50% provengono da \(C3\). Calcolare:
<ol class="org-ol">
<li>La probabilit√† che preso un componente a caso questo sia funzionante;</li>
<li>La probabilit√† che un componente preso a caso provenga da \(C1\) avendo osservato che esso √® funzionante;</li>
<li>La probabilit√† che almeno uno tra 3 componenti a caso sia funzionante;</li>
<li>Il numero minimo di componenti da estrarre affinch√© la probabilit√† che almeno uno sia funzionante sia maggiore o
uguale a 0.999.</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">funz_c1 <span style="color: #558b2f;">&lt;-</span> 1/10
funz_c2 <span style="color: #558b2f;">&lt;-</span> 2/10
funz_c3 <span style="color: #558b2f;">&lt;-</span> 3/10
prob_funz <span style="color: #558b2f;">&lt;-</span> c(funz_c1, funz_c2, funz_c3)

da_c1 <span style="color: #558b2f;">&lt;-</span> 0.3
da_c2 <span style="color: #558b2f;">&lt;-</span> 0.2
da_c3 <span style="color: #558b2f;">&lt;-</span> 0.5
prob_orig <span style="color: #558b2f;">&lt;-</span> c(da_c1, da_c2, da_c3)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
prob <span style="color: #558b2f;">&lt;-</span> prob_funz*prob_orig
prob_componente_funz <span style="color: #558b2f;">&lt;-</span> sum(prob)
prob_componente_funz

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
num <span style="color: #558b2f;">&lt;-</span> prob[1]
num/prob_componente_funz

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
prob_0_funz <span style="color: #558b2f;">&lt;-</span> (1-prob_componente_funz)^3
prob_almeno_1_funz <span style="color: #558b2f;">&lt;-</span> 1 - prob_0_funz
prob_almeno_1_funz
 
<span style="color: #607d8b;">#</span><span style="color: #607d8b;">4</span>
p <span style="color: #558b2f;">&lt;-</span> 0.999
ceiling(log(1-p, base=(1-prob_componente_funz)))
</pre>
</div>

<pre class="example">
[1] 0.22
[1] 0.1363636
[1] 0.525448
[1] 28

</pre>

<p>
Esercizio 18:
</p>
<ul class="org-ul">
<li><p>
Abbiamo un sistema elettronico costruito da 4 componenti posti in serie e parallelo come in figura:
</p>


<div class="figure">
<p><img src="Laboratorio/screenshot_2018-04-01_23-16-56.png" alt="screenshot_2018-04-01_23-16-56.png" />
</p>
</div>

<p>
Supponiamo che il funzionamento di ogni singolo componente sia indipendente dal funzionamento degli altri e
supponiamo che i 2 in parallelo funzionino ognuno con probabilit√† \(p_P\) mentre quelli in serie ognuno con
probabilit√† \(P_S\) (\(P_P\) e \(P_S \in (0, 1) \subseteq \mathbb{R}\))
</p></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">ps <span style="color: #558b2f;">&lt;-</span> 0.8
pp <span style="color: #558b2f;">&lt;-</span> 0.9

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
nessuno_funz <span style="color: #558b2f;">&lt;-</span> (1-ps)^2 * (1-pp)^2
1- nessuno_funz

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
nessun_paral_funz <span style="color: #558b2f;">&lt;-</span> (1-pp)^2
almeno_uno_paral_funz <span style="color: #558b2f;">&lt;-</span> 1 - nessun_paral_funz
due_serie_funz <span style="color: #558b2f;">&lt;-</span> ps^2
sistema_funz <span style="color: #558b2f;">&lt;-</span> almeno_uno_paral_funz*due_serie_funz
sistema_funz

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
pp <span style="color: #558b2f;">&lt;-</span> 0.8
ps <span style="color: #558b2f;">&lt;-</span> <span style="color: #0097A7;">NULL</span>
p <span style="color: #558b2f;">&lt;-</span> 0.9
nessun_paral_funz <span style="color: #558b2f;">&lt;-</span> (1-pp)^2
sqrt(p/(1-nessun_paral_funz))

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">4</span>
ps <span style="color: #558b2f;">&lt;-</span> 0.8
pp <span style="color: #558b2f;">&lt;-</span> 0.9
sistema_funz <span style="color: #558b2f;">&lt;-</span> almeno_uno_paral_funz*due_serie_funz
(ps^2*(1-pp)^2)/(1-sistema_funz)
</pre>
</div>

<pre class="example">
[1] 0.9996
[1] 0.6336
[1] 0.9682458
[1] 0.01746725

</pre>

<p>
Esercizio 19:
</p>
<ul class="org-ul">
<li>Da un mazzo regolare di 52 carte (13 cuori, 13 quadri, 13 fiori e 13 picche) vengono estratte contemporaneamente 3 carte.
<ul class="org-ul">
<li>Qual'√® la probabilit√† che le 3 carte estratte siano tutte di picche?</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">carte <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(cards(), 3))
Prob(carte, all(suit==<span style="color: #689f38;">"Spade"</span>))
</pre>
</div>

<pre class="example">
[1] 0.01294118

</pre>

<p>
Esercizio 20:
</p>
<ul class="org-ul">
<li>Supponiamo che un'urna contenga 1 pallina rossa e 1 pallina bianca. Una pallina √® estratta e se ne osserva il colore.
Essa viene poi rimessa nell'urna insieme a 1 pallina dello stesso colore. Sia \(R_i\) l'evento "All'\(i\)-esima estrazione
viene estratta una pallina rossa", analogamente \(B_i\) sia l'evento "All'\(i\)-esima estrazione viene estratta una pallina
bianca". Si calcoli:
<ol class="org-ol">
<li>\(P(R_2)\) e \(P(R_3)\);</li>
<li>Sapendo che la seconda estratta √® una pallina rossa, √® pi√π probabile che la prima estratta fosse rossa o bianca?</li>
<li>Qual'√® la probabilit√† che la prima estratta sia rossa e la seconda bianca?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">r <span style="color: #558b2f;">&lt;-</span> 1
b <span style="color: #558b2f;">&lt;-</span> 1
tot <span style="color: #558b2f;">&lt;-</span> r+b
p <span style="color: #558b2f;">&lt;-</span> 0.5

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
prob_r1 <span style="color: #558b2f;">&lt;-</span> r/tot
prob_b1 <span style="color: #558b2f;">&lt;-</span> b/tot
tot <span style="color: #558b2f;">&lt;-</span> tot+1
prob_r1_r2 <span style="color: #558b2f;">&lt;-</span> (r+1)/tot
prob_b1_r2 <span style="color: #558b2f;">&lt;-</span> r/tot
prob_r2 <span style="color: #558b2f;">&lt;-</span> prob_r1_r2*p + prob_b1_r2*p
prob_r2
prob_r1_b2 <span style="color: #558b2f;">&lt;-</span> b/tot
prob_b1_b2 <span style="color: #558b2f;">&lt;-</span> (b+1)/tot
prob_b2 <span style="color: #558b2f;">&lt;-</span> prob_r1_b2*p + prob_b1_b2*p
tot <span style="color: #558b2f;">&lt;-</span> tot+1
p <span style="color: #558b2f;">&lt;-</span> p/2
prob_r1_r2_r3 <span style="color: #558b2f;">&lt;-</span> (r+2)/tot
prob_r1_b2_r3 <span style="color: #558b2f;">&lt;-</span> (r+1)/tot
prob_b1_r2_r3 <span style="color: #558b2f;">&lt;-</span> prob_r1_b2_r3
prob_b1_b2_r3 <span style="color: #558b2f;">&lt;-</span> r/tot
prob_r3 <span style="color: #558b2f;">&lt;-</span> prob_r1_r2_r3*p + prob_r1_b2_r3*p + prob_b1_r2_r3*p + prob_b1_b2_r3*p
prob_r3

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
num_r <span style="color: #558b2f;">&lt;-</span> prob_r1*prob_r1_r2
denom_r <span style="color: #558b2f;">&lt;-</span> prob_r2
prob_r1_dato_r2 <span style="color: #558b2f;">&lt;-</span> num_r/denom_r
num_b <span style="color: #558b2f;">&lt;-</span> prob_b1*prob_b1_r2
denom_b <span style="color: #558b2f;">&lt;-</span> prob_r2
prob_b1_dato_r2 <span style="color: #558b2f;">&lt;-</span> num_b/denom_b
<span style="color: #00796b;">if</span> (prob_r1_dato_r2 &gt; prob_b1_dato_r2 | prob_r1_dato_r2 == prob_b1_dato_r2) {
  print(<span style="color: #689f38;">"Pi&#249; probabile la pallina rossa"</span>)
} <span style="color: #00796b;">else</span> <span style="color: #00796b;">if</span> (prob_b1_dato_r2 == prob_r1_dato_r2) {
  print(<span style="color: #689f38;">"Stessa probabilit&#224;"</span>)
} <span style="color: #00796b;">else</span> {
  print(<span style="color: #689f38;">"Pi&#249; probabile la pallina bianca"</span>)
}

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
prob_r1_b2*0.5
</pre>
</div>

<pre class="example">
[1] 0.5
[1] 0.5
[1] "Pi√π probabile la pallina rossa"
[1] 0.1666667

</pre>

<p>
Esercizio 21:
</p>
<ul class="org-ul">
<li>Un'urna contiene 6 palline di cui 3 bianche, 2 rosse ed 1 nera. Si estraggono senza reimmissione tre palline
e si vince se una delle 3 √® nera.
<ol class="org-ol">
<li>Si calcoli la probabilit√† di vincere;</li>
<li>Si calcoli la probabilit√† di vincere sapendo che la pallina nera non √® uscita nelle prime 2 estrazioni;</li>
<li>Sapendo di aver vinto, qual'√® la probabilit√† che la pallina nera non sia uscita nelle prime 2 estrazioni?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">urna <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"b"</span>, <span style="color: #689f38;">"b"</span>, <span style="color: #689f38;">"b"</span>, <span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"n"</span>)
urna_space <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(urna, 3, ordered=T))

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
prob_vincita <span style="color: #558b2f;">&lt;-</span> Prob(urna_space, X1==<span style="color: #689f38;">"n"</span> | X2==<span style="color: #689f38;">"n"</span> | X3==<span style="color: #689f38;">"n"</span>)
prob_vincita

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
prob_nera_al_terzo <span style="color: #558b2f;">&lt;-</span> Prob(urna_space, X1!=<span style="color: #689f38;">"n"</span> &amp; X2!=<span style="color: #689f38;">"n"</span> &amp; X3==<span style="color: #689f38;">"n"</span>)
prob_prime_2_non_nera <span style="color: #558b2f;">&lt;-</span> Prob(urna_space, X1!=<span style="color: #689f38;">"n"</span> &amp; X2!=<span style="color: #689f38;">"n"</span>)
prob_vincita_prime_2_non_nera <span style="color: #558b2f;">&lt;-</span> prob_nera_al_terzo/prob_prime_2_non_nera
prob_vincita_prime_2_non_nera

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
(prob_vincita_prime_2_non_nera*prob_prime_2_non_nera)/prob_vincita
</pre>
</div>

<pre class="example">
[1] 0.5
[1] 0.25
[1] 0.3333333

</pre>

<p>
Esercizio 22:
</p>
<ul class="org-ul">
<li>Il modello "plus" di una chiave USB pu√≤ presentare 2 tipi di difetto, difetto di tipo \(A\) con probabilit√† pari a 0.03 e difetto di
tipo \(B\) con probabilit√† pari a 0.07. I due tipi di difetto sono indipendenti l'uno dall'altro. Qual'√® la probabilit√† che
una generica chiave USB
<ol class="org-ol">
<li>Presenti entrambi i difetti?</li>
<li>Sia difettosa?</li>
<li>Presenti il difetto \(A\), sapendo che √® difettosa?</li>
<li>Presenti uno solo dei difetti, sapendo che √® difettosa?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">pa <span style="color: #558b2f;">&lt;-</span> 0.03
pb <span style="color: #558b2f;">&lt;-</span> 0.07

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
entrambi_difetti <span style="color: #558b2f;">&lt;-</span> pa*pb
entrambi_difetti

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
difettosa <span style="color: #558b2f;">&lt;-</span> pa + pb - pa*pb
difettosa

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
pa/difettosa

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">4</span>
un_solo_difetto <span style="color: #558b2f;">&lt;-</span> difettosa - pa*pb
un_solo_difetto/difettosa
</pre>
</div>

<pre class="example">
[1] 0.0021
[1] 0.0979
[1] 0.3064351
[1] 0.9785495

</pre>

<p>
Esercizio 23:
</p>
<ul class="org-ul">
<li><p>
Una roulette semplificata √® formata da 12 numeri che sono classificati rosso (\(R\)) e nero (\(N\)) in base allo schema seguente:
</p>


<div class="figure">
<p><img src="Laboratorio/screenshot_2018-04-02_11-03-33.png" alt="screenshot_2018-04-02_11-03-33.png" />
</p>
</div>

<p>
Siano \(A =\) "esce un numero pari", \(B =\) "esce un numero rosso", \(C =\) "esce un numero" \(\leq 6\) e \(D =\) "esce un numero" \(\leq 8\).
</p>
<ol class="org-ol">
<li>Stabilire se gli eventi \(A, B\) e \(C\) sono a 2 a 2 indipendenti;</li>
<li>Stabilire se \(A, B\) e \(C\) costituiscono una famiglia di eventi indipendenti;</li>
<li>Stabilire se \(A, B\) e \(D\) costituiscono una famiglia di eventi indipendenti;</li>
<li>Ponendo \(E =\) "esce un numero dispari" \(\leq 3\), \(E\) √® indipendente da \(A\) e da \(D\)?</li>
<li>Supponiamo di sapere che esca un numero rosso, gli eventi \(A\) e \(C\) sono indipendenti?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">numbers <span style="color: #558b2f;">&lt;-</span> 1:12
colors <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"n"</span>, <span style="color: #689f38;">"n"</span>, <span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"n"</span>, <span style="color: #689f38;">"n"</span>, <span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"n"</span>, <span style="color: #689f38;">"n"</span>, <span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"r"</span>)
roulette <span style="color: #558b2f;">&lt;-</span> data.frame(numbers, colors)
    
roulette_space <span style="color: #558b2f;">&lt;-</span> probspace(roulette)
    
prob_a <span style="color: #558b2f;">&lt;-</span> Prob(roulette_space, numbers<span style="color: #558b2f;">%%</span>2==0)
prob_b <span style="color: #558b2f;">&lt;-</span> Prob(roulette_space, colors==<span style="color: #689f38;">"r"</span>)
prob_c <span style="color: #558b2f;">&lt;-</span> Prob(roulette_space, numbers&lt;=6)
prob_d <span style="color: #558b2f;">&lt;-</span> Prob(roulette_space, numbers&lt;=8)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
prob_a_AND_b <span style="color: #558b2f;">&lt;-</span> Prob(roulette_space, numbers<span style="color: #558b2f;">%%</span>2==0 &amp; colors==<span style="color: #689f38;">"r"</span>)
prob_a_AND_c <span style="color: #558b2f;">&lt;-</span> Prob(roulette_space, numbers<span style="color: #558b2f;">%%</span>2==0 &amp; numbers &lt;=6)
prob_b_AND_c <span style="color: #558b2f;">&lt;-</span> Prob(roulette_space, colors==<span style="color: #689f38;">"r"</span> &amp; numbers &lt;=6)
<span style="color: #00796b;">if</span> (prob_a*prob_b==prob_a_AND_b &amp; prob_a*prob_c==prob_a_AND_c &amp; prob_b*prob_c==prob_b_AND_c) {
  print(<span style="color: #689f38;">"Gli eventi A, B e C sono a 2 a 2 indipendenti"</span>)
} <span style="color: #00796b;">else</span> {
  print(<span style="color: #689f38;">"Gli eventi A, B e C non sono a 2 a 2 indipendenti"</span>)
}

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
prob_a_AND_b_AND_c <span style="color: #558b2f;">&lt;-</span> Prob(roulette_space, numbers<span style="color: #558b2f;">%%</span>2==0 &amp; colors==<span style="color: #689f38;">"r"</span> &amp; numbers &lt;=6)
<span style="color: #00796b;">if</span> (prob_a*prob_b*prob_c==prob_a_AND_b_AND_c) {
  print(<span style="color: #689f38;">"Gli eventi A, B e C costituiscono una famiglia di eventi indipendenti"</span>)
} <span style="color: #00796b;">else</span> {
  print(<span style="color: #689f38;">"Gli eventi A, B e C non costituiscono una famiglia di eventi indipendenti"</span>)
}

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
prob_a_AND_d <span style="color: #558b2f;">&lt;-</span> Prob(roulette_space, numbers<span style="color: #558b2f;">%%</span>2==0 &amp; numbers &lt;=8)
prob_b_AND_d <span style="color: #558b2f;">&lt;-</span> Prob(roulette_space, colors==<span style="color: #689f38;">"r"</span> &amp; numbers &lt;=8)
<span style="color: #00796b;">if</span> (prob_a*prob_b==prob_a_AND_b &amp; prob_a*prob_d==prob_a_AND_d &amp; prob_b*prob_d==prob_b_AND_d) {
  print(<span style="color: #689f38;">"Gli eventi A, B e D sono a 2 a 2 indipendenti"</span>)
} <span style="color: #00796b;">else</span> {
  print(<span style="color: #689f38;">"Gli eventi A, B e D non sono a 2 a 2 indipendenti"</span>)
}

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">4</span>
prob_e <span style="color: #558b2f;">&lt;-</span> Prob(roulette_space, numbers<span style="color: #558b2f;">%%</span>2==1 &amp; numbers&lt;=3)
prob_a_AND_d <span style="color: #558b2f;">&lt;-</span> Prob(roulette_space, numbers<span style="color: #558b2f;">%%</span>2==0 &amp; numbers&lt;=8)
prob_a_AND_e <span style="color: #558b2f;">&lt;-</span> Prob(roulette_space, numbers<span style="color: #558b2f;">%%</span>2==0 &amp; numbers<span style="color: #558b2f;">%%</span>2==1 &amp; numbers&lt;=3)
prob_b_AND_e <span style="color: #558b2f;">&lt;-</span> Prob(roulette_space, colors==<span style="color: #689f38;">"r"</span> &amp; numbers<span style="color: #558b2f;">%%</span>2==1 &amp; numbers&lt;=3)
<span style="color: #00796b;">if</span> (prob_a*prob_d==prob_a_AND_d &amp; prob_a*prob_e==prob_a_AND_e &amp; prob_b*prob_e==prob_b_AND_e) {
  print(<span style="color: #689f38;">"Gli eventi A, D e E sono a 2 a 2 indipendenti"</span>)
} <span style="color: #00796b;">else</span> {
  print(<span style="color: #689f38;">"Gli eventi A, D e E non sono a 2 a 2 indipendenti"</span>)
}

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">5</span>
prob_a_dato_b <span style="color: #558b2f;">&lt;-</span> prob_a_AND_b/prob_b
prob_c_dato_b <span style="color: #558b2f;">&lt;-</span> prob_b_AND_c/prob_b
prob_a_AND_c_dato_b <span style="color: #558b2f;">&lt;-</span> prob_a_AND_b_AND_c/prob_b
<span style="color: #00796b;">if</span> (prob_a*prob_d==prob_a_AND_d &amp; prob_a*prob_e==prob_a_AND_e &amp; prob_b*prob_e==prob_b_AND_e) {
  cat(<span style="color: #689f38;">"Se sappiamo che esce un numero rosso, gli eventi A e C sono indipendenti"</span>)
} <span style="color: #00796b;">else</span> {
  cat(<span style="color: #689f38;">"Se sappiamo che esce un numero rosso, gli eventi A e C non sono indipendenti"</span>)
}
</pre>
</div>

<pre class="example">
[1] "Gli eventi A, B e C sono a 2 a 2 indipendenti"
[1] "Gli eventi A, B e C non costituiscono una famiglia di eventi indipendenti"
[1] "Gli eventi A, B e D sono a 2 a 2 indipendenti"
[1] "Gli eventi A, D e E non sono a 2 a 2 indipendenti"

</pre>

<p>
Esercizio 24:
</p>
<ul class="org-ul">
<li>Da un'urna che contiene 3 palline bianche e 2 palline nere vengono trasferite 2 palline, scelte a caso, in un'altra
urna che contiene 4 palline bianche e 4 palline nere. Infine, si estrae una pallina dalla seconda urna.
<ol class="org-ol">
<li>Trovare la probabilit√† di estrarre una pallina bianca dalla seconda urna;</li>
<li>Calcolare la probabilit√† di aver trasferito almeno una pallina bianca se estraiamo una pallina nera dalla seconda urna.</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">b1 <span style="color: #558b2f;">&lt;-</span> 3
n1 <span style="color: #558b2f;">&lt;-</span> 2
tot1<span style="color: #558b2f;">&lt;-</span> b1+n1
b2 <span style="color: #558b2f;">&lt;-</span> 4
n2 <span style="color: #558b2f;">&lt;-</span> 4
tot2<span style="color: #558b2f;">&lt;-</span> b2+n2+2

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
bn <span style="color: #558b2f;">&lt;-</span> b1*n1/choose(tot1, 2)
bb <span style="color: #558b2f;">&lt;-</span> choose(b1, 2)/choose(tot1, 2)
nn <span style="color: #558b2f;">&lt;-</span> choose(n1, 2)/choose(tot1, 2)
estr_b2 <span style="color: #558b2f;">&lt;-</span> bn*(b2+1)/tot2 + bb*(b2+2)/tot2 + nn*b2/tot2
estr_b2

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
almeno_1_b1 <span style="color: #558b2f;">&lt;-</span> bn+bb
estr_n2_dato_almeno_1_b1 <span style="color: #558b2f;">&lt;-</span> bn*(n2+1)/tot2 + bb*n2/tot2
estr_n2 <span style="color: #558b2f;">&lt;-</span> 1 - estr_b2
estr_almeno_1_b1_dato_n2 <span style="color: #558b2f;">&lt;-</span> estr_n2_dato_almeno_1_b1/estr_n2
estr_almeno_1_b1_dato_n2
</pre>
</div>

<pre class="example">
[1] 0.52
[1] 0.875

</pre>

<p>
Esercizio 25:
</p>
<ul class="org-ul">
<li>Ci sono 2 urne, la prima urna \(U_1\) contiene 2 dadi a 6 facce (dadi onesti), la seconda urna \(U_2\) contiene 2 dadi a 6 facce
(dadi truccati nel modo seguente; ognuno dei dadi ha 3 facce che indicano il numero 6 e le rimanenti 3 il numero 5).
Si lancia una moneta onesta e se l'esito del bilancio √® testa si prendono i dadi dalla prima urna \(U_1\) mentre l'esito √® croce si
prendono i dadi dalla seconda urna \(U_2\), poi, in ogni caso si lanciano i dati:
<ol class="org-ol">
<li>Calcolare la probabilit√† che la somma dei 2 dadi sia 11;</li>
<li>Sapendo di aver ottenuto un 11 lanciando i due dadi, calcolare la probabilit√† di aver ottenuto croce lanciando la moneta;</li>
<li>Sapendo di aver ottenuto un 11 lanciando i 2 dadi, calcolare la probabilit√† di aver ottenuto croce lanciando la moneta;</li>
<li>Gli eventi \(D_1 =\) "ottengo 6 sul primo lancio" e \(D_2 =\) "ottengo 6 sul secondo dato" sono indipendenti?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">dado1 <span style="color: #558b2f;">&lt;-</span> rolldie(2, makespace=T)
load_dado2 <span style="color: #558b2f;">&lt;-</span> <span style="color: #0097A7;">NULL</span>
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1:3) {
  load_dado2 <span style="color: #558b2f;">&lt;-</span> append(load_dado2, 6)
}
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1:3) {
  load_dado2 <span style="color: #558b2f;">&lt;-</span> append(load_dado2, 5)
}
dado2 <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(load_dado2, 2, ordered=T, replace=T))
moneta <span style="color: #558b2f;">&lt;-</span> tosscoin(1, makespace=T)
t <span style="color: #558b2f;">&lt;-</span> Prob(moneta, toss1==<span style="color: #689f38;">"H"</span>)
c <span style="color: #558b2f;">&lt;-</span> Prob(moneta, toss1==<span style="color: #689f38;">"T"</span>)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
somma_11_dado1 <span style="color: #558b2f;">&lt;-</span> Prob(dado1, (X1+X2)==11)
somma_11_dado2 <span style="color: #558b2f;">&lt;-</span> Prob(dado2, (X1+X2)==11)
somma_11 <span style="color: #558b2f;">&lt;-</span> somma_11_dado1*t + somma_11_dado2*c
somma_11

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
somma_11_dado2*c/somma_11

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
p_d1 <span style="color: #558b2f;">&lt;-</span> Prob(dado1, X1==6)*t + Prob(dado1, X1==6)*c
p_d2 <span style="color: #558b2f;">&lt;-</span> Prob(dado1, X2==6)*t + Prob(dado2, X2==6)*c
p_d1_AND_d2 <span style="color: #558b2f;">&lt;-</span> Prob(dado1, X1==6 &amp; X2==6)*t + Prob(dado2, X1==6 &amp; X2==6)*c
<span style="color: #00796b;">if</span> (p_d1*p_d2==p_d1_AND_d2) {
  print(<span style="color: #689f38;">"D_1 e D_2 sono indipendenti"</span>)
} <span style="color: #00796b;">else</span> {
  print(<span style="color: #689f38;">"D_1 e D_2 non sono indipendenti"</span>)
}
</pre>
</div>

<pre class="example">
[1] 0.2777778
[1] 0.9
[1] "D_1 e D_2 non sono indipendenti"

</pre>

<p>
Esercizio 26:
</p>
<ul class="org-ul">
<li>Nel gioco del lotto ad ogni estrazione che avviene settimanalmente vengono pescate contemporaneamente 5 palline da un'urna
contenente 90 palline numerate da 1 a 90 e per il resto indistinguibili. Giovanni ogni settimana gioca l'ambo \(\{89, 90\}\),
cio√® Giovanni vince se fra le 5 palline estratte vi sono quelle numerate con 89 e 90.
<ol class="org-ol">
<li>Calcolare la probabilit√† di vincere in una singola estrazione;</li>
<li>Se nelle prime 2 estrazioni Giovanni non ha vinto con quale probabilit√† vincer√† almeno una volta nelle prime 10 estrazioni?</li>
<li>Se nelle prime 10 giocate Giovanni ha vinto 3 volte, con quale probabilit√† ha vinto nelle prime 3 giocate?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">p1 <span style="color: #558b2f;">&lt;-</span> 89
p2 <span style="color: #558b2f;">&lt;-</span> 90

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
vinc_1_estr <span style="color: #558b2f;">&lt;-</span> choose(87, 3)/choose(90, 5)
vinc_1_estr

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
1 - (1 - vinc_1_estr)^8

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
1/choose(10, 3)
</pre>
</div>

<pre class="example">
[1] 0.002411758
[1] 0.01913198
[1] 0.008333333

</pre>

<p>
Esercizio 27:
</p>
<ul class="org-ul">
<li>Un'urna contiene 2 palline rosse e 4 palline nere. Due giocatori \(A\) e \(B\) giocano nel modo seguente: le palline vengono
estratte ad una ad una e messe da parte. \(A\) vince se l'ultima palline estratta √® rossa, altrimenti vince \(B\).
<ol class="org-ol">
<li>Qual'√® la probabilit√† che \(A\) vinca?</li>
<li>Qual'√® la probabilit√† che \(A\) vinca sapendo che la prima pallina estratta √® rossa?</li>
<li>Qual'√® la probabilit√† che \(A\) vinca e che la prima pallina estratta sia rossa?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">urna <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"r"</span>, <span style="color: #689f38;">"n"</span>, <span style="color: #689f38;">"n"</span>, <span style="color: #689f38;">"n"</span>, <span style="color: #689f38;">"n"</span>)

urna_space <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(urna, 6, ordered=T))

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
rossa_1 <span style="color: #558b2f;">&lt;-</span> Prob(urna_space, X6==<span style="color: #689f38;">"r"</span>)
rossa_1

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
rossa_1_6 <span style="color: #558b2f;">&lt;-</span> Prob(urna_space, X1==X6 &amp; X6==<span style="color: #689f38;">"r"</span>)
rossa_1_6/rossa_1

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
rossa_1_6
</pre>
</div>

<pre class="example">
[1] 0.3333333
[1] 0.2
[1] 0.06666667

</pre>

<p>
Esercizio 28:
</p>
<ul class="org-ul">
<li>Gli abitanti della localit√† <code>abc</code> raggiungono ogni giorno la citt√† <code>xyz</code> in treno o in macchina. Il 90% degli abitanti di
<code>abc</code> arrivano nella citt√† <code>xyz</code> in ritardo (sull'orario previsto). Il 40% di questi (cio√® di quelli in ritardo) usano il
treno, mentre, il 30% di quelli che NON arrivano in ritardo (sull'orario previsto) usano la macchina.
<ol class="org-ol">
<li>Qual'√® la probabilit√† che un abitante di <code>abc</code> usi il treno per raggiungere la citt√† <code>xyz</code> (un dato giorno)?</li>
<li>Se un abitante di <code>abc</code> usa il treno per raggiungere <code>xyz</code>, √® pi√π probabile che arrivi in ritardo o non in ritardo?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">ritardo <span style="color: #558b2f;">&lt;-</span> 0.9
rit_treno <span style="color: #558b2f;">&lt;-</span> 0.4
or_macchina <span style="color: #558b2f;">&lt;-</span> 0.2
orario <span style="color: #558b2f;">&lt;-</span> 1-ritardo
rit_macchina <span style="color: #558b2f;">&lt;-</span> 1-rit_treno
or_treno <span style="color: #558b2f;">&lt;-</span> 1-or_macchina

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
treno <span style="color: #558b2f;">&lt;-</span> rit_treno*ritardo + or_treno*orario
treno

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
ritardo_dato_treno <span style="color: #558b2f;">&lt;-</span> rit_treno*ritardo/treno
orario_dato_treno <span style="color: #558b2f;">&lt;-</span> or_treno*orario/treno
<span style="color: #00796b;">if</span> (ritardo_dato_treno==orario_dato_treno) {
    print(<span style="color: #689f38;">"La probabilit&#224; che arrivi in orario e che arrivi in ritardo &#232; la medesima"</span>)
} <span style="color: #00796b;">else</span> <span style="color: #00796b;">if</span> (ritardo_dato_treno&gt;orario_dato_treno) {
    print(<span style="color: #689f38;">"&#200; pi&#249; probabile che arrivi in ritardo"</span>)
} <span style="color: #00796b;">else</span> <span style="color: #00796b;">if</span> (ritardo_dato_treno&gt;orario_dato_treno) {
    print(<span style="color: #689f38;">"&#200; pi&#249; probabile che arrivi in orario"</span>)
}
</pre>
</div>

<pre class="example">
[1] 0.44
[1] "√à pi√π probabile che arrivi in ritardo"

</pre>

<p>
Esercizio 31:
</p>
<ul class="org-ul">
<li>Ho 2 urne \(A\) e \(B\): \(A\) contiene 6 palline di cui 1 numerata 1, 2 numerate 2 e 3 numerate 3 e \(B\) contiene 9 palline di
cui 2 numerate 2, 3 numerate 3 e 4 numerate 4. Lancio un dado regolare: se esce la faccio 6, estraggo una pallina dall'urna \(A\).
Invece, se non esce la faccia 6, estraggo una pallina dall'urna \(B\).
<ol class="org-ol">
<li>Qual'√® la probabilit√† di estrarre una pallina numerata 2?</li>
<li>Se la pallina estratta √® numerata 2, qual'√® la probabilit√† che il dado lanciato abbia esibito la faccia 6?</li>
<li>Sia \(X\) la variabile aleatoria discreta che rappresenta il numero della pallina estratta. Determinare la densit√† di \(X\).</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">urna1 <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(c(1, 2, 2, 3, 3, 3), 1))
urna2 <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(c(2, 2, 3, 3, 3, 4, 4, 4, 4), 1))
dado <span style="color: #558b2f;">&lt;-</span> rolldie(1, makespace=T)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
dado_6 <span style="color: #558b2f;">&lt;-</span> Prob(dado, X1==6)
dado_non_6 <span style="color: #558b2f;">&lt;-</span> 1-dado_6
urna1_2 <span style="color: #558b2f;">&lt;-</span> Prob(urna1, out==2)
urna2_2 <span style="color: #558b2f;">&lt;-</span> Prob(urna2, out==2)
estr_2 <span style="color: #558b2f;">&lt;-</span> urna1_2*dado_6 + urna2_2*dado_non_6
estr_2

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
urna1_2*dado_6/estr_2

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
p <span style="color: #558b2f;">&lt;-</span> <span style="color: #0097A7;">NULL</span>
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> 1:4) {
    p <span style="color: #558b2f;">&lt;-</span> append(p, Prob(urna1, out==i)*dado_6 + Prob(urna2, out==i)*dado_non_6)
}
p
</pre>
</div>

<pre class="example">
[1] 0.2407407
[1] 0.2307692
[1] 0.02777778 0.24074074 0.36111111 0.37037037

</pre>

<p>
Esercizio 32:
</p>
<ul class="org-ul">
<li>Giulio, Carlo e Federico giocano al tiro con l'arco. Si sa che la probabilit√† che Giulio colpisca il bersaglio √® pari a
3/4, quella che Carlo colpisca il bersaglio √® pari ad 1/2 e quella di Federico √® pari ad 1/4. Si sa inoltre che i risultati
dei lanci dei 3 arcieri sono indipendenti.
<ol class="org-ol">
<li>Calcolare la probabilit√† che nessuno di loro colpisca il bersaglio;</li>
<li>Calcolare la probabilit√† che esattamente 2 di loro colpiscano il bersaglio;</li>
<li>Calcolare la probabilit√† che Giulio colpisca il bersaglio sapendo che esattamente 2 di loro hanno colpito il bersaglio.</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">g <span style="color: #558b2f;">&lt;-</span> 3/4
c <span style="color: #558b2f;">&lt;-</span> 1/2
f <span style="color: #558b2f;">&lt;-</span> 1/4

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
nessuno <span style="color: #558b2f;">&lt;-</span> (1-g)*(1-c)*(1-f)
nessuno

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
due <span style="color: #558b2f;">&lt;-</span> g*c*(1-f) + g*(1-c)*f + (1-g)*c*f
due

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
due_dato_giulio <span style="color: #558b2f;">&lt;-</span> due - (1-g)*c*f
due_dato_giulio*g/due
</pre>
</div>

<pre class="example">
[1] 0.09375
[1] 0.40625
[1] 0.6923077

</pre>

<p>
Esercizio 33:
</p>
<ul class="org-ul">
<li>Un supermercato accetta pagamenti con carte di credito di 2 soli tipi, \(A\) e \(B\). Il 25% dei clienti possiede la carta \(A\),
il 50% la carta \(B\) e il 15% possiede entrambe le carte.
<ol class="org-ol">
<li>Calcolare la probabilit√† che un cliente scelto a caso possieda almeno una carta di credito accettata dal supermercato;</li>
<li>Calcolare la probabilit√† che un cliente scelto a caso possieda esattamente una carta di credito accettata dal supermercato;</li>
<li>Se un cliente possiede almeno una carta di credito accettata dal supermercato, qual'√® la probabilit√† che sia una carta
di credito di tipo \(A\)?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">a <span style="color: #558b2f;">&lt;-</span> 0.25
b <span style="color: #558b2f;">&lt;-</span> 0.50
ab <span style="color: #558b2f;">&lt;-</span> 0.15

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
almeno_una <span style="color: #558b2f;">&lt;-</span> a+b-ab
almeno_una

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
esattamente_una <span style="color: #558b2f;">&lt;-</span> almeno_una - ab
esattamente_una

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
a/almeno_una
</pre>
</div>

<pre class="example">
[1] 0.6
[1] 0.45
[1] 0.4166667

</pre>

<p>
Esercizio 35:
</p>
<ul class="org-ul">
<li>Uno scommettitore ha nel suo portafoglio una moneta equa ed una moneta con entrambi i lati testa. Egli seleziona in modo
casuale una delle due monete, la lancia e ne osserva l'esito testa.
<ol class="org-ol">
<li>Qual'√® la probabilit√† che si tratti della moneta equa?</li>
<li>Supponiamo che lanci la stessa moneta una seconda volta e che l'esito sia ancora testa. Qual'√® la probabilit√† che si
tratti della moneta equa?</li>
<li>Supponiamo che lanci una terza volta la stessa moneta ottenendo croce. Qual'√® la probabilit√† che si tratti della
moneta equa?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">p <span style="color: #558b2f;">&lt;-</span> 0.5
equa <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"t"</span>, <span style="color: #689f38;">"c"</span>)
truc <span style="color: #558b2f;">&lt;-</span> c(<span style="color: #689f38;">"t"</span>, <span style="color: #689f38;">"t"</span>)
equa_s <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(equa, 1))
truc_s <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(truc, 1))

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
equa_testa <span style="color: #558b2f;">&lt;-</span> Prob(equa_s, out==<span style="color: #689f38;">"t"</span>)
truc_testa <span style="color: #558b2f;">&lt;-</span> Prob(truc_s, out==<span style="color: #689f38;">"t"</span>)
testa <span style="color: #558b2f;">&lt;-</span> p*(equa_testa + truc_testa)
prob_equa <span style="color: #558b2f;">&lt;-</span> equa_testa*p/testa
prob_equa

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
equa_s <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(equa, 2, ordered=T, replace=T))
truc_s <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(truc, 2, ordered=T, replace=T))
equa_testa_2 <span style="color: #558b2f;">&lt;-</span> Prob(equa_s, X1==<span style="color: #689f38;">"t"</span> &amp; X2==<span style="color: #689f38;">"t"</span>)
truc_testa_2 <span style="color: #558b2f;">&lt;-</span> Prob(truc_s, X1==<span style="color: #689f38;">"t"</span> &amp; X2==<span style="color: #689f38;">"t"</span>)
testa_2 <span style="color: #558b2f;">&lt;-</span> p*(equa_testa_2 + truc_testa_2)
prob_equa_2 <span style="color: #558b2f;">&lt;-</span> equa_testa_2*p/testa_2
prob_equa_2 

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
equa_s <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(equa, 3, ordered=T, replace=T))
truc_s <span style="color: #558b2f;">&lt;-</span> probspace(urnsamples(truc, 3, ordered=T, replace=T))
equa_testa_2_croce <span style="color: #558b2f;">&lt;-</span> Prob(equa_s, X1==<span style="color: #689f38;">"t"</span> &amp; X2==<span style="color: #689f38;">"t"</span> &amp; X3==<span style="color: #689f38;">"c"</span>)
truc_testa_2_croce <span style="color: #558b2f;">&lt;-</span> Prob(truc_s, X1==<span style="color: #689f38;">"t"</span> &amp; X2==<span style="color: #689f38;">"t"</span> &amp; X3==<span style="color: #689f38;">"c"</span>)
testa_2_croce <span style="color: #558b2f;">&lt;-</span> p*(equa_testa_2_croce + truc_testa_2_croce)
prob_equa_3 <span style="color: #558b2f;">&lt;-</span> equa_testa_2_croce*p/testa_2_croce
prob_equa_3 
</pre>
</div>

<pre class="example">
[1] 0.3333333
[1] 0.2
[1] 1

</pre>

<p>
Esercizio 36:
</p>
<ul class="org-ul">
<li>In un certo collegio, il 25% degli studenti √® stato bocciato in matematica, il 15% √® stato bocciato in chimica, e il 10%
√® stato bocciato sia in matematica che in chimica. Viene scelto a caso uno studente.
<ol class="org-ol">
<li>Se egli √® stato bocciato in chimica, qual'√® la probabilit√† che sia stato bocciato in matematica?</li>
<li>Se egli √® stato bocciato in matematica, qual'√® la probabilit√† che sia stato bocciato in chimica?</li>
<li>Qual'√® la probabilit√† che sia stato bocciato in matematica o in chimica?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">mat <span style="color: #558b2f;">&lt;-</span> 0.25
chim <span style="color: #558b2f;">&lt;-</span> 0.15
matchim <span style="color: #558b2f;">&lt;-</span> 0.1

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
matchim/chim

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
matchim/mat

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
mat+chim-matchim
</pre>
</div>

<pre class="example">
[1] 0.6666667
[1] 0.4
[1] 0.3

</pre>
</div>
</div>

<div id="outline-container-org8ab59fb" class="outline-4">
<h4 id="org8ab59fb"><span class="section-number-4">3.2.3</span> Distribuzioni Notevoli</h4>
<div class="outline-text-4" id="text-3-2-3">
<p>
Nel package <code>stats</code> sono inclusi i metodi per le pi√π importanti distribuzioni notevoli discrete:
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />
</colgroup>

<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">Distribuzione</th>
<th scope="col" class="org-left">Ripartizione</th>
<th scope="col" class="org-left">Quantile</th>
<th scope="col" class="org-left">Generazione</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Binomiale</td>
<td class="org-left"><code>dbinom</code></td>
<td class="org-left"><code>pbinom</code></td>
<td class="org-left"><code>qbinom</code></td>
<td class="org-left"><code>rbinom</code></td>
</tr>

<tr>
<td class="org-left">Ipergeometrica</td>
<td class="org-left"><code>dhyper</code></td>
<td class="org-left"><code>phyper</code></td>
<td class="org-left"><code>qhyper</code></td>
<td class="org-left"><code>rhyper</code></td>
</tr>

<tr>
<td class="org-left">Geometrica</td>
<td class="org-left"><code>dgeom</code></td>
<td class="org-left"><code>pgeom</code></td>
<td class="org-left"><code>qgeom</code></td>
<td class="org-left"><code>rgeom</code></td>
</tr>

<tr>
<td class="org-left">Poisson</td>
<td class="org-left"><code>dpois</code></td>
<td class="org-left"><code>ppois</code></td>
<td class="org-left"><code>qpois</code></td>
<td class="org-left"><code>rpois</code></td>
</tr>

<tr>
<td class="org-left">Uniforme</td>
<td class="org-left"><code>dunif</code></td>
<td class="org-left"><code>qunif</code></td>
<td class="org-left"><code>qunif</code></td>
<td class="org-left"><code>runif</code></td>
</tr>

<tr>
<td class="org-left">Esponenziale</td>
<td class="org-left"><code>dexp</code></td>
<td class="org-left"><code>pexp</code></td>
<td class="org-left"><code>qexp</code></td>
<td class="org-left"><code>rexp</code></td>
</tr>

<tr>
<td class="org-left">Normale</td>
<td class="org-left"><code>dnorm</code></td>
<td class="org-left"><code>pnorm</code></td>
<td class="org-left"><code>qnorm</code></td>
<td class="org-left"><code>rnorm</code></td>
</tr>

<tr>
<td class="org-left">Chi-Quadro</td>
<td class="org-left"><code>dchisq</code></td>
<td class="org-left"><code>pchisq</code></td>
<td class="org-left"><code>qchisq</code></td>
<td class="org-left"><code>rchisq</code></td>
</tr>
</tbody>
</table>

<p>
Esercizio 1:
</p>
<ul class="org-ul">
<li>4 monete bilanciate vengono lanciate. Assumendo l'indipendenza dei risultati, qual'√® la probabilit√† di ottenere 2 testa
e 2 croce?</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">dbinom(2, 4, prob=1/2)
</pre>
</div>

<pre class="example">
[1] 0.375

</pre>

<p>
Distribuzioni notevoli discrete:
</p>
<ul class="org-ul">
<li>Disegnare la distribuzione di probabilit√† della variabile binomiale: \(X\) = "numero di volte in cui compare testa",
lanciando 4 volte una moneta bilanciata.</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">plot(c(0:4), dbinom(0:4, 4, prob=1/2), type=<span style="color: #689f38;">"h"</span>, xlab=<span style="color: #689f38;">"X"</span>)
lines(c(0:4), dbinom(0:4, 4, prob=0.5), lty=5, col=<span style="color: #689f38;">"red"</span>)
text(c(0:4), dbinom(0:4, 4, prob=0.5), dbinom(0:4, 4, prob=0.5))
</pre>
</div>


<div class="figure">
<p><img src="graf_binom.png" alt="graf_binom.png" />
</p>
</div>

<p>
Disegnare la funzione di ripartizione:
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Impostare il grafico</span>
plot(0, xlim=c(-0.2, 4.2), ylim=c(-0.04, 1.04), type=<span style="color: #689f38;">"n"</span>, xlab=<span style="color: #689f38;">"X"</span>, ylab=<span style="color: #689f38;">"Probabilit&#224; cumulata"</span>)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Disegnare due linee orizzontali che limitano la y</span>
abline(h=c(0, 1), lty=2, col=<span style="color: #689f38;">"grey"</span>)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Disegnare una funzione a gradini</span>
lines(stepfun(0:4, pbinom(-1:4, size=4, prob=0.5)), verticals=<span style="color: #0097A7;">FALSE</span>, do.p=<span style="color: #0097A7;">FALSE</span>)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Disegnare i punti estremi</span>
points(0:4, pbinom(0:4, size=4, prob=0.5), pch=16, cex=1.2)
points(0:4, pbinom(-1:3, size=4, prob=0.5), pch=1, cex=1.2)
</pre>
</div>


<div class="figure">
<p><img src="graf_rip_binom.png" alt="graf_rip_binom.png" />
</p>
</div>

<p>
Esercizio 2:
</p>
<ul class="org-ul">
<li>√à noto che gli item prodotti da una macchina utensile saranno difettosi con probabilit√† 0.1. Qual'√® la probabilit√†
che in un campione di 3 items al pi√π uno sia difettoso?</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">pbinom(1, 3, prob=0.1)
</pre>
</div>

<pre class="example">
null device 
          1
null device 
          1
[1] 0.972

</pre>

<p>
Esercizio 3:
</p>
<ul class="org-ul">
<li>Supponiamo che il colore degli occhi di una persona sia determinato in base ad una coppia di geni e che <code>r</code> rappresenti
il gene dominante mentre <code>r</code> il gene recessivo. Pertanto una persona con la coppia di geni <code>dd</code> ha dominanza pura,
una con <code>rr</code> ha recessione pura e una con <code>dr</code> o <code>rd</code> √® ibrida. Un bambino riceve un gene da ognuno dei genitori.
Se rispetto al colore degli occhi i due genitori "ibridi" hanno 4 figli.
<ul class="org-ul">
<li>Qual'√® la probabilit√† che esattamente 3 dei 4 figli abbiano 1 gene dominante?</li>
</ul></li>
</ul>

<div class="org-src-container">
<pre class="src src-R">dbinom(3, 4, prob=3/4)
</pre>
</div>

<pre class="example">
[1] 0.421875

</pre>

<p>
Esercizio 6:
</p>
<ul class="org-ul">
<li>Un'azienda produce dischetti, la probabilit√† che un dischetto sia difettoso √® pari a 0.01. L'azienda vende i dischetti
in confezioni da 10 e rimborsa l'acquirente se pi√π di 1 dischetto √® difettoso.
<ol class="org-ol">
<li>Quale proporzione delle confezioni sar√† restituita?</li>
<li>Se un acquirente acquista 3 scatole, qual'√® la probabilit√† che ne restituisca esattamente 1?</li>
</ol></li>
</ul>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
1 - pbinom(1, 10, 0.01)
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">pbinom(1, 10, 0.01, lower.t=FALSE)</span>

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
dbinom(1, 3, 0.0042662)
</pre>
</div>

<pre class="example">
[1] 0.0042662
[1] 0.01268963

</pre>

<p>
Esercizio 4:
</p>
<ul class="org-ul">
<li>Supponiamo che il numero di errori tipografici presenti in una singola pagina di un libro sia distribuito secondo
una Poisson con parametri \(\lambda=1\).
<ul class="org-ul">
<li>Si calcoli la probabilit√† che vi sia almeno un errore in una data pagina.</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">ppois(0, lambda=1, lower.t=<span style="color: #0097A7;">FALSE</span>)
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">1 - ppois(0, 1)</span>
</pre>
</div>

<pre class="example">
[1] 0.6321206

</pre>

<p>
Esercizio 7:
</p>
<ul class="org-ul">
<li>Si supponga che la probabilit√† che un prodotto costruito da una macchina sia difettoso √® pari a 0.1.
<ol class="org-ol">
<li>Si trovi la probabilit√† che un campione di 10 prodotti contenga al pi√π un prodotto difettoso;</li>
<li>Si trovi la probabilit√† che un campione di 10 prodotti contenga tra 3 e i 5 prodotti difettosi.</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
ppois(1, lambda=10*0.1)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
diff(ppois(c(2, 5), lambda=10*0.1))
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Equivale a:</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">dpois(3, lambda=10*0.1) + dpois(4, lambda=10*0.1) + dpois(5, lambda=10*0.1)</span>
</pre>
</div>

<pre class="example">
[1] 0.7357589
[1] 0.07970721

</pre>

<p>
Es:
</p>
<ul class="org-ul">
<li>Tracciare il grafico della distribuzione della variabile casuale di Poisson per \(\lambda=1\)</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">plot(c(0:5), dpois(0:5, 1), type=<span style="color: #689f38;">"h"</span>, xlab=<span style="color: #689f38;">"X"</span>)
text(c(0:5), dpois(0:5, 1), round(dpois(0:5, 1), 4))
</pre>
</div>


<div class="figure">
<p><img src="graf_pois.png" alt="graf_pois.png" />
</p>
</div>

<p>
Es:
</p>
<ul class="org-ul">
<li>Un calciatore ha una probabilit√† di segnare un calcio di rigore di 0.812. Si supponga che tirare un calcio di rigore
sia un evento Bernoulliano.
<ol class="org-ol">
<li>Qual'√® la probabilit√† che sbagli 5 calci di rigore prima di segnarne uno?</li>
<li>Qual'√® la probabilit√† che sbagli al massimo 5 calci di rigore prima di segnarne uno?</li>
<li>Qual'√® la probabilit√† che sbagli almeno 5 calci di rigore prima di segnarne uno?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
dgeom(5, prob=0.812)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
pgeom(5, prob=0.812)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
pgeom(4, prob=0.812, lower.tail=<span style="color: #0097A7;">FALSE</span>)
</pre>
</div>

<pre class="example">
null device 
          1
[1] 0.0001906976
[1] 0.9999558
[1] 0.0002348493

</pre>

<p>
Esercizio 5:
</p>
<ul class="org-ul">
<li>In media su un'autostrada si verificano 3 incidenti al giorno.
<ul class="org-ul">
<li>Qual'√® la probabilit√† che non si verifichino incidenti oggi?</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">lambda <span style="color: #558b2f;">&lt;-</span> 3
incidenti <span style="color: #558b2f;">&lt;-</span> 0

dpois(incidenti, lambda)
</pre>
</div>

<pre class="example">
[1] 0.04978707

</pre>

<p>
Esercizio 13:
</p>
<ul class="org-ul">
<li>Da un mazzo di 52 carte ne vengono estratte 5 con reinserimento. Si √® interessati alla variabile casuale \(X\) che descrive
il numero di carte di cuori ottenute nelle estrazioni. Determinare:
<ol class="org-ol">
<li>Il valore atteso e la varianza della variabile \(X\);</li>
<li>La probabilit√† di estrarre 3 carte di cuori;</li>
<li>La probabilit√† di estrarre almeno 3 carte di cuori;</li>
<li>La probabilit√† di estrarre al pi√π 3 carte di cuori.</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">pcuori <span style="color: #558b2f;">&lt;-</span> 1/4
numero_estrazioni <span style="color: #558b2f;">&lt;-</span> 5
numero_cuori <span style="color: #558b2f;">&lt;-</span> 13

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
mu <span style="color: #558b2f;">&lt;-</span> pcuori*numero_estrazioni
mu

var <span style="color: #558b2f;">&lt;-</span> mu*(1-pcuori)
var

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
numero_cuori_estratti <span style="color: #558b2f;">&lt;-</span> 3
dbinom(numero_cuori_estratti, numero_estrazioni, pcuori)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
pbinom(numero_cuori_estratti-1, numero_estrazioni, pcuori, lower.tail=<span style="color: #0097A7;">FALSE</span>)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">4</span>
pbinom(numero_cuori_estratti, numero_estrazioni, pcuori)
</pre>
</div>

<pre class="example">
[1] 1.25
[1] 0.9375
[1] 0.08789063
[1] 0.1035156
[1] 0.984375

</pre>

<p>
Esercizio 15:
</p>
<ul class="org-ul">
<li>Il numero \(X\) di telefonate ricevute nell'intervallo di tempo \([0, t_o]\) √® una variabile aleatoria distribuita secondo una
distribuzione di Poisson con parametro \(\lambda = t_0\).
<ul class="org-ul">
<li>Calcolare la probabilit√† \(P(2 \leq X \leq 4)\) di ricevere da 2 a 4 telefonate (2 e 4 inclusi) entro l'istante \(t_0 = 1\).</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">lambda <span style="color: #558b2f;">&lt;-</span> 1
lower <span style="color: #558b2f;">&lt;-</span> 2
upper <span style="color: #558b2f;">&lt;-</span> 4

ppois(upper, lambda) - ppois(lower-1, lambda)
</pre>
</div>

<pre class="example">
[1] 0.2605813

</pre>

<p>
Esercizio 16:
</p>
<ul class="org-ul">
<li>In un dato canale di comunicazione sappiamo che la probabilit√† di ricevere in modo errato un singolo messaggio √® pari a 0.01.
Sapendo che viene inviata una sequenza di 150 messaggi, e che i messaggi trasmessi sono stocasticamente indipendenti tra loro,
ci si chiede:
<ul class="org-ul">
<li>Quale sia la probabilit√† che 2 dei messaggi ricevuti siano errati.</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">p <span style="color: #558b2f;">&lt;-</span> 0.01
n <span style="color: #558b2f;">&lt;-</span> 150
lambda <span style="color: #558b2f;">&lt;-</span> p*n
n_messaggi_errati <span style="color: #558b2f;">&lt;-</span> 2

binom <span style="color: #558b2f;">&lt;-</span> dbinom(n_messaggi_errati, n, p)
binom
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Approssimativamente:</span>
pois <span style="color: #558b2f;">&lt;-</span> dpois(n_messaggi_errati, lambda)
pois
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Errore approssimazione:</span>
binom-pois
</pre>
</div>

<pre class="example">
[1] 0.2524971
[1] 0.2510214
[1] 0.001475634

</pre>

<p>
Esercizio 17:
</p>
<ul class="org-ul">
<li>In una certa provincia montuosa si pu√≤ supporre che il numero \(X\) di frane al mese sia una variabile aleatoria con la legge
di Poisson di parametro \(\lambda = 2.3\).
<ol class="org-ol">
<li>Calcolare la probabilit√† che ci siano almeno 2 frane in un dato mese;</li>
<li>Quanto dovrebbe valere il parametro \(\lambda\) affinch√© la probabilit√† che in un mese non ci siano frane sia superiore a \(1/2\)?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">lambda <span style="color: #558b2f;">&lt;-</span> 2.3
frane_min <span style="color: #558b2f;">&lt;-</span> 2

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
ppois(frane_min-1, lambda, lower.tail=<span style="color: #0097A7;">FALSE</span>)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
lambdaB = log(1/p)
lambdaB
cat(<span style="color: #689f38;">'lambda &lt;'</span>, lambdaB)
</pre>
</div>

<pre class="example">
[1] 0.6691458
[1] 4.60517

</pre>

<p>
Esercizio 18:
</p>
<ul class="org-ul">
<li>Il "Crazy Boat" √® un battello a due motori utilizzato per le crociere sul Tamigi. I due motori lavorano indipendentemente
e il numero di piccoli guasti in una singola crociera √® modellabile tramite una v.a. \(X\) di Poisson di parametro 1 per il
primo motore, e da una v.a. \(Y\) di Poisson di parametro 2 per il secondo.
<ol class="org-ol">
<li>Qual'√® la distribuzione della v.a. \(X+Y\)?</li>
<li>Calcolare la probabilit√† che non avvenga alcun guasto in una data crociera;</li>
<li>Partono 10 modelli identici "Crazy Boat"; calcolare la probabilit√† che almeno 2 battelli concludano la crociera
senza guasti.</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
lambda <span style="color: #558b2f;">&lt;-</span> 3

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
guasti <span style="color: #558b2f;">&lt;-</span> 0
p_noguasti <span style="color: #558b2f;">&lt;-</span> dpois(guasti, lambda)
p_noguasti

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
battelli_min <span style="color: #558b2f;">&lt;-</span> 2
modelli <span style="color: #558b2f;">&lt;-</span> 10
pbinom(battelli_min-1, modelli, p_noguasti, lower.tail=<span style="color: #0097A7;">FALSE</span>)
</pre>
</div>

<pre class="example">
[1] 0.04978707
[1] 0.08550346

</pre>

<p>
Il package <code>distr</code> contiene classi per gestire una grande variet√† di distribuzioni:
</p>


<div class="figure">
<p><img src="Laboratorio/screenshot_2018-04-05_21-54-10.png" alt="screenshot_2018-04-05_21-54-10.png" />
</p>
</div>

<p>
Uniforme:
</p>

<p>
Esempio 1:
</p>
<ul class="org-ul">
<li>Sia \(X\) una v.c. che rappresenta la probabilit√† di ricevere una telefonata tra le 10 e le 10.30. Si calcoli la probabilit√†
che la chiamata arrivi tra le 10:10 e le 10:20. \(X\) √® distribuita secondo una variabile uniforma con parametri \(a=0\) e \(b=30\).</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">diff(punif(c(10, 20), 0, 30))
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">punif(20, 0, 30) - punif(10, 0, 30)</span>
</pre>
</div>

<pre class="example">
[1] 0.3333333

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #558b2f;">library</span>(distr)
X <span style="color: #558b2f;">&lt;-</span> Unif(Min=0, Max=30)
plot(X, to.draw.args=c(<span style="color: #689f38;">"d"</span>, <span style="color: #689f38;">"p"</span>))
</pre>
</div>


<div class="figure">
<p><img src="grafunif.png" alt="grafunif.png" />
</p>
</div>

<p>
Es:
</p>
<ul class="org-ul">
<li>Generare 10 numeri da una distribuzione uniforme compresa tra 0 e 50.</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">runif(n=10, min=0, max=50)
</pre>
</div>

<pre class="example">
Loading required package: startupmsg
:startupmsg&gt;  Utilities for Start-Up Messages (version 0.9.4)
:startupmsg&gt; 
:startupmsg&gt;  For more information see ?"startupmsg",
:startupmsg&gt;  NEWS("startupmsg")

Loading required package: sfsmisc
Loading required package: SweaveListingUtils
:SweaveListingUtils&gt;  Utilities for Sweave Together with
:SweaveListingUtils&gt;  TeX 'listings' Package (version
:SweaveListingUtils&gt;  0.7.7)
:SweaveListingUtils&gt; 
:SweaveListingUtils&gt;  NOTE: Support for this package
:SweaveListingUtils&gt;  will stop soon.
:SweaveListingUtils&gt; 
:SweaveListingUtils&gt;  Package 'knitr' is providing the
:SweaveListingUtils&gt;  same functionality in a better
:SweaveListingUtils&gt;  way.
:SweaveListingUtils&gt; 
:SweaveListingUtils&gt;  Some functions from package 'base'
:SweaveListingUtils&gt;  are intentionally masked ---see
:SweaveListingUtils&gt;  SweaveListingMASK().
:SweaveListingUtils&gt; 
:SweaveListingUtils&gt;  Note that global options are
:SweaveListingUtils&gt;  controlled by
:SweaveListingUtils&gt;  SweaveListingoptions() ---c.f.
:SweaveListingUtils&gt;  ?"SweaveListingoptions".
:SweaveListingUtils&gt; 
:SweaveListingUtils&gt;  For more information see
:SweaveListingUtils&gt;  ?"SweaveListingUtils",
:SweaveListingUtils&gt;  NEWS("SweaveListingUtils")
:SweaveListingUtils&gt;  There is a vignette to this
:SweaveListingUtils&gt;  package; try
:SweaveListingUtils&gt;  vignette("ExampleSweaveListingUtils").


Attaching package: ‚ÄòSweaveListingUtils‚Äô

The following objects are masked from ‚Äòpackage:base‚Äô:

    library, require

:distr&gt;  Object Oriented Implementation of Distributions (version
:distr&gt;  2.6.2)
:distr&gt; 
:distr&gt;  Attention: Arithmetics on distribution objects are
:distr&gt;  understood as operations on corresponding random variables
:distr&gt;  (r.v.s); see distrARITH().
:distr&gt; 
:distr&gt;  Some functions from package 'stats' are intentionally masked
:distr&gt;  ---see distrMASK().
:distr&gt; 
:distr&gt;  Note that global options are controlled by distroptions()
:distr&gt;  ---c.f. ?"distroptions".
:distr&gt; 
:distr&gt;  For more information see ?"distr", NEWS("distr"), as well as
:distr&gt;    http://distr.r-forge.r-project.org/
:distr&gt;  Package "distrDoc" provides a vignette to this package as
:distr&gt;  well as to several extension packages; try
:distr&gt;  vignette("distr").


Attaching package: ‚Äòdistr‚Äô

The following objects are masked from ‚Äòpackage:stats‚Äô:

    df, qqplot, sd

null device 
          1
 
[1] 37.498461 18.300084 13.047373 28.028070 11.834291 20.264217 25.819957
 [8] 11.167059  1.040536 25.571013
</pre>

<p>
Esercizio 8:
</p>
<ul class="org-ul">
<li>Un bus arriva ad una data fermata ad intervalli di 15 minuti a partire dalle ore 7:00. Poich√© il bus passa ogni quarto d'ora,
se un passeggero arriva alla fermata in un istante di tempo uniformemente distribuito nell'intervallo 7:00-7:30, si determino:
<ol class="org-ol">
<li>La probabilit√† che attenda meno di 5 minuti;</li>
<li>La probabilit√† che attenda almeno 12 minuti;</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
(punif(15, 0, 30) - punif(10, 0, 30)) + (punif(30, 0, 30) - punif(25, 0, 30))

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
(punif(3, 0, 30) - punif(0, 0, 30)) + (punif(18, 0, 30) - punif(15, 0, 30))
</pre>
</div>

<pre class="example">
[1] 0.3333333
[1] 0.2

</pre>

<p>
Esponenziale:
</p>

<p>
Esempio 2:
</p>
<ul class="org-ul">
<li>Sia \(X\) una v.c. che rappresenta la durata di una batteria in mesi. \(X\) √® distribuita secondo un'esponenziale
con parametro \(\lambda = 0.2\).
<ol class="org-ol">
<li>Si calcoli la probabilit√† che una batteria duri tra i 4 e i 6 mesi;</li>
<li>Si calcoli la probabilit√† che una batteria duri almeno 10 mesi;</li>
<li>Si calcoli la probabilit√† che una batteria duri almeno 10 mesi;</li>
<li>Si calcoli la probabilit√† che una batteria duri altri 10 mesi sapendo che la batteria sta durando da 4 mesi.</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
diff(pexp(c(4, 6), rate=0.2))

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
pexp(10, rate=0.2, lower.tail=<span style="color: #0097A7;">FALSE</span>)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
pexp(14, rate=0.2, lower.tail=<span style="color: #0097A7;">FALSE</span>)/pexp(4, rate=0.2, lower.tail=<span style="color: #0097A7;">FALSE</span>)
</pre>
</div>

<pre class="example">
[1] 0.1481348
[1] 0.1353353
[1] 0.1353353

</pre>

<p>
Es:
</p>
<ul class="org-ul">
<li>Generare 10 numeri da una distribuzione esponenziale con \(\lambda = 0.4\).</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">rexp(10, rate=0.4)
</pre>
</div>

<pre class="example">
[1] 4.0737930 2.0113980 0.7364057 1.7908249 0.3227216 9.8757692 1.4179396
[8] 6.3137443 5.7167530 3.2930921

</pre>

<p>
Esercizio 12:
</p>
<ul class="org-ul">
<li>Un certo tipo di componenti elettronici viene prodotto da una ditta che utilizza 2 linee di produzione. La prima di queste
produce il 40% dei pezzi ed i pezzi prodotti hanno un tempo di vita che segue una legge esponenziale di parametro \(\lambda_1 = 1.5\).
La seconda invece produce il 60% dei pezzi ed i pezzi prodotti hanno tempo di vita che segue una legge esponenziale di
parametro \(\lambda_2 = 2\). Un componente viene scelto a caso tra quelli prodotti dalle 2 linee e indichiamone con \(X\) il suo
tempo di vita.
<ol class="org-ol">
<li>Qual'√® la probabilit√† che sia ancora funzionante al tempo \(t = 1\)?</li>
<li>Sapendo che √® ancora funzionante al tempo \(t=1\), qual'√® la probabilit√† che esso sia ancora funzionante la tempo \(t=2\)?</li>
<li>Qual'√® la probabilit√† che su 7 componenti scelti a caso e in modo indipendente l'uno dall'altro, almeno 3 siano ancora
funzionanti al tempo \(t=1\)?</li>
<li>Supponiamo di scegliere a caso ed in modo indipendente dei componenti. Qual'√® la probabilit√† che il primo pezzo non
funzionante al tempo \(t=1\) sia il secondo esaminato?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">l1 <span style="color: #558b2f;">&lt;-</span> 0.4
l2 <span style="color: #558b2f;">&lt;-</span> 0.6
lambda1 <span style="color: #558b2f;">&lt;-</span> 1.5
lambda2 <span style="color: #558b2f;">&lt;-</span> 2

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
t1 <span style="color: #558b2f;">&lt;-</span> 1
funz_1 <span style="color: #558b2f;">&lt;-</span> pexp(t1, lambda1, lower.tail=<span style="color: #0097A7;">FALSE</span>)*l1 + pexp(t1, lambda2, lower.tail=<span style="color: #0097A7;">FALSE</span>)*l2
funz_1

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
t2 <span style="color: #558b2f;">&lt;-</span> 2
funz_2 <span style="color: #558b2f;">&lt;-</span> pexp(t2, lambda1, lower.tail=<span style="color: #0097A7;">FALSE</span>)*l1 + pexp(t2, lambda2, lower.tail=<span style="color: #0097A7;">FALSE</span>)*l2
funz_2/funz_1

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
funz_min <span style="color: #558b2f;">&lt;-</span> 3
n_componenti <span style="color: #558b2f;">&lt;-</span> 7
pbinom(funz_min-1, n_componenti, funz_1, lower.t=<span style="color: #0097A7;">FALSE</span>)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">4</span>
funz_1*(1-funz_1)
</pre>
</div>

<pre class="example">
[1] 0.1704532
[1] 0.1813061
[1] 0.1011738
[1] 0.1413989

</pre>

<p>
Esercizio 14:
</p>
<ul class="org-ul">
<li>L'istante d'arrivo dell'autobus √® uniformemente distribuito tra le 10:00 e le 10:30. Tu arrivi alla fermata dell'autobus alle 10:00.
<ol class="org-ol">
<li>Qual'√® la probabilit√† che tu debba aspettare pi√π di 10 minuti?</li>
<li>Quanto tempo aspetti in media? Con quale deviazione standard?</li>
<li>Se l'autobus non √® ancora passato alle 10:10, qual'√® la probabilit√† che tu debba aspettare almeno altri 10 minuti?</li>
<li>Supponi di arrivare alla fermata dell'autobus alle 10 per 100 giorni. Calcola, in modo approssimato, la probabilit√† che il tempo
totale speso ad attendere l'autobus sia superiore a 1 giorno.</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">min <span style="color: #558b2f;">&lt;-</span> 0
max <span style="color: #558b2f;">&lt;-</span> 30

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
minuti_min1 <span style="color: #558b2f;">&lt;-</span> 10
t_maggiore_10 <span style="color: #558b2f;">&lt;-</span> punif(minuti_min1, min, max, lower.t=<span style="color: #0097A7;">FALSE</span>)
t_maggiore_10

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
mean <span style="color: #558b2f;">&lt;-</span> (min + max)/2
mean
stdev <span style="color: #558b2f;">&lt;-</span> sqrt((max - min)^2/12)
stdev

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
minuti_min2 <span style="color: #558b2f;">&lt;-</span> 20
t_maggiore_20 <span style="color: #558b2f;">&lt;-</span> punif(minuti_min2, min, max, lower.t=<span style="color: #0097A7;">FALSE</span>)
t_maggiore_20/t_maggiore_10

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">4</span>
minuti_min <span style="color: #558b2f;">&lt;-</span> 1440
giorni <span style="color: #558b2f;">&lt;-</span> 100
pnorm(minuti_min, mean=mean*100, sd=sqrt(giorni)*stdev, lower.t=<span style="color: #0097A7;">FALSE</span>)

</pre>
</div>

<pre class="example">
[1] 0.6666667
[1] 15
[1] 8.660254
[1] 0.5
[1] 0.7557888

</pre>

<p>
Normale:
</p>

<p>
Esempio 3.1:
</p>
<ul class="org-ul">
<li>Sia \(X\) una variabile aleatoria con distribuzione normale di parametri \(\mu=10\) e \(\sigma=1\) e si voglia determinare la probabilit√†
dell'evento "\(X \in [9.2, 11.35]\)"</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">pnorm(11.35, mean=10) - pnorm(9.2, mean=10)
</pre>
</div>

<pre class="example">
[1] 0.6996366

</pre>

<p>
Esempio:
</p>
<ul class="org-ul">
<li>Sia \(X\) una variabile che rappresenta il risultato ad un test sul QI. \(X\) √® distribuita secondo una variabile normale con media 100
e deviazione standard 15. Si calcoli la probabilit√† che una persona abbia un QI tra 85 e 115.di</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">diff(pnorm(c(85, 115), mean=100, sd=5))
</pre>
</div>

<pre class="example">
[1] 0.9973002

</pre>

<p>
Grafico distribuzione normale:
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #558b2f;">library</span>(distr)
X <span style="color: #558b2f;">&lt;-</span> Norm(mean=100, sd=15)
plot(X, to.draw.arg=c(<span style="color: #689f38;">"d"</span>, <span style="color: #689f38;">"p"</span>))
</pre>
</div>


<div class="figure">
<p><img src="grafnorm.png" alt="grafnorm.png" />
</p>
</div>

<p>
Es:
</p>
<ol class="org-ol">
<li>\(P(X \in [\mu - \sigma, \mu + \sigma]) = 0.683\);</li>
<li>\(P(X \in [\mu - 2\sigma, \mu + 2\sigma]) = 0.954\);</li>
<li>\(P(X \in [\mu - 3\sigma, \mu + 3\sigma]) = 0.997\)</li>
</ol>
<div class="org-src-container">
<pre class="src src-R">pnorm(1:3) - pnorm(-(1:3))
</pre>
</div>

<pre class="example">
null device 
          1
[1] 0.6826895 0.9544997 0.9973002

</pre>

<p>
Es:
</p>
<ul class="org-ul">
<li>Generare 1000 numeri da una normale standardizzata</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">rand <span style="color: #558b2f;">&lt;-</span> rnorm(1000)
hist(rand)
</pre>
</div>


<div class="figure">
<p><img src="grafrandnorm.png" alt="grafrandnorm.png" />
</p>
</div>

<p>
Esempio precedente sul QI:
</p>
<ul class="org-ul">
<li>Qual'√® il minimo QI che una persona deve avere per essere nell'1% delle persone con il QI pi√π alto?</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">qnorm(0.99, mean=100, sd=15)
</pre>
</div>

<pre class="example">
null device 
          1
[1] 134.8952

</pre>

<p>
Es:
</p>
<ul class="org-ul">
<li>Calcolare \(z_{0.025}, z_0.01\) e \(z_{0.05}\)</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">qnorm(c(0.025, 0.01, 0.005), lower.t=<span style="color: #0097A7;">FALSE</span>)
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">qnorm(c(0.975, 0.99, 0.995))</span>
</pre>
</div>

<pre class="example">
[1] 1.959964 2.326348 2.575829

</pre>

<p>
Esercizio 9:
</p>
<ul class="org-ul">
<li>Se \(X\) √® una variabile distribuita secondo una normale con \(\mu=3\) e \(\sigma^2=16\), si determini:
<ol class="org-ol">
<li>\(P(X < 11)\);</li>
<li>\(P(X > -1)\);</li>
<li>\(P(2 < X < 7)\)</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
pnorm(11, mean=3, sd=sqrt(16))

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
pnorm(-1, mean=3, sd=4, lower.t=<span style="color: #0097A7;">FALSE</span>)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
pnorm(7, mean=3, sd=4) - pnorm(2, mean=3, sd=4)
</pre>
</div>

<pre class="example">
[1] 0.9772499
[1] 0.8413447
[1] 0.4400511

</pre>

<p>
Esercizio 10:
</p>
<ul class="org-ul">
<li>Un'industria produce su commissione delle sbarre d'acciaio cilindriche, il cui diametro dovrebbe essere di 4 cm, ma che tuttavia
sono accettabili se hanno diametro compreso tra 3.95 cm e 4.05 cm. Il cliente, nel controllare le sbarre fornitegli, constata che
il 5% sono di diametro inferiore al minimo tollerato ed il 12% di diametro superiore al massimo tollerato.
<ol class="org-ol">
<li>Supponendo che le misure dei diametri seguano una legge normale, determinare media e deviazione standard;</li>
<li>Mantenendo la media precedentemente calcolata, determinare quale dovrebbe essere il valore massimo della deviazione
standard affinch√© la probabilit√† che le sbarre abbiano un diametro superiore al massimo tollerato sia minore di 0.05.</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">m1 <span style="color: #558b2f;">&lt;-</span> 5
m2 <span style="color: #558b2f;">&lt;-</span> 12
max <span style="color: #558b2f;">&lt;-</span> 4.05
min <span style="color: #558b2f;">&lt;-</span> 3.95

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
q1 <span style="color: #558b2f;">&lt;-</span> qnorm(m1/100)
q2 <span style="color: #558b2f;">&lt;-</span> qnorm(m2/100, lower.t=<span style="color: #0097A7;">FALSE</span>)
sd <span style="color: #558b2f;">&lt;-</span> (max-min)/(q2-q1)
sd
mean <span style="color: #558b2f;">&lt;-</span> min-q1*sd
mean

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
q3 <span style="color: #558b2f;">&lt;-</span> qnorm(1-m1/100, mean=mean, sd=1)
sd2 <span style="color: #558b2f;">&lt;-</span> (max)/q3
cat(<span style="color: #689f38;">"sd &lt; "</span>, sd2)
</pre>
</div>

<pre class="example">
[1] 0.035463
[1] 4.008331

</pre>

<p>
Esercizio 11:
</p>
<ul class="org-ul">
<li>Un'azienda stipula un contratto per vendere barattoli di conserva da 500g. La quantit√† di conserva \(X\) messa in ciascun barattolo
√® predeterminata meccanicamente ed √® normalmente distribuita con media \(\mu\) e deviazione standard 25g.
<ol class="org-ol">
<li>A quale valore minimo \(\mu\) deve essere tarata la macchina, perch√© non pi√π del 2% dei barattoli contenga meno di 500g di conserva?</li>
<li>Supponiamo che i barattoli siano di metallo e che il loro peso \(Y\) da vuoti segua una distribuzione \(N(mean=90, V=64)\). Se un
ispettore pesa i barattoli pieni e scarta quelli il cui peso √® inferiore a 590g, quale percentuale di barattoli non
passer√† l'ispezione?</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">sd1 <span style="color: #558b2f;">&lt;-</span> 25

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
p <span style="color: #558b2f;">&lt;-</span> 2/100
g <span style="color: #558b2f;">&lt;-</span> 500
q <span style="color: #558b2f;">&lt;-</span> qnorm(p)
mean1 <span style="color: #558b2f;">&lt;-</span> g - q*sd1
mean1

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
mean2 <span style="color: #558b2f;">&lt;-</span> 90
v2 <span style="color: #558b2f;">&lt;-</span> 64
sd2 <span style="color: #558b2f;">&lt;-</span> sqrt(v2)
pnorm(590, mean1+mean2, sqrt(sd1^2+sd2^2))
</pre>
</div>

<pre class="example">
[1] 551.3437
[1] 0.02523022

</pre>

<p>
Chi-Quadro:
</p>
<div class="org-src-container">
<pre class="src src-R">curve(dchisq(x, df=3), from=0, to=20, ylab=<span style="color: #689f38;">"y"</span>)
ind <span style="color: #558b2f;">&lt;-</span> c(4, 5, 10, 15)
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> ind) curve(dchisq(x, df=i), 0, 20, add=<span style="color: #0097A7;">TRUE</span>, col=i)
legend(<span style="color: #689f38;">"topright"</span>, legend=c(<span style="color: #689f38;">"3 gl"</span>, <span style="color: #689f38;">"4 gl"</span>, <span style="color: #689f38;">"5 gl"</span>, <span style="color: #689f38;">"10 gl"</span>, <span style="color: #689f38;">"15 gl"</span>),
       col=c(<span style="color: #689f38;">"Black"</span>, <span style="color: #689f38;">"Blue"</span>, <span style="color: #689f38;">"light Blue"</span>, <span style="color: #689f38;">"Red"</span>, <span style="color: #689f38;">"Yellow"</span>), lty=c(1, 1, 1, 1, 1), lwd=c(3, 3, 3, 3, 3))
</pre>
</div>


<div class="figure">
<p><img src="grafdchiquadro.png" alt="grafdchiquadro.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-R">curve(pchisq(x, df=3), from=0, to=20, ylab=<span style="color: #689f38;">"y"</span>)
ind <span style="color: #558b2f;">&lt;-</span> c(4, 5, 10, 15)
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> ind) curve(pchisq(x, df=i), 0, 20, add=<span style="color: #0097A7;">TRUE</span>, col=i)
legend(<span style="color: #689f38;">"topright"</span>, legend=c(<span style="color: #689f38;">"3 gl"</span>, <span style="color: #689f38;">"4 gl"</span>, <span style="color: #689f38;">"5 gl"</span>, <span style="color: #689f38;">"10 gl"</span>, <span style="color: #689f38;">"15 gl"</span>),
       col=c(<span style="color: #689f38;">"Black"</span>, <span style="color: #689f38;">"Blue"</span>, <span style="color: #689f38;">"light Blue"</span>, <span style="color: #689f38;">"Red"</span>, <span style="color: #689f38;">"Yellow"</span>), lty=c(1, 1, 1, 1, 1), lwd=c(3, 3, 3, 3, 3))
</pre>
</div>


<div class="figure">
<p><img src="grafpchiquadro.png" alt="grafpchiquadro.png" />
</p>
</div>

<p>
T di Student:
</p>

<div class="org-src-container">
<pre class="src src-R">curve(dt(x, df=1), from=-4, to=4, ylim=c(0, 0.4), ylab=<span style="color: #689f38;">"y"</span>)
ind <span style="color: #558b2f;">&lt;-</span> c(3, 5, 10, 15)
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> ind) curve(dt(x, df=i), -4, 4, add=<span style="color: #0097A7;">TRUE</span>, col=i)
legend(<span style="color: #689f38;">"topright"</span>, legend=c(<span style="color: #689f38;">"1 gl"</span>, <span style="color: #689f38;">"3 gl"</span>, <span style="color: #689f38;">"5 gl"</span>, <span style="color: #689f38;">"10 gl"</span>),
       col=c(<span style="color: #689f38;">"Black"</span>, <span style="color: #689f38;">"Green"</span>, <span style="color: #689f38;">"light Blue"</span>, <span style="color: #689f38;">"Red"</span>), lty=c(1, 1, 1, 1), lwd=c(3, 3, 3, 3))
</pre>
</div>


<div class="figure">
<p><img src="grafdt.png" alt="grafdt.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-R">curve(pt(x, df=1), from=-4, to=4, ylim=c(0, 1), ylab=<span style="color: #689f38;">"y"</span>)
ind <span style="color: #558b2f;">&lt;-</span> c(3, 5, 10, 15)
<span style="color: #00796b;">for</span> (i <span style="color: #00796b;">in</span> ind) curve(pt(x, df=i), -4, 4, add=<span style="color: #0097A7;">TRUE</span>, col=i)
legend(<span style="color: #689f38;">"topleft"</span>, legend=c(<span style="color: #689f38;">"1 gl"</span>, <span style="color: #689f38;">"3 gl"</span>, <span style="color: #689f38;">"5 gl"</span>, <span style="color: #689f38;">"10 gl"</span>),
       col=c(<span style="color: #689f38;">"Black"</span>, <span style="color: #689f38;">"Green"</span>, <span style="color: #689f38;">"light Blue"</span>, <span style="color: #689f38;">"Red"</span>), lty=c(1, 1, 1, 1), lwd=c(3, 3, 3, 3))
</pre>
</div>


<div class="figure">
<p><img src="grafpt.png" alt="grafpt.png" />
</p>
</div>

<p>
Esempio:
</p>
<ul class="org-ul">
<li>Il grafico della distribuzione t di Student con 9 gradi di libert√† √® il seguente:</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">curve(dt(x, df=9), from=-4, to=4, ylim=c(0, 0.4), ylab=<span style="color: #689f38;">"y"</span>)
</pre>
</div>


<div class="figure">
<p><img src="grafdt9.png" alt="grafdt9.png" />
</p>
</div>

<p>
Trovare:
</p>
<ul class="org-ul">
<li>Il valore di \(t_1\) tale per cui:
<ol class="org-ol">
<li>L'area a destra di \(t1\) √® pari a 0.05;</li>
<li>Il totale dell'area a sinistra di \(-t_1\) e a destra di \(t_1\) √® pari a 0.05;</li>
<li>Il totale dell'area compresa tra \(-t_1\) e \(t_1\) √® pari a 0.99.</li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
qt(0.95, df=9)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
qt(0.975, df=9)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
qt(0.995, df=9)
</pre>
</div>

<pre class="example">
null device 
          1
null device 
          1
null device 
          1
null device 
          1
null device 
          1
[1] 1.833113
[1] 2.262157
[1] 3.249836
</pre>

<p>
F di Fisher:
</p>
<div class="org-src-container">
<pre class="src src-R">curve(df(x, df1=3, df2=3), 0, +3, ylim=c(0, 1.3), col=<span style="color: #689f38;">"Black"</span>, lwd=3)
curve(df(x, df1=5, df2=10), 0, +3, col=<span style="color: #689f38;">"Blue"</span>, lwd=3, add=<span style="color: #0097A7;">TRUE</span>)
curve(df(x, df1=30, df2=50), 0, +3, col=<span style="color: #689f38;">"Red"</span>, lwd=3, add=<span style="color: #0097A7;">TRUE</span>)
legend(<span style="color: #689f38;">"topright"</span>, legend=c(<span style="color: #689f38;">"3,3 gl"</span>, <span style="color: #689f38;">"5,10 gl"</span>, <span style="color: #689f38;">"30,50 gl"</span>),
       col=c(<span style="color: #689f38;">"Black"</span>, <span style="color: #689f38;">"Blue"</span>, <span style="color: #689f38;">"Red"</span>), lty=c(1, 1, 1), lwd=c(3, 3, 3))
</pre>
</div>


<div class="figure">
<p><img src="grafdf.png" alt="grafdf.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-R">curve(pf(x, df1=3, df2=3), 0, 10, ylim=c(0, 1), col=<span style="color: #689f38;">"Black"</span>, lwd=3)
curve(pf(x, df1=5, df2=10), 0, 10, col=<span style="color: #689f38;">"Blue"</span>, lwd=3, add=<span style="color: #0097A7;">TRUE</span>)
curve(pf(x, df1=30, df2=50), 0, 10, col=<span style="color: #689f38;">"Red"</span>, lwd=3, add=<span style="color: #0097A7;">TRUE</span>)
legend(<span style="color: #689f38;">"topright"</span>, legend=c(<span style="color: #689f38;">"3,3 gl"</span>, <span style="color: #689f38;">"5,10 gl"</span>, <span style="color: #689f38;">"30,50 gl"</span>),
       col=c(<span style="color: #689f38;">"Black"</span>, <span style="color: #689f38;">"Blue"</span>, <span style="color: #689f38;">"Red"</span>), lty=c(1, 1, 1), lwd=c(3, 3, 3))
</pre>
</div>


<div class="figure">
<p><img src="grafpf.png" alt="grafpf.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-org5f5f532" class="outline-4">
<h4 id="org5f5f532"><span class="section-number-4">3.2.4</span> Stime di Parametri</h4>
<div class="outline-text-4" id="text-3-2-4">
<p>
Libreria utilizzata:
</p>
<ul class="org-ul">
<li><p>
Library:
</p>
<div class="org-src-container">
<pre class="src src-R">  <span style="color: #607d8b;">#</span><span style="color: #607d8b;">install.packages("TeachingDemos")</span>
  <span style="color: #558b2f;">require</span>(<span style="color: #689f38;">"TeachingDemos"</span>)
</pre>
</div>

<pre class="example">
Carico il pacchetto richiesto: TeachingDemos

</pre></li>
</ul>

<p>
Intervalli di confidenza per la media:
</p>
<ul class="org-ul">
<li><p>
Popolazione non normalmente distribuita e varianza sconosiuta:
</p>
<div class="org-src-container">
<pre class="src src-R">  z.test(x, mu=0, stdev, alternative=c(<span style="color: #689f38;">"two.sided"</span>, <span style="color: #689f38;">"less"</span>, <span style="color: #689f38;">"greater"</span>), sd=stdev, n=length(x), conf.level=0.95, ...)
</pre>
</div></li>
<li><p>
Popolazione non normalmente distribuita e varianza nota:
</p>
<div class="org-src-container">
<pre class="src src-R">  z.test()
</pre>
</div></li>
<li><p>
Popolazione normalmente distribuita e varianza nota:
</p>
<pre class="example">
  z.test()  
</pre></li>
<li><p>
Popolazione normalmente distribuita e varianza sconosiuta:
</p>
<div class="org-src-container">
<pre class="src src-R">  z.test(x, y=<span style="color: #0097A7;">NULL</span>, alternative=c(<span style="color: #689f38;">"two.sided"</span>, <span style="color: #689f38;">"less"</span>, <span style="color: #689f38;">"greater"</span>), mu=0, paired=<span style="color: #0097A7;">FALSE</span>, var.equal=<span style="color: #0097A7;">FALSE</span>, conf.level=0.95, ...)
</pre>
</div></li>
</ul>

<p>
Esercizio 08:
</p>
<ul class="org-ul">
<li>Popolazione non normalmente distribuita e varianza nota;</li>
<li>Da un lotto di gelati, se ne estraggono 100 e se ne calcola in 82 g il valore del peso medio. Sapendo che la varianza √® pari
a 25:
<ol class="org-ol">
<li>Si determini l'intervallo di confidenza per il peso medio \(\mu\) dei gelati al livello di confidenza del 97%;</li>
<li>Si determini la probabilit√† che la differenza in valore assoluto tra la media campionaria e il peso medio \(\mu\) dei gelati
sia inferiore a 3 g.</li>
</ol></li>
</ul>

<p>
2:
</p>
\begin{align*}
P(|\bar{X}_n - \mu| < 3) &= P(-3 < \bar{X}_n < 3)\\
&= P\left(-\frac{3}{\frac{\sigma}{\sqrt{n}}} < \frac{\bar{X}_n - \mu}{\frac{\sigma}{\sqrt{n}}} < \frac{3}{\frac{\sigma}{\sqrt{n}}}\right)\\
&= P(-6 < Z < 6)\\
&= P(Z < 6) - P(Z < -6)\\
&= P(Z < 6) - (1 - P(Z < 6))
\end{align*}
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
out <span style="color: #558b2f;">&lt;-</span> z.test(82, stdev=sqrt(25), alternative=<span style="color: #689f38;">"two.sided"</span>, n=100, conf.level=0.97)
out$conf.int

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
pk <span style="color: #558b2f;">&lt;-</span> pnorm((3*sqrt(100))/sqrt(25))
pk - (1-pk)
</pre>
</div>

<pre class="example">
[1] 80.91495 83.08505
attr(,"conf.level")
[1] 0.97
[1] 1

</pre>

<p>
Esercizio 5.5:
</p>
<ul class="org-ul">
<li>Popolazione non normalmente distribuita e varianza sconosciuta;</li>
<li><p>
Consideriamo la seguente tabella:
</p>


<div class="figure">
<p><img src="Laboratorio/screenshot_2018-06-10_09-39-58.png" alt="screenshot_2018-06-10_09-39-58.png" />
</p>
</div>

<p>
e supponiamo di voler determinare un intervallo di confidenza per la media della popolazione, richiedendo un livello di
fiducia \(\alpha = 0.05\).
</p></li>
</ul>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Caricare il file "esempio1.2.csv"</span>
ese12 <span style="color: #558b2f;">&lt;-</span> scan(<span style="color: #689f38;">"./Files/esempio1.2.csv"</span>, sep=<span style="color: #689f38;">";"</span>, dec=<span style="color: #689f38;">","</span>)

out <span style="color: #558b2f;">&lt;-</span> z.test(ese12, stdev=sd(ese12), alternative=<span style="color: #689f38;">"two.sided"</span>, conf.level=0.95)
out
out$conf.int
</pre>
</div>

<pre class="example">
Read 80 items

	One Sample z-test

data:  ese12
z = 19.756, n = 80.00000, Std. Dev. = 1.21320, Std. Dev. of the sample
mean = 0.13564, p-value &lt; 2.2e-16
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 2.413901 2.945599
sample estimates:
mean of ese12 
      2.67975
[1] 2.413901 2.945599
attr(,"conf.level")
[1] 0.95
</pre>

<p>
Soluzione alternativa:
</p>
<div class="org-src-container">
<pre class="src src-R">lower <span style="color: #558b2f;">&lt;-</span> mean(ese12) - qnorm(0.975)*sd(ese12)/sqrt(length(ese12))

upper <span style="color: #558b2f;">&lt;-</span> mean(ese12) + qnorm(0.975)*sd(ese12)/sqrt(length(ese12))

interval <span style="color: #558b2f;">&lt;-</span> c(lower, upper)
interval
</pre>
</div>

<pre class="example">
[1] 2.413901 2.945599

</pre>

<p>
Esercizio 06:
</p>
<ul class="org-ul">
<li>Popolazione normalmente distribuita e varianza nota:</li>
<li>Un segnale radio viene emesso con frequenza distribuita normalmente e con valore atteso \(\mu\) e deviazione standard 30 kHz.
Supponendo di osservare la seguente serie di frequenze in kHz:
\((610, 601, 578, 615, 640, 630, 618, 602, 613, 610, 625, 585, 622, 608, 597)\).
<ol class="org-ol">
<li>Determinare una stima di \(\mu\) e la probabilit√† che la frequenza stia nell'intervallo di estremi 590 kHz e 610 kHz;</li>
<li>Determinare poi un intervallo di confidenza per \(\mu\) al 95%.</li>
</ol></li>
</ul>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
fr <span style="color: #558b2f;">&lt;-</span> c(610, 601, 578, 615, 640, 630, 618, 602, 613, 610, 625, 585, 622, 608, 597)
m <span style="color: #558b2f;">&lt;-</span> mean(fr)
m
pnorm(610, m, 30) - pnorm(590, m, 30)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
out <span style="color: #558b2f;">&lt;-</span> z.test(fr, stdev=30, alternative=<span style="color: #689f38;">"two.sided"</span>, conf.level=0.95)
out
out$conf.int
</pre>
</div>

<pre class="example">
[1] 610.2667
[1] 0.2467925

	One Sample z-test

data:  fr
z = 78.785, n = 15.000, Std. Dev. = 30.000, Std. Dev. of the sample
mean = 7.746, p-value &lt; 2.2e-16
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 595.0849 625.4485
sample estimates:
mean of fr 
  610.2667
[1] 595.0849 625.4485
attr(,"conf.level")
[1] 0.95
</pre>

<p>
Esercizio 02:
</p>
<ul class="org-ul">
<li>Popolazione normalmente distribuita e varianza sconosciuta;</li>
<li>Un segnale \(\mu\) viene trasmesso da una sorgente \(A\) ad una destinazione \(B\). Il segnale ricevuto in \(B\) √® distribuito normalmente
con media \(\mu\) e varianza \(\sigma^2\) incognita. Se vengono trasmessi 9 segnali successivi con valore \(\mu\) eguale e vengono ricevuti in
\(B\) i seguenti valori: \((5, 8.5, 12, 15, 7, 9, 7.5, 6.5, 10.5)\). Si calcoli un intervallo di confidenza con il 95% di confidenza
per \(\mu\).</li>
</ul>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(5, 8.5, 12, 15, 7, 9, 7.5, 6.5, 10.5)
out <span style="color: #558b2f;">&lt;-</span> t.test(x, conf.level=0.95)
out$conf.int
</pre>
</div>

<pre class="example">
[1]  6.630806 11.369194
attr(,"conf.level")
[1] 0.95

</pre>

<p>
Stime intervallari:
</p>
<ul class="org-ul">
<li>Intervalli di confidenza per la varianza:
<ul class="org-ul">
<li><p>
Popolazione normalmente distribuita:
</p>
<div class="org-src-container">
<pre class="src src-R">    sigma.test(x, sigma=1, sigmasq=sigma^2, alternative=c(<span style="color: #689f38;">"two.sisded"</span>, <span style="color: #689f38;">"less"</span>, <span style="color: #689f38;">"greater"</span>), conf.level=0.95, ...)
</pre>
</div></li>
</ul></li>
</ul>

<p>
Esempio 11:
</p>
<ul class="org-ul">
<li>Popolazione normalmente distribuita;</li>
<li>Si vuole verificare se la quantit√† \(X\) di una sostanza inquinante emessa dalle marmitte prodotto da un'azienda √® contenuta
entro i limiti prestabiliti. A tal fine, si estrae un campione di 10 marmitte dalla produzione settimanale dell'azienda e,
attraverso prove su strada, si rilevano le seguenti quantit√† (in mg/Km) della sostanza nociva rilasciante:
\((895, 902, 894, 903, 901, 893, 897, 908, 906, 891)\). Sapendo che la quantit√† emessa della sostanza in esame ha distribuzione
normale di parametri \(\mu\) e \(\sigma^2\) incogniti, determinare la stima intervallare di \(\sigma^2\) al livello di confidenza del 99%.</li>
</ul>

<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(895, 902, 894, 903, 901, 893, 897, 908, 906, 891)

out <span style="color: #558b2f;">&lt;-</span> sigma.test(x, conf.level = 0.99)
out$conf.int
</pre>
</div>

<pre class="example">
[1]  12.88717 175.22291
attr(,"conf.level")
[1] 0.99

</pre>

<p>
Esercizio 1:
</p>
<ul class="org-ul">
<li>Popolazione normalmente distribuita e varianza nota;</li>
<li>Si desidera stimare il tempo medio di CUP utilizzato dagli utenti di un server, in modo da affermare con il 95% di confidenza
che il valore stimato non disti pi√π di mezzo secondo dal valore vero. Dall'esperienza passata, possiamo ipotizzare che il tempo
di CPU utilizzato sia distribuito secondo una normale, con \(\sigma^2 = 2.25\). Quale deve essere la dimensione \(n\) del campione?</li>
</ul>
<p>
\[2 \cdot z_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}} = \frac{1}{2} \implies n = 2 \cdot z_{1-\frac{\alpha}{2}} \frac{\sigma}{\frac{1}{2}}\]
</p>

<div class="org-src-container">
<pre class="src src-R">q1 <span style="color: #558b2f;">&lt;-</span> qnorm(1-(1-0.95)/2) <span style="color: #607d8b;">#</span><span style="color: #607d8b;">quantile 0.975</span>

n <span style="color: #558b2f;">&lt;-</span> ceiling((2*q1*sqrt(2.25)/0.5)^2)
n
</pre>
</div>

<pre class="example">
[1] 139

</pre>

<p>
Esempio 5.5:
</p>
<ul class="org-ul">
<li>Popolazione normalmente distribuita e varianza sconosciuta;</li>
<li>Riprendiamo in considerazione il problema esposto nell'Esempio 5.5, nel quale si sono determinate 2 intervalli di confidenza
per la media del costo al metro quadro degli appartamenti di un dato quartiere di una citt√† italiana. Si voglia determinare
quanto deve essere grande il campione affinch√© l'intervallo di confidenza simmetrico abbia ampiezza non superiore a 0.3,
mantenendo sempre un livello di confidenza \(\alpha = 0.05\).</li>
</ul>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Caricare il file "esempio1.2.csv"</span>
ese12 <span style="color: #558b2f;">&lt;-</span> scan(<span style="color: #689f38;">"./Files/esempio1.2.csv"</span>, sep=<span style="color: #689f38;">";"</span>, dec=<span style="color: #689f38;">","</span>)

alpha = 0.05
q <span style="color: #558b2f;">&lt;-</span> qnorm(1-alpha/2)

n <span style="color: #558b2f;">&lt;-</span> ceiling((2*q*sd(ese12)/0.3)^2)
n
</pre>
</div>

<pre class="example">
Read 80 items
[1] 252

</pre>
</div>
</div>
<div id="outline-container-orgcf3bbd5" class="outline-4">
<h4 id="orgcf3bbd5"><span class="section-number-4">3.2.5</span> Verifica di ipotesi: Test Parametrici</h4>
<div class="outline-text-4" id="text-3-2-5">
<p>
<i>Errori di I specie</i>
</p>

<p>
Esercizio 01:
</p>
<ul class="org-ul">
<li><p>
Per provare l'ipotesi che una moneta √® buona viene adottata la seguente regola di decisione. Si accetta l'ipotesi se il numero di teste
in un campione di 100 lanci √® compreso tra 40 e 60 inclusi. In caso contrario si rifiuta l'ipotesi. Si determini la probabilit√† di rifiutare
l'ipotesi quando essa √® vera. Sia \(X = \text{numero di teste}\). Sotto ipotesi nulla, \(X\) √® distribuita secondo una \(\text{Bin}(n=100, p=0.5)\).
Poich√© \(n > 30\), allora approssimiamo la distribuzione di \(X\) con una \(N(\mu = 50, \sigma^2 = 25)\). La regione critica √® \((X<40) \cup (X>60)\).
</p>

<p>
√à necessario calcolare \(P((X < 40) \cup (X > 60)) = P(X < 40) + P(X > 60)\)
</p></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">mu = 100*0.5
sd = sqrt(100*(1-0.5)*0.5)

Pmin <span style="color: #558b2f;">&lt;-</span> pnorm(40, mean=mu, sd)
Pmax <span style="color: #558b2f;">&lt;-</span> pnorm(60, mean=mu, sd, lower.tail=F)
Pmax + Pmin
</pre>
</div>

<pre class="example">
[1] 0.04550026

</pre>

<p>
Esercizio 03:
</p>
<ul class="org-ul">
<li><p>
Una fabbrica produce corde le cui resistenze alla rottura hanno una media di 300 N e uno scarto quadratico medio di 24N. Si crede che per mezzo di un
recente processo produttivo, la resistenza media alla rottura possa essere aumentata.
</p>
<ol class="org-ol">
<li>Si determini una regola di decisione per il rifiuto del vecchio processo produttivo al livello di significativit√† dello 0.01 se si vogliono provare
64 corde.</li>
</ol>

<p>
Considerazioni:
</p>
<ul class="org-ul">
<li>Ipotesi nulla: \(H_0 : \mu = 300N\);</li>
<li>Ipotesi alternativa: \(H_1 : \mu > 300N\).</li>
</ul>
<p>
\[Z = \frac{\bar{X} - \mu}{\frac{\sigma}{\sqrt{n}}} = \frac{\bar{X} - 300}{\frac{24}{\sqrt{64}}} = \frac{\bar{X} - 300}{3} \implies Z*3 + 300 = \bar{X}\]
</p></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">z <span style="color: #558b2f;">&lt;-</span> qnorm(1-0.01)
lower <span style="color: #558b2f;">&lt;-</span> ceiling(z*(24/sqrt(64))+300) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">limite inferiore della regione critica</span>
cat(<span style="color: #689f38;">"Si rifiuta l'ipotesi H_0 se Xn cade in: ["</span>, lower,<span style="color: #689f38;">", inf]"</span>)                 
</pre>
</div>

<pre class="example">
Si rifiuta l'ipotesi H_0 se Xn cade in: [ 307 , inf]

</pre>

<p>
<i>Errore di II specie</i>
</p>

<p>
Esercizio 04:
</p>
<ul class="org-ul">
<li><p>
Una fabbrica produce corde le cui resistenze alla rottura hanno una media di 300 N e uno scarto quadratico medio di 24 N. Si
crede che per mezzo di un recente processo produttivo la resistenza media alla rottura possa essere aumentata.
</p>
<ol class="org-ol">
<li>Qual'√® la probabilit√† di accettare il vecchio processo produttivo con la regola di decisione stabilita quando in realt√† il
nuovo processo ha aumentato la resistenza media alla rottura a 310 N?</li>
</ol>
<p>
Considerazioni:
</p>
<ul class="org-ul">
<li>Ipotesi nulla: \(H_0 : \mu = 300 N\);</li>
<li>Ipotesi alternativa: \(H_1 : \mu = 310 N\)</li>
</ul>
<p>
\[P(\bar{X} \in (-\infty, 307] \mid \mu = 310)\]
Dobbiamo calcolare la probabilit√† che \(\bar{X} \in (-\infty, 307]\) sapendo che \(\bar{X}\) √® distribuita come indicato da \(H_1\), cio√®
\(\bar{X} \sim N(310, 24)\).
</p></li>
</ul>

<div class="org-src-container">
<pre class="src src-R">out <span style="color: #558b2f;">&lt;-</span> pnorm(307, mean=310, sd=24/sqrt(64))
out
</pre>
</div>

<pre class="example">
[1] 0.1586553

</pre>

<p>
Libreria utilizzata:
</p>
<div class="org-src-container">
<pre class="src src-R">  <span style="color: #607d8b;">#</span><span style="color: #607d8b;">install.packages("TeachingDemos")</span>
  <span style="color: #558b2f;">require</span>(<span style="color: #689f38;">"TeachingDemos"</span>)
</pre>
</div>

<pre class="example">
Carico il pacchetto richiesto: TeachingDemos

</pre>

<p>
Test sulla media di una popolazione:
</p>
<ol class="org-ol">
<li><p>
Popolazione normalmente distribuita e varianza nota:
</p>
<div class="org-src-container">
<pre class="src src-R">   z.test(x, mu=0, stdev, alternative=c(<span style="color: #689f38;">"two.sided"</span>, <span style="color: #689f38;">"less"</span>, <span style="color: #689f38;">"greater"</span>), sd=stdev, n=length(x), conf.level=0.95, ...)
</pre>
</div></li>
<li><p>
Popolazione normalmente distribuita e varianza sconosciuta:
</p>
<div class="org-src-container">
<pre class="src src-R">   t.test(x, y=<span style="color: #0097A7;">NULL</span>, alternative=c(<span style="color: #689f38;">"two.sided"</span>, <span style="color: #689f38;">"less"</span>, <span style="color: #689f38;">"greater"</span>), paired=<span style="color: #0097A7;">FALSE</span>, var.equal=<span style="color: #0097A7;">FALSE</span>, conf.level=0.95, ...)
</pre>
</div></li>
<li><p>
Popolazione non normalmente distribuita e varianza nota:
</p>
<div class="org-src-container">
<pre class="src src-R">   z.test()
</pre>
</div></li>
<li><p>
Popolazione non normalmente distribuita e varianza sconosciuta:
</p>
<div class="org-src-container">
<pre class="src src-R">   z.test()
</pre>
</div></li>
</ol>

<p>
<i>Test sulla media di una popolazione</i>
</p>

<p>
\(p\)-value:
</p>
<ul class="org-ul">
<li>Probabilit√† che una variabile avente la stessa distribuzione della statistica test, sotto ipotesi \(H_0\), assuma un valore maggiore di
quello da essa effettivamente ottenuto sulla base della realizzazione del campione.</li>
</ul>
<p>
Regola di decisione:
</p>
<ul class="org-ul">
<li>\(p-\text{value} < \alpha \implies \text{si rifiuta } H_0\);</li>
<li>\(p-\text{value} > \alpha \implies \text{non si rifiuta } H_0\).</li>
</ul>

<p>
Esercizio 15:
</p>
<ul class="org-ul">
<li>Popolazione normalmente distribuita e varianza nota;</li>
<li><p>
Dato il campione \((0.5, 1.2, -0.5, 0.9, 2.0, -1.2, -0.3)\) estratto da una popolazione con distribuzione normale, testare l'ipotesi \(\mu=0\)
contro \(\mu \neq 0\).
</p>
<ol class="org-ol">
<li>Con livello di significativit√† 0.05, supponendo varianza nota e uguale a 2.</li>
</ol>
<p>
Considerazioni:
</p>
<ul class="org-ul">
<li>Ipotesi nulla: \(H_0 : \mu=0\);</li>
<li>Ipotesi alternativa: \(H_1 : \mu \neq 0\).</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(0.5, 1.2, -0.5, 0.9, 2.0, -1.2, -0.3)
z.test(x, mu=0, stdev=sqrt(2))
</pre>
</div>

<pre class="example">

	One Sample z-test

data:  x
z = 0.69488, n = 7.00000, Std. Dev. = 1.41420, Std. Dev. of the sample
mean = 0.53452, p-value = 0.4871
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 -0.6762162  1.4190734
sample estimates:
mean of x 
0.3714286
</pre>
<p>
Non si rifiuta \(H_0 : p-\text{value} > \alpha\)
</p>

<p>
Soluzione alternativa:
\[Z_n = \frac{\bar{X}_n - \mu_0}{\frac{\sigma}{\sqrt{n}}}\]
</p>
<div class="org-src-container">
<pre class="src src-R">z1 <span style="color: #558b2f;">&lt;-</span> qnorm((1-(0.05/2))) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">calcolo del quantile</span>
Zn <span style="color: #558b2f;">&lt;-</span> (mean(x) - 0)/(sqrt(2)/sqrt(7)) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">calcolo della statistica</span>
Zn

<span style="color: #00796b;">if</span> (Zn &lt;= -z1 | Zn &gt;= z1) {
    out <span style="color: #558b2f;">&lt;-</span> <span style="color: #689f38;">'Rigettiamo H_0 in favore di H_1'</span>
} <span style="color: #00796b;">else</span> {
    out <span style="color: #558b2f;">&lt;-</span> <span style="color: #689f38;">'Non rigettiamo H_0 in favore di H_1'</span>
}
out
</pre>
</div>

<pre class="example">
[1] 0.6948792
[1] "Non rigettiamo H_0 in favore di H_1"

</pre>

<p>
Esercizio 15 (modificato):
</p>
<ul class="org-ul">
<li>Popolazione normalmente distribuita e varianza nota;</li>
<li><p>
Dato il campione \((0.5, 1.2, -0.5, 0.9, 2.0, -1.2, -0.3)\) estratto da una popolazione con distribuzione normale, testare l'ipotesi
\(\mu=0\) contro \(\mu > 0\).
</p>
<ol class="org-ol">
<li>Con livello di significativit√† 0.05, supponendo varianza nota ed uguale a 2.</li>
</ol>
<p>
Considerazioni:
</p>
<ul class="org-ul">
<li>Ipotesi nulla: \(H_0 : \mu = 0\);</li>
<li>Ipotesi alternativa: \(H_1 : \mu > 0\).</li>
</ul>
<p>
Nota:
</p>
<ul class="org-ul">
<li>Test unidirezionale con coda a destra poich√© \(\mu > 0\);</li>
<li>Se l'esercizio avesse richiesto \(\mu < 0\): test unidirezionale con coda a sinistra.</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(0.5, 1.2, -0.5, 0.9, 2.0, -1.2, -0.3)
z.test(x, mu=0, stdev=sqrt(2), alternative=<span style="color: #689f38;">"greater"</span>)
</pre>
</div>

<pre class="example">

	One Sample z-test

data:  x
z = 0.69488, n = 7.00000, Std. Dev. = 1.41420, Std. Dev. of the sample
mean = 0.53452, p-value = 0.2436
alternative hypothesis: true mean is greater than 0
95 percent confidence interval:
 -0.5077827        Inf
sample estimates:
mean of x 
0.3714286
</pre>
<p>
Non si rifiuta \(H_0 : p-\text{value} > \alpha\)
Esercizio 15:
</p>
<ul class="org-ul">
<li>Popolazione normalmente distribuita e varianza sconosciuta:</li>
<li><p>
Dato il campione \((0.5, 1.2, -0.5, 0.9, 2.0, -1.2, -0.3)\) estratto da una popolazione con distribuzione normale, testare
l'ipotesi \(\mu=0\) contro \(\mu \neq 0\).
</p>
<ol class="org-ol">
<li>Con livello di significativit√† 0.1, supponendo varianza sconosciuta.</li>
</ol>
<p>
Considerazioni:
</p>
<ul class="org-ul">
<li>Ipotesi nulla: \(H_0 : \mu = 0\);</li>
<li>Ipotesi alternativa: \(H_0 : \mu \neq 0\).</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">t.test(x, conf.level=0.9)
</pre>
</div>

<pre class="example">

	One Sample t-test

data:  x
t = 0.89005, df = 6, p-value = 0.4077
alternative hypothesis: true mean is not equal to 0
90 percent confidence interval:
 -0.4394847  1.1823418
sample estimates:
mean of x 
0.3714286
</pre>
<p>
Non si rifiuta \(H_0 : p-\text{value} > \alpha\).
</p>

<p>
Soluzione alternativa (statistica test: media campionaria):
</p>
<div class="org-src-container">
<pre class="src src-R">m <span style="color: #558b2f;">&lt;-</span> mean(x) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">statistica test</span>

n <span style="color: #558b2f;">&lt;-</span> length(x) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">calcolo lunghezza campione</span>
q1 <span style="color: #558b2f;">&lt;-</span> qt(1-(1-0.9)/2, n) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">calcolo quantile</span>
sdcc <span style="color: #558b2f;">&lt;-</span> sd(x) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">calcolo deviazione standard campionaria corretta</span>

T1 <span style="color: #558b2f;">&lt;-</span> 0 - q1*sdcc/sqrt(n) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">limiti della regione critica</span>
T2 <span style="color: #558b2f;">&lt;-</span> 0 + q1*sdcc/sqrt(n)

<span style="color: #00796b;">if</span> (m &lt;= T1 | m &gt;= T2) {
    out2 <span style="color: #558b2f;">&lt;-</span> <span style="color: #689f38;">'Rigettiamo H_0 in favore di H_1'</span>
} <span style="color: #00796b;">else</span> {
    out2 <span style="color: #558b2f;">&lt;-</span> <span style="color: #689f38;">'Non rigettiamo H_0 in favore di H_1'</span>
}
out2
</pre>
</div>

<pre class="example">
[1] "Non rigettiamo H_0 in favore di H_1"

</pre>

<p>
Esercizio 21:
</p>
<ul class="org-ul">
<li>Popolazione non normalmente distribuita e varianza nota;</li>
<li><p>
Il signor Rossi desidera capire quale sia la media della spesa mensile per generi alimentari del proprio nucleo familiare. Per questo
registra tali spese per 36 mesi, ottenendo una media campionaria uguale a 305 e una varianza campionaria corretta uguale a 225.
</p>
<ol class="org-ol">
<li>Fornire una stima intervallare, con significativit√† \(\alpha = 0.05\), per la media della spesa mensile in generi alimentari della famiglia Rossi.</li>
<li>Controllare, con un livello \(\alpha = 0.1\), l'ipotesi che la media della spesa mensile della Famiglia Rossi in generi alimentari sia in realt√†
di 280 euro.</li>
</ol>
<p>
Considerazioni:
</p>
<ul class="org-ul">
<li>Ipotesi nulla: \(H_0 : \mu = 280\);</li>
<li>Ipotesi alternativa: \(H_1 : \mu \neq 280\).</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">z.test(305, mu=280, stdev=sqrt(225), conf.level=0.9, n=36)
</pre>
</div>

<pre class="example">

	One Sample z-test

data:  305
z = 10, n = 36.0, Std. Dev. = 15.0, Std. Dev. of the sample mean = 2.5,
p-value &lt; 2.2e-16
alternative hypothesis: true mean is not equal to 280
90 percent confidence interval:
 300.8879 309.1121
sample estimates:
mean of 305 
        305
</pre>
<p>
Si rifiuta \(H_0 : p-\text{value} < \alpha\).
</p>

<p>
Test sulla varianza di una popolazione:
</p>
<ul class="org-ul">
<li><p>
Popolazione normalmente distribuita:
</p>
<div class="org-src-container">
<pre class="src src-R">  sigma.test(x, sigma=1, sigmasq=sigma^2, alternative=c(<span style="color: #689f38;">"two.sided"</span>, <span style="color: #689f38;">"less"</span>, <span style="color: #689f38;">"greater"</span>), conf.level=0.95)
</pre>
</div></li>
</ul>

<p>
Esercizio 28:
</p>
<ul class="org-ul">
<li>Popolazione normalmente distribuita;</li>
<li><p>
Un campione di 10 individui estratto da una popolazione con distribuzione normale ha assunto i seguenti valori:
\((1.4, 0.6, 2.2, 0.8, 2.3, -1.6, -0.1, -0.3, 1, 2)\)
</p>
<ol class="org-ol">
<li>Controllare con \(\alpha = 0.01\), l'ipotesi che la deviazione standard della popolazione sia uguale a 1.2.</li>
</ol>
<p>
Considerazioni:
</p>
<ul class="org-ul">
<li>Ipotesi nulla: \(H_0 : \sigma = 1.2\);</li>
<li>Ipotesi alternativa: \(H_1 : \sigma \neq 1.2\).</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(1.4, 0.6, 2.2, 0.8, 2.3, -1.6, -0.1, -0.3, 1, 2)
sigma.test(x, sigma=1.2, conf.level=0.9)
</pre>
</div>

<pre class="example">

	One sample Chi-squared test for variance

data:  x
X-squared = 9.6257, df = 9, p-value = 0.7633
alternative hypothesis: true variance is not equal to 1.44
90 percent confidence interval:
 0.8192575 4.1685803
sample estimates:
var of x 
1.540111
</pre>
<p>
Non si rifiuta \(H_0 : p-\text{value} > \alpha\).
</p>

<p>
Libreria:
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">install.packages('BSDA')</span>
<span style="color: #558b2f;">require</span>(<span style="color: #689f38;">'BSDA'</span>)
</pre>
</div>

<p>
Test sulla differenza delle medie di due popolazioni:
</p>
<ol class="org-ol">
<li><p>
Popolazioni \(X\) e \(Y\) normalmente distribuite con varianze uguali e sconosciute:
</p>
<div class="org-src-container">
<pre class="src src-R">   t.test(x, y=<span style="color: #0097A7;">NULL</span>, alternative=c(<span style="color: #689f38;">"two.sided"</span>, <span style="color: #689f38;">"leww"</span>, <span style="color: #689f38;">"greater"</span>), mu=0, paired=<span style="color: #0097A7;">FALSE</span>, var.equal=<span style="color: #0097A7;">TRUE</span>, conf.level=0.95, ...)
</pre>
</div></li>
<li><p>
Popolazioni \(X\) e \(Y\) normalmente distribuite con varianze diverse e note:
</p>
<div class="org-src-container">
<pre class="src src-R">   z.test(x, y=<span style="color: #0097A7;">NULL</span>, alternative=<span style="color: #689f38;">"two.sided"</span>, mu=0, sigma.x=<span style="color: #0097A7;">NULL</span>, sigma.y=<span style="color: #0097A7;">NULL</span>, conf.level=0.95)
</pre>
</div></li>
<li><p>
Popolazioni \(X\) e \(Y\) non normalmente distribuite con varianze diverse e note (campioni grandi con numerosit√† maggiore o uguale a 30):
</p>
<div class="org-src-container">
<pre class="src src-R">   z.test()
</pre>
</div></li>
</ol>

<p>
Esercizio 13:
</p>
<ul class="org-ul">
<li>Popolazioni \(X\) e \(Y\) normalmente distribuite con varianze uguali e sconosciute;</li>
<li><p>
Un insieme di pazienti viene sottoposto all'uso di un nuovo farmaco per una data patologia. La patologia viene misurata quotidianamente
da un esame, portando alla seguente tabella:
</p>
<ul class="org-ul">
<li>Campione \(X: (110, 102, 104, 96, 92,  97, 85, 115)\);</li>
<li>Campione \(Y: (125, 133, 128, 119, 134, 126, 132, 135)\).</li>
</ul>
<p>
Si sa che la misura √® normalmente distribuita e si vuole verificare che il farmaco influisce o meno sulla patologia con confidenza
al 95%.
Considerazioni:
</p>
<ul class="org-ul">
<li>Ipotesi nulla: \(H_0 : \mu_X = \mu_Y\);</li>
<li>Ipotesi alternativa: \(H_1 : \mu_X \neq \mu_Y\).</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(110, 102, 104, 96, 92, 97, 85, 115)
y <span style="color: #558b2f;">&lt;-</span> c(125, 133, 128, 119, 134, 126, 132, 135)

t.test(x, y, var.equal=T)
</pre>
</div>

<pre class="example">

	Two Sample t-test

data:  x and y
t = -7.3221, df = 14, p-value = 3.778e-06
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -37.33301 -20.41699
sample estimates:
mean of x mean of y 
  100.125   129.000
</pre>
<p>
Rifiutando \(H_0\) in favore di \(H_1\): il farmaco non influisce.
</p>

<p>
Esempio:
</p>
<ul class="org-ul">
<li>Popolazione \(X\) e \(Y\) normalmente distribuite con varianze diverse e note;</li>
<li><p>
Si supponga di avere:
</p>
<ul class="org-ul">
<li>Campione \(X: (154, 109, 137, 115, 140)\);</li>
<li>Campione \(Y: (108, 115, 126, 92, 146)\).</li>
</ul>
<p>
Estratti da popolazioni normalmente distribuite. Le deviazioni standard delle due popolazioni sono note e rispettivamente pari a
15.5 e 13.5. Si vuole verificare che la differenza delle medie √® pari a 0 con confidenza del 95%.
Considerazioni:
</p>
<ul class="org-ul">
<li>Ipotesi nulla: \(H_0: \mu_X = \mu_Y\);</li>
<li>Ipotesi alternativa: \(H_1: \mu_X \neq \mu_Y\)</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(154, 109, 137, 115, 140)
y <span style="color: #558b2f;">&lt;-</span> c(108, 115, 126, 92, 146)

z.test(x, y, mu=0, sigma.x=15.5, sigma.y=13.5)
</pre>
</div>

<pre class="example">

	One Sample z-test

data:  x
z1 = 2.7123, z2 = 2.5472, z3 = 2.3248, z4 = 3.1840, z5 = 2.0063, n =
5.000, Std. Dev.1 = 108.000, Std. Dev.2 = 115.000, Std. Dev.3 =
126.000, Std. Dev.4 = 92.000, Std. Dev.5 = 146.000, Std. Dev. of the
sample mean1 = 48.299, Std. Dev. of the sample mean2 = 51.430, Std.
Dev. of the sample mean3 = 56.349, Std. Dev. of the sample mean4 =
41.144, Std. Dev. of the sample mean5 = 65.293, p-value = 0.006682,
p-value = 0.010860, p-value = 0.020083, p-value = 0.001453, p-value =
0.044821
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
  36.33557 231.80009
sample estimates:
mean of x 
      131 

Warning messages:
1: In c(-1, 1) * qnorm(1 - (1 - conf.level)/2) * sd :
  longer object length is not a multiple of shorter object length
2: In if (substr(fp, 1L, 1L) == "&lt;") fp else paste("=", fp) :
  la condizione la lunghezza &gt; 1 e solo il promo elemento verr√† utilizzato
</pre>
<p>
Non rifiutiamo \(H_0\) in favore di \(H_1\).
</p>

<p>
Test sull'uguaglianza della varianza di due popolazioni:
</p>
<ul class="org-ul">
<li><p>
Popolazioni \(X\) e \(Y\) normalmente distribuite:
</p>
<ul class="org-ul">
<li>\(\tilde{V} = \frac{\sigma_Y^2 \cdot \hat{S}_{X, n}^2}{\sigma_X^2 \cdot \hat{S}_{Y, m}^2}\);</li>
<li>\(H_0 : \sigma_X^2 = \sigma_Y^2\);</li>
<li>\(V_{n, m} = \frac{\hat{S}_{X, n}^2}{\hat{S}_{Y, m}^2}\)</li>
</ul>
<p>
Risulta essere distribuita come una F con \((n-1)\) e \((m-1)\) gradi di libert√†.
</p></li>
</ul>

<p>
Esempio 6.6:
</p>
<ul class="org-ul">
<li>Popolazioni \(X\) e \(Y\) normalmente distribuite con varianze uguali e sconosciute;</li>
<li><p>
Consideriamo due diversi quartieri della stessa citt√† e supponiamo di essere interessati a confrontare il valor medio dei redditi annui
familiari in migliaia di euro. Si supponga che sia lecito assumere che tali redditi siano normalmente distribuiti. Si supponga di estrarre
un campione casuale per ogni quartiere di numerosit√† pari a 10 e 15. Supponiamo che le realizzazioni dei campioni relativi ad \(X\) ed \(Y\) siano
\((22, 48, 51, 20, 28, 35, 38, 26, 50, 36)\) e \((40, 42, 50, 26, 30, 34, 37, 28, 25, 30, 32, 38, 22, 55, 40)\).
</p>

<p>
Verificare l'uguaglianza delle due varianze.
Considerazioni:
</p>
<ul class="org-ul">
<li>Ipotesi nulla: \(H_0 : \sigma^2_X = \sigma^2_Y\);</li>
<li>Ipotesi alternativa: \(H_1 : \sigma^2_X \neq \sigma^2_Y\).</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(22, 48, 51, 20, 28, 35, 38, 26, 50, 36)
y <span style="color: #558b2f;">&lt;-</span> c(40, 42, 50, 26, 30, 34, 37, 28, 25, 30, 32, 38, 22, 55, 40)
stat <span style="color: #558b2f;">&lt;-</span> var(x)/var(y)
stat

F1 <span style="color: #558b2f;">&lt;-</span> qf((0.1/2), 9, 14)
F2 <span style="color: #558b2f;">&lt;-</span> qf(1-(0.1/2), 9, 14)
F1
F2

<span style="color: #00796b;">if</span> (stat &gt;= F1 &amp; stat &lt;= F2) {
    out <span style="color: #558b2f;">&lt;-</span> <span style="color: #689f38;">'Non rigettiamo H_0 in favore di H_1'</span>
} <span style="color: #00796b;">else</span>{
    out <span style="color: #558b2f;">&lt;-</span> <span style="color: #689f38;">'Rigettiamo H_0 in favore di H_1'</span>
}
out
</pre>
</div>

<pre class="example">
[1] 1.53924
[1] 0.3305269
[1] 2.645791
[1] "Non rigettiamo H_0 in favore di H_1"

</pre>

<p>
Soluzione alternativa:
</p>
<div class="org-src-container">
<pre class="src src-R">var.test(x, y, ratio=1, alternativa=c(<span style="color: #689f38;">"two.sided"</span>, <span style="color: #689f38;">"less"</span>, <span style="color: #689f38;">"greater"</span>), conf.level=0.95)
var.test(x, y)
</pre>
</div>

<pre class="example">

	F test to compare two variances

data:  x and y
F = 1.5392, num df = 9, denom df = 14, p-value = 0.4528
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 0.4796185 5.8459594
sample estimates:
ratio of variances 
           1.53924

	F test to compare two variances

data:  x and y
F = 1.5392, num df = 9, denom df = 14, p-value = 0.4528
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 0.4796185 5.8459594
sample estimates:
ratio of variances 
           1.53924
</pre>

<p>
Test di incorrelazione:
</p>
<ul class="org-ul">
<li>\(\rho_{XY} = \frac{\sigma_{XY}}{\sigma_X \cdot \sigma_Y}\);</li>
<li>\(R_n = \frac{\sum_{i=1}^n (X_i - \bar{X}) \cdot (Y_i - \bar{Y})}{n \cdot S_{X, n} \cdot S_{Y, n}}\);</li>
<li>\(H_0 : \rho_{XY} = 0\);</li>
<li>\(\hat{T}_n = R_n \cdot \sqrt{\frac{n-2}{1-R_n^2}}\).</li>
</ul>
<p>
Risulta essere distribuita come una t di Studente con \((n-2)\) gradi di libert√†.
</p>
<div class="org-src-container">
<pre class="src src-R">cor.test(x, y, alternative=c(<span style="color: #689f38;">"two.sided"</span>, <span style="color: #689f38;">"less"</span>, <span style="color: #689f38;">"greater"</span>),
         method=c(<span style="color: #689f38;">"pearson"</span>, <span style="color: #689f38;">"kendal"</span>, <span style="color: #689f38;">"spearman"</span>), exact=<span style="color: #0097A7;">NULL</span>, conf.level=0.95, continuiti=<span style="color: #0097A7;">FALSE</span>, ...)
</pre>
</div>

<p>
Esempio 6.7:
</p>
<ul class="org-ul">
<li><p>
Si consideri una popolazione \((X, Y)\) di travi di cemento, in cui \(X\) indica il carico di prima lesione e \(Y\) il carico a rottura finale.
Si supponga di avere un'ampia popolazione, ovvero di avere un elevato numero di queste travi e di voler controllare, con un livello di
significativit√† \(\alpha = 0.05\), se esiste una correlazione tra il carico di prima lesione ed il carico a rottura finale. A tale scopo
si supponga di aver effettuato delle prove su 15 travi, ottenendo i risultati riportati nel file Esempio 1.16.
</p>

<p>
Considerazioni:
</p>
<ul class="org-ul">
<li>Ipotesi nulla: \(H_0 : \rho_{XY} = 0\);</li>
<li>Ipotesi alternativa: \(H_1 : \rho_{XY} \neq 0\).</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">ese116 <span style="color: #558b2f;">&lt;-</span> read.csv(<span style="color: #689f38;">"./Files/esempio1.16.csv"</span>, sep=<span style="color: #689f38;">";"</span>, header=<span style="color: #0097A7;">TRUE</span>)

cor.test(ese116$CaricoPrimaLesione.x., ese116$CaricoRottura.y., method=<span style="color: #689f38;">"pearson"</span>)
</pre>
</div>

<pre class="example">

	Pearson's product-moment correlation

data:  ese116$CaricoPrimaLesione.x. and ese116$CaricoRottura.y.
t = 8.4357, df = 13, p-value = 1.245e-06
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 0.7699373 0.9733190
sample estimates:
      cor 
0.9195286
</pre>
</div>
</div>
<div id="outline-container-org5bee095" class="outline-4">
<h4 id="org5bee095"><span class="section-number-4">3.2.6</span> Verifica di ipotesi: Test non Parametrici</h4>
<div class="outline-text-4" id="text-3-2-6">
<p>
Test per la bont√† dell'adattamento:
</p>
<ul class="org-ul">
<li>Ipotesi:
<ul class="org-ul">
<li>Nulla \(H_0 : F_X (t) = F(t) \text{ per ogni } t \in \mathbb{R}\);</li>
<li>Alternativa: \(H_1 : F_X(t) \neq F(t) text{ per almeno un} t \in \mathbb{R}\)</li>
</ul></li>
<li><p>
Test di Kolmogorov-Smirnov: \(D_n = \text{sup}_{t} \in \mathbb{R}|F(t) - \hat{F}_{X, n}(t)|\).
</p>
<div class="org-src-container">
<pre class="src src-R">  ks.test(x, y, ..., alternative = c(<span style="color: #689f38;">"two.sided"</span>, <span style="color: #689f38;">"less"</span>, <span style="color: #689f38;">"greater"</span>), exact=<span style="color: #0097A7;">NULL</span>)
</pre>
</div></li>
</ul>

<p>
Esercizio 02:
</p>
<ul class="org-ul">
<li><p>
Un campione di numerosit√† 5 estratto da una popolazione \(X\) ha fornito i seguenti valori: \((6.2, 8.8, 9.4, 13.6, 10)\).
Controllare con Kolmogorov-Smirnov e livello di significativit√† 0.1 l'ipotesi che \(X\) sia distribuita:
</p>
<ol class="org-ol">
<li>Secondo una uniforme \([0, 20]\);</li>
<li>Secondo un'esponenziale di parametro \(\lambda = 0.1\).</li>
</ol>
<p>
Considerazioni:
</p>
<ol class="org-ol">
<li>Ipotesi:
<ul class="org-ul">
<li>Nulla: \(H_0 : X \sim U[0, 20]\)</li>
<li>Alternativa: \(H_1 : X text{ non } U[0, 20]\).</li>
</ul></li>
<li>Ipotesi:
<ul class="org-ul">
<li>Nulla: \(H_0 : X \sim \text{Exp}[0.1]\);</li>
<li>Alternativa: \(H_1 : X \text{ non } \sim \text{Exp}[0.1]\).</li>
</ul></li>
</ol></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(6.2, 8.8, 9.4, 13.6, 10)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
ks.test(x, <span style="color: #689f38;">"punif"</span>, 0, 20)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
ks.test(x, <span style="color: #689f38;">"pexp"</span>, 0.1)
</pre>
</div>

<pre class="example">

	One-sample Kolmogorov-Smirnov test

data:  x
D = 0.32, p-value = 0.585
alternative hypothesis: two-sided

	One-sample Kolmogorov-Smirnov test

data:  x
D = 0.46206, p-value = 0.1713
alternative hypothesis: two-sided
</pre>

<ol class="org-ol">
<li>Non si rifiuta l'ipotesi \(H_0\) che la popolazione segue una distribuzione Uniforme \(p-\text{value} > \alpha = 0.1\)</li>
<li>Non si rifiuta l'ipotesi \(H_0\) che la popolazione segue una distribuzione Esponenziale \(p-\text{value} > \alpha = 0.1\).</li>
</ol>

<p>
Test per la bont√† dell'adattamento:
</p>
<ul class="org-ul">
<li>Ipotesi:
<ul class="org-ul">
<li>Nulla \(H_0 : F_X (t) = F(t) \text{ per ogni } t \in \mathbb{R}\);</li>
<li>Alternativa: \(H_1 : F_X(t) \neq F(t) text{ per almeno un} t \in \mathbb{R}\)</li>
</ul></li>
<li><p>
Test del Chi-quadro: \[W = \sum_{k=1}^K \frac{(n_k - np_k)^2}{np_k}\], con \(K\) numero di intervalli.
</p>
<ul class="org-ul">
<li>Quando \(H_0\) √® vera e quando \(n_k\) sono sufficientemente grandi (\(\geq 5\)), la \(W\) √® distribuita come una Chi-Quadro con:
<ul class="org-ul">
<li>\(K-1\) gradi di libert√† se la funzione di ripartizione \(F\) √® stata decisa arbitrariamente senza fare uso preventivo
dei dati campionari;</li>
<li>\(K-r-1\) gradi di libert√† se nella funzione di ripartizione \(F\) compaiono \(r\) parametri che sono stati stimati facendo
uso dei dati campionari.</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">  chisq.test(x, y=<span style="color: #0097A7;">NULL</span>, correct=<span style="color: #0097A7;">TRUE</span>, p=rep(1/length(x), length(x)), rescale.p=<span style="color: #0097A7;">FALSE</span>, simulate.p.value=<span style="color: #0097A7;">FALSE</span>, B=2000)
</pre>
</div></li>
</ul>

<p>
Esercizio 03:
</p>
<ul class="org-ul">
<li><p>
Un campione di dimensione 30, estratto da una popolazione \(X\), ha fornito i seguenti valori:
</p>


<div class="figure">
<p><img src="Laboratorio/screenshot_2018-06-14_13-26-11.png" alt="screenshot_2018-06-14_13-26-11.png" />
</p>
</div>

<p>
Controllare con il metodo del Chi-Quadro, con significativit√† 0.01, l'ipotesi che \(X\) sia distribuito secondo un'uniforme con
parametri \([0, 20]\). Dividere l'intervallo in 4.
</p>

<p>
Considerazioni:
</p>
<ul class="org-ul">
<li>Ipotesi:
<ul class="org-ul">
<li>Nulla: \(H_0 : X \sim U[0, 20]\);</li>
<li>Alternativa: \(H_1 : X \text{ non } \sim U[0, 20]\).</li>
</ul></li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">x <span style="color: #558b2f;">&lt;-</span> c(2.03 , 9.82 , 2.50 , 6.14 , 4.44 , 4.62 , 10.10 , 7.34 , 8.31 , 8.32 , 16.46 , 3.61,16.55 , 
15.49 , 17.87 , 6.93 , 10.96 , 4.53, 17.72 , 7.52 , 4.69 , 6.70 , 16.24 , 6.19, 13.14 , 16.73 , 10.64 , 
11.53, 2.78, 15.36)

limiti <span style="color: #558b2f;">&lt;-</span> c(0, 5, 10, 15, 20) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">si indicano i limiti degli intervalli</span>
interval <span style="color: #558b2f;">&lt;-</span> cut(x, breaks=limiti) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">si divide in intervalli</span>
f <span style="color: #558b2f;">&lt;-</span> table(interval) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">si calcolano le frequenze assolute</span>
chisq.test(f, p=diff(punif(limiti, 0, 20)))
</pre>
</div>

<pre class="example">

	Chi-squared test for given probabilities

data:  f
X-squared = 1.2, df = 3, p-value = 0.753

</pre>

<p>
Non si rifiuta l'ipotesi \(H_0\) che la popolazione segue una distribuzione Uniforme \(p-\text{value} > \alpha = 0.01\)
</p>

<p>
Test per il confronto delle distribuzioni di due popolazioni:
</p>
<ul class="org-ul">
<li>Ipotesi:
<ul class="org-ul">
<li>Nulla: \(H_0 : X \sim U[0, 20]\);</li>
<li>Alternativa: \(H_1 : X \text{ non } \sim U[0, 20]\).</li>
</ul></li>
<li>Test:
<ol class="org-ol">
<li>Dei segni;</li>
<li>Dei ranghi di Wilcoxon;</li>
<li>Di Kolmogorov-Smirnov al caso di due campioni.</li>
</ol></li>
</ul>

<p>
Test dei segni:
</p>
<ul class="org-ul">
<li><p>
Se l'ipotesi nulla √® vera e se \(n - S^= \geq 10\), la quantit√† \(S_n = S^+ - S^-\) risulta essere distribuita:
\(N\left(0, \frac{n-S^=}{2}\right)\), con:
</p>
<ul class="org-ul">
<li>\(S^+ = \text{numero di volte che \(X_i > Y_i\)}\);</li>
<li>\(S^- = \text{numero di volte che \(X_i < Y_i\)}\);</li>
<li>\(S^= = \text{numero di volte che \(X_i = Y_i\)}\).</li>
</ul>
<p>
Fissato il livello di significativit√† \(\alpha\), la regione critica per \(S_n\) √®
\(C = \left(-\infty, -z_{1-\frac{\alpha}{2}} \frac{n-S^=}{2}\right) \cup \left(+z_{1-\frac{\alpha}{2}} \frac{n-S^=}{2}, +\infty\right)\)
</p></li>
</ul>

<p>
Esercizio 09:
</p>
<ul class="org-ul">
<li><p>
Un'azienda afferma che un integratore di sua ideazione √® in grado di influire sul livello di colesterolo nel sangue, per tale
ragione viene prodotto uno studio dell'azienda medesima dove a 10 individui √® stato misurato il livello del colesterolo prima
di assumere l'integratore in questione e dopo 2 settimane di assunzione del medesimo. Si √® ottenuto quanto segue:
</p>


<div class="figure">
<p><img src="Laboratorio/screenshot_2018-06-14_14-24-33.png" alt="screenshot_2018-06-14_14-24-33.png" />
</p>
</div>

<p>
Cosa possiamo concludere circa l'affermazione dell'azienda?
</p></li>
<li>Ipotesi:
<ul class="org-ul">
<li>Nulla: \(H_0 : F_X(t) = F_Y(t)\);</li>
<li>Alternativa: \(H_1 : F_X(t) \neq F_Y(t)\);</li>
<li>\(X\) indica il livello di colesterolo "prima" e \(Y\) il livello "dopo" la cura con l'integratore.</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">prima <span style="color: #558b2f;">&lt;-</span> c( 225, 310, 287, 249, 345, 288, 247, 268, 213, 332) 
dopo <span style="color: #558b2f;">&lt;-</span> c(210, 301, 291, 212, 307, 290, 216, 245, 195, 301) 

s <span style="color: #558b2f;">&lt;-</span> sign(prima-dopo)
p <span style="color: #558b2f;">&lt;-</span> length(which(s&gt;0))
n <span style="color: #558b2f;">&lt;-</span> length(which(s&lt;0))
u <span style="color: #558b2f;">&lt;-</span> length(which(s==0))

stat <span style="color: #558b2f;">&lt;-</span> p-n
stat

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Calcolo dei limiti della regione critica</span>
- qnorm(0.975)*sqrt((length(x)-u)/2)
qnorm(0.975)*sqrt((length(x)-u)/2)
</pre>
</div>

<pre class="example">
[1] 6
[1] -7.590908
[1] 7.590908

</pre>

<p>
La statistica, che ha valore 6, cade nella Regione Critica. Rigettiamo l'ipotesi nulla che le due distribuzioni (\(X\) ed \(Y\))
siano identiche: il che porta a concludere che l'affermazione fatta dall'azienda non √® falsa, ossia che l'integrazione
influisce sul livello di colesterolo nel sangue.
</p>

<p>
Test dei ranghi di Wilcoxon:
</p>
<div class="org-src-container">
<pre class="src src-R">wilcoxon.test(x, y=<span style="color: #0097A7;">NULL</span>, alternative=c(<span style="color: #689f38;">"two.sided"</span>, <span style="color: #689f38;">"less"</span>, <span style="color: #689f38;">"greater"</span>), mu=0, paired=<span style="color: #0097A7;">FALSE</span>, exact=<span style="color: #0097A7;">NULL</span>, correct=<span style="color: #0097A7;">TRUE</span>, conf.int=<span style="color: #0097A7;">FALSE</span>, conf.lecvel=0.95, ...)
</pre>
</div>

<p>
Esercizio 10:
</p>
<ul class="org-ul">
<li><p>
Un'azienda afferma che un integratore di sua ideazione √® in grado di influire sul livello di colesterolo nel sangue, per tale
ragione viene prodotto uno studio dell'azienda medesima dove a 10 individui √® stato misurato il livello del colesterolo prima
di assumere l'integratore in questione e dopo 2 settimane di assunzione del medesimo. Si √® ottenuto quanto segue:
</p>


<div class="figure">
<p><img src="Laboratorio/screenshot_2018-06-14_14-34-21.png" alt="screenshot_2018-06-14_14-34-21.png" />
</p>
</div>

<p>
Cosa possiamo concludere circa l'affermazione dell'azienda (considerare un livello di significativit√† pari a 0.05)?
</p></li>
<li>Ipotesi:
<ul class="org-ul">
<li>Nulla: \(H_0 : F_X(t) = F_Y(t)\);</li>
<li>Alternativa: \(H_1 : F_X(t) \neq F_Y(t)\);</li>
<li>\(X\) indica il livello di colesterolo "prima" e \(Y\) il livello "dopo" la cura con l'integratore.</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">X <span style="color: #558b2f;">&lt;-</span> c( 225, 310, 287, 249, 345, 288, 247, 277, 267, 194)
Y <span style="color: #558b2f;">&lt;-</span> c( 210, 301, 291, 212, 307, 290, 216, 312, 206, 185, 199, 204, 245, 195, 301)

wilcox.test(X, Y, exact=<span style="color: #0097A7;">FALSE</span>)
</pre>
</div>

<pre class="example">

	Wilcoxon rank sum test with continuity correction

data:  X and Y
W = 92, p-value = 0.36
alternative hypothesis: true location shift is not equal to 0

</pre>

<p>
Non si rifiuta l'ipotesi \(H_0\) che le due distribuzioni siano uguali. \(p-\text{value} > \alpha = 0.05\). Quindi l'affermazione
dell'azienda circa l'efficacia dell'integratore viene rigettata.
</p>

<p>
TEst di Kolmogorov-Smirnov nel caso di due campioni:
</p>
<div class="org-src-container">
<pre class="src src-R">ks.test(x, y, ..., alternative=c(<span style="color: #689f38;">"two.sided"</span>, <span style="color: #689f38;">"less"</span>, <span style="color: #689f38;">"greater"</span>), exact=<span style="color: #0097A7;">NULL</span>)
</pre>
</div>


<p>
Esercizio 12:
</p>
<ul class="org-ul">
<li><p>
Pazienti leucemici vengono sottoposti a due trattamenti \(A\) e \(B\). Il conteggio delle piastrine \((10^3)\) viene riportato
nella tabella.
</p>


<div class="figure">
<p><img src="Laboratorio/screenshot_2018-06-14_14-39-46.png" alt="screenshot_2018-06-14_14-39-46.png" />
</p>
</div>

<p>
Possiamo affermare che tali conteggi provengano dalla stessa distribuzione?
</p></li>
<li>Ipotesi:
<ul class="org-ul">
<li>Nulla: \(H_0 : F_X(t) = F_Y(t)\);</li>
<li>Alternativa: \(H_1 : F_X(t) \neq F_Y(t)\);</li>
<li>\(X\) indica il trattamento \(A\) e \(Y\) indica il trattamento \(B\).</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">A <span style="color: #558b2f;">&lt;-</span> c( 20.30, 22.53, 25.70, 13.23, 29.67, 24.46, 26.07, 19.35, 17.81,16.00, 13.50, 32.90)
B <span style="color: #558b2f;">&lt;-</span> c( 10.56, 28.13, 19.94, 11.03, 8.09, 12.95, 21.14, 32.50, 10.90 )

ks.test(A, B)
</pre>
</div>

<pre class="example">

	Two-sample Kolmogorov-Smirnov test

data:  A and B
D = 0.55556, p-value = 0.06063
alternative hypothesis: two-sided

</pre>

<p>
Non si rifiuta l'ipotesi \(H_0\) che le due distribuzioni \(A\) e \(B\) siano identiche. Ossia che il numero di piastrine sotto il
trattamento \(A\) sia distribuito in modo identico dal numero di piastrine sotto il trattamento \(B\) \(p-\text{value} > \alpha = 0.05\).
</p>

<p>
Test di indipendenza:
</p>
<ul class="org-ul">
<li>Test del Chi-quadro per l'indipendenza:
<ul class="org-ul">
<li>Consideriamo una popolazione bidimensionale \((X, Y)\) ed estraiamo un campione casuale \(((X_1, Y_1), \dots, (X_n, Y_n))\);</li>
<li>Ipotesi:
<ul class="org-ul">
<li>Nulla: \(H_0 : \text{i caratteri \(X\) ed \(Y\) sono indipendenti}\);</li>
<li>Alternativa: \(H_1 : \text{i caratteri \(X\) ed \(Y\) non sono indipendenti}\);</li>
<li>Per ogni coppia \((k, j)\) consideriamo le seguenti quantit√†:
<ul class="org-ul">
<li>\(n_k^X =\) numero di elementi \(X_i\) del campione che cadono in \(I_k^X\);</li>
<li>\(n_j^Y =\) numero di elementi \(Y_i\) del campione che cadono in \(I_j^Y\);</li>
<li>\(n_{k, j} =\) numero di elementi \((X_i, Y_i)\) del campione che cadono in \(I_k^X \times I_j^Y\);</li>
<li>\(f_k^X = \frac{n_k^X}{n} =\) frequenza relativa di \(I_k^X\);</li>
<li>\(f_j^Y = \frac{n_j^Y}{n} =\) frequenza relativa di \(I_j^Y\);</li>
<li>\(f_{k, j} = \frac{n_{k, j}}{n} =\) frequenza relativa di \(I_k^X \times I_j^Y\).</li>
</ul></li>
<li>\(W = n \cdot \sum_{k=1}^{M_X}\sum_{j=1}^{M_Y} \frac{(f_{k, j} - f_k^X \cdot f_j^Y)^2}{f_k^X \cdot f_j^Y}\);</li>
<li>Si pu√≤ dimostrare che quando l'ipotesi nulla √® vera e quando le \(n_{k, j}\) sono sufficientemente grandi \((\geq 5)\), allora \(W\)
√® approssimativamente distribuita come una Chi-Quadro con \((M_X - 1) \cdot (M_Y - 1)\) gradi di libert√†.</li>
</ul></li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">chisq.test(x, y=<span style="color: #0097A7;">NULL</span>, correct=<span style="color: #0097A7;">TRUE</span>, p=rep(1/length(1/length(x), length(x)), rescale.p=<span style="color: #0097A7;">FALSE</span>, simulate.p.value=<span style="color: #0097A7;">FALSE</span>, B=2000))
</pre>
</div>

<p>
Esercizio 06:
</p>
<ul class="org-ul">
<li><p>
Si desidera controllare l'ipotesi di indipendenza tra due caratteri discreti \(X\) ed \(Y\) di una popolazione. Il campione, di
numerosit√† 150, ha fornito i conteggi riportati in tabella.
</p>


<div class="figure">
<p><img src="Laboratorio/screenshot_2018-06-14_14-53-44.png" alt="screenshot_2018-06-14_14-53-44.png" />
</p>
</div>

<p>
Controllare l'ipotesi di indipendenza di \(X\) ed \(Y\) con un livello di significativit√† 0.05.
</p></li>
<li>Ipotesi:
<ul class="org-ul">
<li>Nulla: \(H_0 : \text{i caratteri \(X\) ed \(Y\) sono indipendenti}\);</li>
<li>Alternativa: \(H_1 : \text{i caratteri \(X\) ed \(Y\) non sono indipendenti}\);</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">arr <span style="color: #558b2f;">&lt;-</span> c(25, 20, 5, 15, 30, 15, 10, 25, 5)
m <span style="color: #558b2f;">&lt;-</span> matrix(arr, nrow=3, ncol=3)

chisq.test(m)
</pre>
</div>

<pre class="example">

	Pearson's Chi-squared test

data:  m
X-squared = 12.75, df = 4, p-value = 0.01256

</pre>

<p>
Si rifiuta l'ipotesi \(H_0\) che i due caratteri \(X\) e \(Y\) sono indipendenti. In conclusione i due caratteri \(X\) ed \(Y\) non sono
tra loro indipendenti \(p-\text{value} < \alpha = 0.05\).
</p>

<p>
Test di incorrelazione:
</p>
<ul class="org-ul">
<li>Coefficiente di correlazione dei ranghi di Spearman:
Consideriamo una popolazione bidimensionale \((X, Y)\) ed estraiamo un campione casuale \(((X_1, Y_1,), \dots, (X_n, Y_n))\)</li>
<li>Ipotesi:
<ul class="org-ul">
<li>Nulla: \(H_0 : \text{i caratteri \(X\) ed \(Y\) sono indipendenti}\);</li>
<li>Alternativa: \(H_1 : \text{i caratteri \(X\) ed \(Y\) non sono indipendenti}\);</li>
</ul></li>
<li><p>
Ad ogni coppia \((x_i, y_i)\) associamo ora la corrispondente coppia di ranghi \((r_i^x, r_i^y)\) e denotiamo con \(d_i\) le loro
differenze \(d_i = r_i^x - r_i^y\).
</p>

<p>
Consideriamo la statistica \(R_s = 1 - \frac{6 \cdot \sum_{i=1}^n d_i^2}{n^3 - n}\)
indipendentemente dalla forma della distribuzione
congiunte \((X, Y)\). Quando i caratteri \(X\) ed \(Y\) sono incorrelati, nel senso di Spearman, e la numerosit√† del campione √® maggiore
di 10, allora la statistica \(\tilde{T}_n = R_S \cdot \sqrt{\frac{n-2}{1 - R_S^2}}\)
risulta essere approssimativamente distribuita come una t di Student con \((n-2)\) gradi di libert√†.
</p></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">cor(x, y=<span style="color: #0097A7;">NULL</span>, use=<span style="color: #689f38;">"everything"</span>, method=c(<span style="color: #689f38;">"pearson"</span>, <span style="color: #689f38;">"kendall"</span>, <span style="color: #689f38;">"spearman"</span>))
</pre>
</div>

<p>
Esercizio 11:
</p>
<ul class="org-ul">
<li><p>
La tabella sottostante riporta il rango dello HumanDevelopmentIndex (HDI) e dell'Income per 10 paesi:
</p>


<div class="figure">
<p><img src="Laboratorio/screenshot_2018-06-14_15-09-58.png" alt="screenshot_2018-06-14_15-09-58.png" />
</p>
</div>

<p>
Cosa possiamo concludere circa la correlazione tra Income e HDI?
</p></li>
<li>Ipotesi:
<ul class="org-ul">
<li>Nulla: \(H_0 : \text{i caratteri \(X\) ed \(Y\) sono incorrelati secondo Spearman}\);</li>
<li>Alternativa: \(H_1 : \text{i caratteri \(X\) ed \(Y\) non sono incorrelati secondo Spearman}\);</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-R">Income <span style="color: #558b2f;">&lt;-</span> c(3, 2, 10, 8, 5, 7, 1, 6, 9, 4)
HDI <span style="color: #558b2f;">&lt;-</span> c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)

rho <span style="color: #558b2f;">&lt;-</span> cor(Income, HDI, method=<span style="color: #689f38;">"spearman"</span>) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">calcolo coeff. di correlazione di Spearman</span>
Tn <span style="color: #558b2f;">&lt;-</span> rho*sqrt((10-2)/(1-rho^2))
Tn

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Calcolo dei limiti della regione critica</span>
qt(0.95, 8) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">quantile di ordine (1 - alpha/2) con alpha=0.1</span>
-qt(0.95, 8)
</pre>
</div>

<pre class="example">
[1] 0.3278787
[1] 1.859548
[1] -1.859548

</pre>

<p>
Non si rifiuta l'ipotesi \(H_0\) che i due caratteri non sono correlati secondo Spearman poich√© la statistica \(T_n = 0.33\) non cade
nella regione critica \(C = (-\infty, -1.86,) \cup (1.86, +\infty)\).
</p>
</div>
</div>
<div id="outline-container-org8063237" class="outline-4">
<h4 id="org8063237"><span class="section-number-4">3.2.7</span> Regressione Lineare</h4>
<div class="outline-text-4" id="text-3-2-7">
<p>
Regressione lineare semplice - stima dei parametri del modello:
</p>
<div class="org-src-container">
<pre class="src src-R">lm(formula, data, subset, weights, na.action, method=<span style="color: #689f38;">"qr"</span>, model=<span style="color: #0097A7;">TRUE</span>, x=<span style="color: #0097A7;">FALSE</span>, y=<span style="color: #0097A7;">FALSE</span>, qr=<span style="color: #0097A7;">TRUE</span>, singular.ok=<span style="color: #0097A7;">TRUE</span>, contrasts=<span style="color: #0097A7;">NULL</span>, offset, ...)
</pre>
</div>

<p>
Regressione lineare semplice - stima puntuale della variabile risposta:
</p>
<div class="org-src-container">
<pre class="src src-R">predict(object, ...)
</pre>
</div>

<p>
Esercizio 02:
</p>
<ul class="org-ul">
<li>Si considerino i seguenti dati:</li>
</ul>


<div class="figure">
<p><img src="Laboratorio/screenshot_2018-06-14_18-16-20.png" alt="screenshot_2018-06-14_18-16-20.png" />
</p>
</div>

<ol class="org-ol">
<li>Stimare il coefficiente di correlazione lineare tra \(X\) e \(Y\) e si discuta la correlazione tra i due caratteri;</li>
<li>Si determini la retta di regressione lineare \(Y = \alpha_0 + \alpha_1 X\);</li>
<li>Stimare il valore atteso della variabile di risposta \(Y\) quando il regressore \(X\) vale 5.</li>
</ol>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
X <span style="color: #558b2f;">&lt;-</span> c(-3, 4, 5, 8, 6)
Y <span style="color: #558b2f;">&lt;-</span> c(2, 6, 7, 10, 5)
Rxy <span style="color: #558b2f;">&lt;-</span> cor(X, Y, method=<span style="color: #689f38;">"p"</span>)
Rxy

</pre>
</div>

<pre class="example">
[1] 0.8814141

</pre>

<p>
Forte correlazione (positiva) che lega i due caratteri \(X\) e \(Y\) poich√© il coefficiente di correlazione lineare (=0.88) √® prossimo
a 1.
</p>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
rr <span style="color: #558b2f;">&lt;-</span> lm(Y ~ X)
rr

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Coefficienti</span>
coef <span style="color: #558b2f;">&lt;-</span> rr$coefficients
</pre>
</div>

<pre class="example">

Call:
lm(formula = Y ~ X)

Coefficients:
(Intercept)            X  
     3.5429       0.6143

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Creare il grafico</span>
plot(Y ~ X)
abline(coef(rr), col=<span style="color: #689f38;">'red'</span>, lwd=3)
</pre>
</div>


<div class="figure">
<p><img src="lm.png" alt="lm.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
new <span style="color: #558b2f;">&lt;-</span> data.frame(X=5)
predict(rr, new)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Stima puntuale della variabile risposta</span>
predict(rr)
</pre>
</div>

<pre class="example">
null device 
          1
       1 
6.614286
       1        2        3        4        5 
1.700000 6.000000 6.614286 8.457143 7.228571

</pre>

<p>
Regressione lineare semplice - residui di un modello:
</p>
<div class="org-src-container">
<pre class="src src-R">residuals(object, ...)
</pre>
</div>

<p>
Regressione lineare semplice - intervalli di confidenza per i coefficienti di regressione:
</p>
<div class="org-src-container">
<pre class="src src-R">confint(object, parm, level=0.95)
</pre>
</div>

<p>
Esempi:
</p>
<div class="org-src-container">
<pre class="src src-R">residuals(rr)
</pre>
</div>

<pre class="example">
           1             2             3             4             5 
3.000000e-01  6.522560e-16  3.857143e-01  1.542857e+00 -2.228571e+00

</pre>

<div class="org-src-container">
<pre class="src src-R">confint(rr, level=0.9) <span style="color: #607d8b;"># </span><span style="color: #607d8b;">livello di fiducia 0.1</span>
</pre>
</div>

<pre class="example">
                  5 %     95 %
(Intercept) 1.0930143 5.992700
X           0.1670077 1.061564

</pre>

<p>
Regressione lineare semplice - intervalli di confidenza per valori stimati della variabile risposta e intervalli di predizione:
</p>
<div class="org-src-container">
<pre class="src src-R">predict(object, newdata, se.fit=<span style="color: #0097A7;">FALSE</span>, scale=<span style="color: #0097A7;">NULL</span>, df=<span style="color: #0097A7;">Inf</span>, interval=c(<span style="color: #689f38;">"none"</span>, <span style="color: #689f38;">"confidence"</span>, <span style="color: #689f38;">"prediction"</span>), level=0.95, type=c(<span style="color: #689f38;">"response"</span>, <span style="color: #689f38;">"terms"</span>), terms=<span style="color: #0097A7;">NULL</span>, na.action=na.pass, pred.var=res.var/weights, weights=1, ...)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Intervalli di confidenza</span>
predict(object, newdata, ..., interval=<span style="color: #689f38;">"confidence"</span>, level=0.95)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Intervalli di predizione</span>
predict(object, newdata, ..., interval=<span style="color: #689f38;">"prediction"</span>, level=0.95)
</pre>
</div>

<p>
Esempi:
</p>
<ul class="org-ul">
<li>\(\left[a_0 - t_{1-\frac{\alpha}{2}} \cdot \sqrt{s_{\text{RES}}^2 \cdot \left[\frac{1}{n} + \frac{x^{-2}}{s_x^2}\right]},
  a_0 + t_{1-\frac{\alpha}{2}} \cdot \sqrt{s_{\text{RES}}^2 \cdot \left[\frac{1}{n} + \frac{x^{-2}}{s_x^2}\right]}\right]\);</li>
<li>\(\left[a_1 - t_{1-\frac{\alpha}{2}} \cdot \sqrt{s_{\text{RES}}^2 \cdot \frac{1}{s_x^2}},
  a_0 + t_{1-\frac{\alpha}{2}} \cdot \sqrt{s_{\text{RES}}^2 \cdot \frac{1}{s_x^2}}\right]\).</li>
</ul>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Intervalli di confidenza</span>
predict(rr, level=0.9, interval=<span style="color: #689f38;">"confidence"</span>)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Intervalli di predizione</span>
new <span style="color: #558b2f;">&lt;-</span> data.frame(X=5)
predict(rr, newdata=new, level=0.9, interval=<span style="color: #689f38;">"prediction"</span>)
</pre>
</div>

<pre class="example">
       fit       lwr       upr
1 1.700000 -1.850160  5.250160
2 6.000000  4.326439  7.673561
3 6.614286  4.881985  8.346586
4 8.457143  6.007300 10.906986
5 7.228571  5.330931  9.126212
       fit      lwr      upr
1 6.614286 2.490586 10.73799

</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;"># </span><span style="color: #607d8b;">Rappresentazione grafica degli intervalli di confidenza e degli intervalli di predizione</span>
<span style="color: #558b2f;">library</span>(HH)
ci.plot(rr, conf.level=0.9)
</pre>
</div>


<div class="figure">
<p><img src="regressione.png" alt="regressione.png" />
</p>
</div>

<p>
Regressione lineare semplice - attendibilit√† del modello:
</p>
<div class="org-src-container">
<pre class="src src-R">summary(object, ...)
</pre>
</div>

<p>
Esercizio 01:
</p>
<ul class="org-ul">
<li>Si considerino i seguenti dati:</li>
</ul>


<div class="figure">
<p><img src="Laboratorio/screenshot_2018-06-14_20-00-07.png" alt="screenshot_2018-06-14_20-00-07.png" />
</p>
</div>

<ol class="org-ol">
<li>Stimare i coefficienti di regressione di \(Y\) su \(X\);</li>
<li>Verificare se l'intercetta √® significativamente diversa da 0 con confidenza 0.95;</li>
<li>Stimare il valore atteso della variabile di risposta \(Y\) quando il regressore \(X\) vale 13.</li>
</ol>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
X <span style="color: #558b2f;">&lt;-</span> c(12, 8, 11, 15, 18)
Y <span style="color: #558b2f;">&lt;-</span> c(30, 23, 27, 36, 42)

fm <span style="color: #558b2f;">&lt;-</span> lm(Y ~ X)
fm

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
summary(fm)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
new <span style="color: #558b2f;">&lt;-</span> data.frame(X=13)
predict(fm, new, level=<span style="color: #689f38;">"prediction"</span>)
</pre>
</div>

<pre class="example">
Loading required package: lattice
Loading required package: grid
Loading required package: latticeExtra
Loading required package: RColorBrewer
Loading required package: multcomp
Loading required package: mvtnorm
Loading required package: survival
Loading required package: TH.data
Loading required package: MASS

Attaching package: ‚ÄòTH.data‚Äô

The following object is masked from ‚Äòpackage:MASS‚Äô:

    geyser

Loading required package: gridExtra
null device 
          1

Call:
lm(formula = Y ~ X)

Coefficients:
(Intercept)            X  
      6.653        1.949

Call:
lm(formula = Y ~ X)

Residuals:
       1        2        3        4        5 
-0.04082  0.75510 -1.09184  0.11224  0.26531 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   6.6531     1.3559   4.907 0.016207 *  
X             1.9490     0.1023  19.047 0.000316 ***
---
Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1

Residual standard error: 0.7846 on 3 degrees of freedom
Multiple R-squared:  0.9918,	Adjusted R-squared:  0.9891 
F-statistic: 362.8 on 1 and 3 DF,  p-value: 0.000316
      1 
31.9898
</pre>

<p>
Regressione lineare semplice - analisi dei residui:
</p>
<ol class="org-ol">
<li>Test di normalit√†: Test di Shapiro Wilk;</li>
<li>Test di incorrelazione: Test di Durbin e Watson;</li>
<li>Test di omoschedasticit√†: Metodi grafici;</li>
<li>Outliers: Distanza di Cook.</li>
</ol>

<p>
Test di normalit√† - Test di Shapiro Wilk:
</p>

<p>
Ipotesi:
</p>
<ul class="org-ul">
<li>Nulla: \(H_0: \text{i residui seguono una distribuzione normale}\);</li>
<li>Alternativa: \(H_1: \text{i residui non seguono una distribuzione normale}\).</li>
</ul>
<div class="org-src-container">
<pre class="src src-R">X <span style="color: #558b2f;">&lt;-</span> c(-3, 4, 5, 8, 6)
Y <span style="color: #558b2f;">&lt;-</span> c(2, 6, 7, 10 ,5)
rr <span style="color: #558b2f;">&lt;-</span> lm(Y ~ X)
residui <span style="color: #558b2f;">&lt;-</span> residuals(rr)
shapiro.test(residui)
</pre>
</div>

<pre class="example">

	Shapiro-Wilk normality test

data:  residui
W = 0.89097, p-value = 0.362

</pre>

<p>
Non si rifiuta l'ipotesi \(H_0\) ossia che i residui seguono una distribuzione normale poich√© il \(p-\text{value} > 0.05\).
</p>

<p>
Test di incorrelazione - Test di Durbin e Watson:
</p>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #558b2f;">library</span>(lmtest)
residui <span style="color: #558b2f;">&lt;-</span> residuals(rr)
dwtest(rr, alternative=<span style="color: #689f38;">"two.sided"</span>)
</pre>
</div>

<pre class="example">
Carico il pacchetto richiesto: zoo

Attaching package: ‚Äòzoo‚Äô

The following objects are masked from ‚Äòpackage:base‚Äô:

    as.Date, as.Date.numeric

	Durbin-Watson test

data:  rr
DW = 2.0831, p-value = 0.6294
alternative hypothesis: true autocorrelation is not 0
</pre>

<p>
Non si rifiuta l'ipotesi \(H_0\), quindi i residui sono incorrelati poich√© il \(p-\text{value} > 0.05\).
</p>

<p>
Test di omoschedasticit√† - Metodi grafici:
</p>
<div class="org-src-container">
<pre class="src src-R">plot(X, rr$residuals, xlab=<span style="color: #689f38;">"X"</span>, ylab=<span style="color: #689f38;">"RESIDUALS"</span>, main=<span style="color: #689f38;">"Verifica Omoschedasticit&#224;"</span>)
abline(h=0)
</pre>
</div>


<div class="figure">
<p><img src="omoschedasticit√†.png" alt="omoschedasticit√†.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-R">plot(fitted(rr), abs(residui), ylab=<span style="color: #689f38;">"RESIDUAL"</span>, xlab=<span style="color: #689f38;">"Fitted"</span>, main=<span style="color: #689f38;">"Residui in valore assoluto vs Fitted Value"</span>)
</pre>
</div>

<div class="figure">
<p><img src="omoschedasticit√†2.png" alt="omoschedasticit√†2.png" />
</p>
</div>

<p>
Outliers - Distanza di Cook:
</p>
<div class="org-src-container">
<pre class="src src-R">cook <span style="color: #558b2f;">&lt;-</span> cooks.distance(rr)
cook
</pre>
</div>

<pre class="example">
null device 
          1
null device 
          1
           1            2            3            4            5 
1.601695e+00 2.628942e-32 1.021151e-02 6.177966e-01 4.576271e-01

</pre>

<p>
Un sospetto outliers √® influente sui parametri della regressione se la Distanza di Cook, \(D > 1\):
\[D_i = \frac{\sum_j \left(y_{(i)_j}^* - \hat{y_j} \right)^2}{\text{SSE}}\]
</p>

<p>
Regressione lineare multipla:
</p>
<div class="org-src-container">
<pre class="src src-R">lm(formula, data, subset, weights, na.action, method=<span style="color: #689f38;">"qr"</span>, model=<span style="color: #0097A7;">TRUE</span>, x=<span style="color: #0097A7;">FALSE</span>, y=<span style="color: #0097A7;">FALSE</span>, qr=<span style="color: #0097A7;">TRUE</span>, singular.ok=<span style="color: #0097A7;">TRUE</span>, contrasts=<span style="color: #0097A7;">NULL</span>, offset, ...)
</pre>
</div>

<pre class="example">
Errore: '...' usato in un contesto sbagliato

</pre>

<p>
Esempio:
</p>
<ul class="org-ul">
<li>Il dataset "trees" (fornito da R) contiene delle misurazioni sulla circonferenza, altezza e volume di 31 alberi di ciliegio abbattuti.</li>
</ul>
<p>
Dati:
</p>
<ol class="org-ol">
<li>Girth: diametro in pollici (\(X_1\));</li>
<li>Height: altezza in piedi (\(X_2\));</li>
<li>Volume: volume in piedi alla terza (\(Y\)).</li>
</ol>

<p>
Vogliamo determinare quanto segue:
</p>
<ol class="org-ol">
<li>Coefficienti della retta di regressione: \(Y = \alpha_0 + \alpha_1 x_1 + \alpha_2 x_2 + \epsilon\);</li>
<li>Intervalli di confidenza per i coefficienti di regressione;</li>
<li>Stima puntuale, intervalli di confidenza e intervalli di predizione della variabile risposta su nuovi dati con Girth
\((9.1, 11.6, 12.5)\) e Height \((46, 74, 87)\).</li>
</ol>
<div class="org-src-container">
<pre class="src src-R"><span style="color: #607d8b;">#</span><span style="color: #607d8b;">1</span>
trees.lm <span style="color: #558b2f;">&lt;-</span> lm(Volume ~ Girth + Height, data=trees)
trees.lm

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">2</span>
confint(trees.lm)

<span style="color: #607d8b;">#</span><span style="color: #607d8b;">3</span>
<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Stima puntuale</span>
new <span style="color: #558b2f;">&lt;-</span> data.frame(Girth=c(9.1, 11.6, 12.5), Height=c(49, 74, 87))
predict(trees.lm, newdata=new)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Intervalli di confidenza del valore mu_0 = E[Y_0]</span>
predict(trees.lm, newdata=new, interval=<span style="color: #689f38;">"confidence"</span>)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Intervalli di predizione del valore y_0 = Y_0</span>
predict(trees.lm, newdata=new, interval=<span style="color: #689f38;">"prediction"</span>)

<span style="color: #607d8b;"># </span><span style="color: #607d8b;">Attendibilit&#224; del modello</span>
summary(trees.lm)
</pre>
</div>

<pre class="example">

Call:
lm(formula = Volume ~ Girth + Height, data = trees)

Coefficients:
(Intercept)        Girth       Height  
   -57.9877       4.7082       0.3393
                   2.5 %      97.5 %
(Intercept) -75.68226247 -40.2930554
Girth         4.16683899   5.2494820
Height        0.07264863   0.6058538
        1         2         3 
 1.479912 21.731594 30.379205
        fit       lwr       upr
1  1.479912 -5.009282  7.969106
2 21.731594 20.111104 23.352084
3 30.379205 26.909637 33.848773
        fit       lwr      upr
1  1.479912 -8.783476 11.74330
2 21.731594 13.616578 29.84661
3 30.379205 21.703641 39.05477

Call:
lm(formula = Volume ~ Girth + Height, data = trees)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.4065 -2.6493 -0.2876  2.2003  8.4847 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -57.9877     8.6382  -6.713 2.75e-07 ***
Girth         4.7082     0.2643  17.816  &lt; 2e-16 ***
Height        0.3393     0.1302   2.607   0.0145 *  
---
Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1

Residual standard error: 3.882 on 28 degrees of freedom
Multiple R-squared:  0.948,	Adjusted R-squared:  0.9442 
F-statistic:   255 on 2 and 28 DF,  p-value: &lt; 2.2e-16
</pre>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Gabriele Calissi</p>
<p class="date">Created: 2018-06-16 sab 16:26</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
